# ä¿®å¤ç‰ˆæ ‡ç­¾ç”Ÿæˆ - é¿å…æœªæ¥æ•°æ®æ³„éœ²

def _generate_labels_fixed(self, price_series: pd.Series, lag: int = 12,
                          profit_quantile: float = 0.85, loss_quantile: float = 0.15,
                          lookback_window: int = 500) -> pd.Series:
    """
    ä¿®å¤ç‰ˆæ ‡ç±¤ç”Ÿæˆ - æ»¾å‹•çª—å£åˆ†ä½æ•¸ï¼Œåš´æ ¼é¿å…æœªä¾†æ•¸æ“šæ´©éœ²
    """
    # è¨ˆç®—æœªä¾†æ”¶ç›Š
    future_prices = price_series.shift(-lag)
    returns = (future_prices - price_series) / price_series
    
    # åˆå§‹åŒ–æ¨™ç±¤
    labels = pd.Series(1, index=price_series.index, dtype=int)  # é»˜èªæŒæœ‰
    
    # æ»¾å‹•çª—å£è¨ˆç®—åˆ†ä½æ•¸é–¾å€¼
    for i in range(lookback_window, len(returns) - lag):
        # åªä½¿ç”¨éå»æ•¸æ“šè¨ˆç®—åˆ†ä½æ•¸
        start_idx = max(0, i - lookback_window)
        historical_returns = returns.iloc[start_idx:i]
        
        if len(historical_returns.dropna()) < 100:  # ç¢ºä¿æœ‰è¶³å¤ æ­·å²æ•¸æ“š
            continue
            
        # åŸºæ–¼æ­·å²æ•¸æ“šè¨ˆç®—å‹•æ…‹é–¾å€¼
        upper_threshold = historical_returns.quantile(profit_quantile)
        lower_threshold = historical_returns.quantile(loss_quantile)
        
        # æ‡‰ç”¨é–¾å€¼åˆ°ç•¶å‰æ™‚é»
        current_return = returns.iloc[i]
        if pd.notna(current_return):
            if current_return > upper_threshold:
                labels.iloc[i] = 2  # è²·å…¥
            elif current_return < lower_threshold:
                labels.iloc[i] = 0  # è³£å‡º
    
    # ç§»é™¤æœªä¾†æ•¸æ“š
    labels = labels[:-lag] if lag > 0 else labels
    
    # çµ±è¨ˆä¿¡æ¯
    label_counts = labels.value_counts()
    total = len(labels)
    distribution = {k: v/total for k, v in label_counts.items()}
    
    print(f"ä¿®å¾©ç‰ˆæ¨™ç±¤åˆ†ä½ˆ: {distribution}")
    print(f"æ»¾å‹•çª—å£: {lookback_window}, lag: {lag}")
    
    return labels.dropna().astype(int)


# ä¿®å¾©ç‰ˆç‰¹å¾µé¸æ“‡ - åµŒå¥—äº¤å‰é©—è­‰

def objective_fixed(self, trial):
    """
    ä¿®å¾©ç‰ˆç›®æ¨™å‡½æ•¸ - åµŒå¥—äº¤å‰é©—è­‰é¿å…æ•¸æ“šæ´©éœ²
    """
    # åƒæ•¸
    lag = trial.suggest_int('lag', 8, 24)
    profit_quantile = trial.suggest_float('profit_quantile', 0.75, 0.90)
    loss_quantile = trial.suggest_float('loss_quantile', 0.10, 0.25)
    lookback_window = trial.suggest_int('lookback_window', 300, 800)
    
    # ä¿®å¾©ç‰ˆæ¨™ç±¤ç”Ÿæˆ
    labels = self._generate_labels_fixed(
        self.ohlcv_data['close'],
        lag=lag,
        profit_quantile=profit_quantile,
        loss_quantile=loss_quantile,
        lookback_window=lookback_window
    )
    
    # æ•¸æ“šå°é½Š
    common_idx = self.features.index.intersection(labels.index)
    X = self.features.loc[common_idx].fillna(0)
    y = labels.loc[common_idx]
    
    if len(X) < 1000:
        return 0.0
    
    # ğŸš€ åµŒå¥—äº¤å‰é©—è­‰ - åœ¨æ¯å€‹foldå…§éƒ¨é€²è¡Œç‰¹å¾µé¸æ“‡
    outer_cv = TimeSeriesSplit(n_splits=3)
    cv_scores = []
    
    for train_idx, test_idx in outer_cv.split(X):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx] 
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
        
        # å…§éƒ¨ç‰¹å¾µé¸æ“‡ï¼ˆåªåœ¨è¨“ç·´é›†ä¸Šï¼‰
        n_features = len(X_train.columns)
        coarse_k = trial.suggest_int('coarse_k', int(n_features * 0.2), int(n_features * 0.6))
        fine_k = trial.suggest_int('fine_k', 10, min(30, coarse_k // 2))
        
        # æ–¹å·®ç¯©é¸
        var_selector = VarianceThreshold(threshold=0.01)
        X_train_var = var_selector.fit_transform(X_train)
        X_test_var = var_selector.transform(X_test)
        
        if X_train_var.shape[1] == 0:
            cv_scores.append(0.0)
            continue
        
        # çµ±è¨ˆé¡¯è‘—æ€§é¸æ“‡ï¼ˆåªåœ¨è¨“ç·´é›†ä¸Šfitï¼‰
        coarse_k = min(coarse_k, X_train_var.shape[1])
        coarse_selector = SelectKBest(f_classif, k=coarse_k)
        X_train_coarse = coarse_selector.fit_transform(X_train_var, y_train)
        X_test_coarse = coarse_selector.transform(X_test_var)
        
        # äº’ä¿¡æ¯é¸æ“‡
        fine_k = min(fine_k, X_train_coarse.shape[1])
        fine_selector = SelectKBest(mutual_info_classif, k=fine_k)
        X_train_final = fine_selector.fit_transform(X_train_coarse, y_train)
        X_test_final = fine_selector.transform(X_test_coarse)
        
        # æ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°
        model = RandomForestClassifier(n_estimators=50, max_depth=8, random_state=42, n_jobs=-1)
        model.fit(X_train_final, y_train)
        y_pred = model.predict(X_test_final)
        
        # F1åˆ†æ•¸
        fold_score = f1_score(y_test, y_pred, average='weighted')
        cv_scores.append(fold_score)
    
    final_score = np.mean(cv_scores)
    
    # æª¢æŸ¥åˆ†æ•¸åˆç†æ€§
    if final_score > 0.8:  # å¯ç–‘çš„é«˜åˆ†æ•¸
        print(f"âš ï¸ å¯ç–‘é«˜åˆ†æ•¸ {final_score:.4f}ï¼Œè«‹æª¢æŸ¥æ•¸æ“šæ´©éœ²")
        
    return final_score