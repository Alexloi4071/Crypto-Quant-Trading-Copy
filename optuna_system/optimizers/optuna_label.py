# -*- coding: utf-8 -*-
"""
æ¨™ç±¤ç”Ÿæˆåƒæ•¸å„ªåŒ–å™¨ (ç¬¬1å±¤)
åŸºæ–¼ä¸»ç³»çµ±çš„label_optimizeré‡æ–°å¯¦ç¾
"""
import json
import logging
import warnings
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any

import numpy as np
import optuna
import pandas as pd

from optuna_system.utils.io_utils import write_dataframe, read_dataframe

warnings.filterwarnings('ignore')


class LabelOptimizer:
    """æ¨™ç±¤ç”Ÿæˆåƒæ•¸å„ªåŒ–å™¨ - ç¬¬1å±¤å„ªåŒ–"""

    def __init__(self, data_path: str, config_path: str = "configs/",
                 symbol: str = "BTCUSDT", timeframe: str = "15m", scaled_config: Dict = None):
        self.data_path = Path(data_path)
        self.config_path = Path(config_path)
        self.config_path.mkdir(exist_ok=True)
        self.symbol = symbol
        self.timeframe = timeframe

        # æ™‚é–“æ¡†æ¶ç¸®æ”¾é…ç½®ï¼ˆæ–‡æª”è¨­è¨ˆï¼‰
        self.scaled_config = scaled_config or {}

        # ä½¿ç”¨é›†ä¸­æ—¥èªŒ (ç”±ä¸Šå±¤/å…¥å£åˆå§‹åŒ–)ï¼Œé¿å…é‡è¤‡ basicConfig
        self.logger = logging.getLogger(__name__)

    def generate_labels(self, price_data: pd.Series, params: Dict) -> pd.Series:
        """âœ… å®Œå…¨ä¿®å¾©ç‰ˆæ¨™ç±¤ç”Ÿæˆ - æ»¾å‹•çª—å£åˆ†ä½æ•¸ï¼Œåš´æ ¼é¿å…æœªä¾†æ•¸æ“šæ´©éœ²"""
        try:
            lag = params['lag']
            threshold_method = params.get('threshold_method', 'quantile')
            lookback_window = params.get('lookback_window', 500)  # æ»¾å‹•çª—å£å¤§å°

            if len(price_data) <= lag:
                return pd.Series([], dtype=int)

            # âœ… è¨ˆç®—æœªä¾†æ”¶ç›Šç‡ï¼ˆé€™æ˜¯æˆ‘å€‘è¦é æ¸¬çš„ç›®æ¨™ï¼‰
            future_prices = price_data.shift(-lag)
            future_returns = (future_prices - price_data) / price_data

            # åˆå§‹åŒ–æ¨™ç±¤
            labels = pd.Series(1, index=price_data.index, dtype=int)  # é»˜èªæŒæœ‰

            # æ ¹æ“šæ–¹æ³•ç¢ºå®šé–¾å€¼
            if threshold_method == 'quantile':
                # ğŸš€ ä½¿ç”¨ç¨ç«‹çš„è²·å…¥/è³£å‡ºåˆ†ä½æ•¸
                buy_quantile = params.get('buy_quantile', 0.75)
                sell_quantile = params.get('sell_quantile', 0.25)

                # âœ… é—œéµä¿®å¾©ï¼šä½¿ç”¨"æ­·å²çš„æœªä¾†æ”¶ç›Šç‡"è¨ˆç®—é–¾å€¼
                # é€™æ¨£é˜ˆå€¼å’Œç›®æ¨™è®Šé‡çš„åˆ†å¸ƒæ˜¯ä¸€è‡´çš„
                historical_future_returns = future_returns.shift(1)  # å‘å‰åç§»ï¼Œåªç”¨æ­·å²
                
                # âœ… åŸºæ–¼æ­·å²æœªä¾†æ”¶ç›Šç‡è¨ˆç®—æ»¾å‹•åˆ†ä½æ•¸
                rolling_upper = historical_future_returns.rolling(
                    window=lookback_window, 
                    min_periods=100
                ).quantile(buy_quantile)
                
                rolling_lower = historical_future_returns.rolling(
                    window=lookback_window, 
                    min_periods=100
                ).quantile(sell_quantile)
                
                # ç¢ºä¿é–¾å€¼åˆç†ä¸”æœ‰é–“éš”
                rolling_upper = rolling_upper.fillna(0.0001).clip(lower=0.0001)
                rolling_lower = rolling_lower.fillna(-0.0001).clip(upper=-0.0001)
                
                # ç¢ºä¿è²·è³£é–¾å€¼æœ‰è¶³å¤ é–“éš”ï¼Œé¿å…é‡ç–Š
                gap_needed = (rolling_upper + abs(rolling_lower)) * 0.1
                gap_needed = gap_needed.clip(lower=0.0005)
                
                # èª¿æ•´é‡ç–Šçš„é–¾å€¼
                overlap_mask = rolling_upper <= abs(rolling_lower)
                rolling_upper[overlap_mask] = rolling_upper[overlap_mask].clip(lower=gap_needed[overlap_mask])
                rolling_lower[overlap_mask] = rolling_lower[overlap_mask].clip(upper=-gap_needed[overlap_mask])

                # âœ… å‘é‡åŒ–æ¨™ç±¤åˆ†é…ï¼ˆé¡å‹ä¸€è‡´ï¼šéƒ½æ˜¯æœªä¾†æ”¶ç›Šç‡ï¼‰
                valid_range = slice(lookback_window, len(future_returns) - lag)
                labels.iloc[valid_range] = 1  # é‡ç½®ç‚ºæŒæœ‰
                
                # è²·å…¥ä¿¡è™Ÿ
                buy_mask = (future_returns.iloc[valid_range] > rolling_upper.iloc[valid_range]) & rolling_upper.iloc[valid_range].notna()
                labels.iloc[valid_range] = labels.iloc[valid_range].where(~buy_mask, 2)
                
                # è³£å‡ºä¿¡è™Ÿ  
                sell_mask = (future_returns.iloc[valid_range] < rolling_lower.iloc[valid_range]) & rolling_lower.iloc[valid_range].notna()
                labels.iloc[valid_range] = labels.iloc[valid_range].where(~sell_mask, 0)

            elif threshold_method == 'fixed':
                # å›ºå®šé–¾å€¼æ–¹æ³•
                profit_threshold = params.get('profit_threshold', 0.01)
                loss_threshold = params.get('loss_threshold', -0.01)

                # æ‡‰ç”¨å›ºå®šé–¾å€¼
                labels[future_returns > profit_threshold] = 2  # è²·å…¥
                labels[future_returns < loss_threshold] = 0   # è³£å‡º

            elif threshold_method == 'adaptive':
                # âœ… ä¿®å¾©ï¼šè‡ªé©æ‡‰é–¾å€¼ä¹ŸåŸºæ–¼æœªä¾†æ”¶ç›Šç‡
                vol_multiplier = params.get('vol_multiplier', 1.5)
                vol_window = int(params.get('vol_window', min(lookback_window, 40)))

                # âœ… ä½¿ç”¨æ­·å²æœªä¾†æ”¶ç›Šç‡è¨ˆç®—æ³¢å‹•ç‡
                historical_future_returns = future_returns.shift(1)
                rolling_volatility = historical_future_returns.rolling(
                    window=vol_window, 
                    min_periods=20
                ).std()
                
                # åŸºæ–¼æ³¢å‹•ç‡çš„å‹•æ…‹é–¾å€¼
                rolling_profit_threshold = rolling_volatility * vol_multiplier
                rolling_loss_threshold = -rolling_volatility * vol_multiplier
                
                # å¡«è£œç„¡æ•ˆå€¼
                rolling_profit_threshold = rolling_profit_threshold.fillna(0.01)
                rolling_loss_threshold = rolling_loss_threshold.fillna(-0.01)
                
                # âœ… å‘é‡åŒ–æ¨™ç±¤åˆ†é…ï¼ˆé¡å‹ä¸€è‡´ï¼‰
                valid_range = slice(vol_window, len(future_returns) - lag)
                labels.iloc[valid_range] = 1  # é‡ç½®ç‚ºæŒæœ‰
                
                # è²·å…¥ä¿¡è™Ÿ
                buy_mask = future_returns.iloc[valid_range] > rolling_profit_threshold.iloc[valid_range]
                labels.iloc[valid_range] = labels.iloc[valid_range].where(~buy_mask, 2)
                
                # è³£å‡ºä¿¡è™Ÿ
                sell_mask = future_returns.iloc[valid_range] < rolling_loss_threshold.iloc[valid_range]
                labels.iloc[valid_range] = labels.iloc[valid_range].where(~sell_mask, 0)
            else:
                # é»˜èªå›ºå®šé–¾å€¼
                profit_threshold = 0.01
                loss_threshold = -0.01
                labels[future_returns > profit_threshold] = 2
                labels[future_returns < loss_threshold] = 0

            # ç§»é™¤æœªä¾†æ•¸æ“šæ´©éœ²
            labels = labels[:-lag] if lag > 0 else labels

            # è¨ˆç®—ä¸¦æ‰“å°æ¨™ç±¤çµ±è¨ˆ
            self._print_label_statistics(labels, params)

            return labels.dropna()

        except Exception as e:
            self.logger.error(f"æ¨™ç±¤ç”Ÿæˆå¤±æ•—: {e}")
            return pd.Series([], dtype=int)

    def stabilized_label_generation(self, price_data: pd.Series, params: Dict) -> pd.Series:
        """ç©©å®šåŒ–æ¨™ç±¤ç”Ÿæˆï¼šå›ºå®šæ­·å²åˆ†ä½æ•¸ + ä¿¡è™Ÿé©—è­‰"""
        try:
            lag = params['lag']
            fixed_lookback = int(params.get('fixed_lookback', 2000))

            if len(price_data) <= max(lag, fixed_lookback):
                return self.generate_labels(price_data, params)

            future_returns = (price_data.shift(-lag) - price_data) / price_data

            historical_returns = future_returns.iloc[:fixed_lookback].dropna()
            if len(historical_returns) < 200:
                return self.generate_labels(price_data, params)

            buy_quantile = float(params.get('buy_quantile', 0.75))
            sell_quantile = float(params.get('sell_quantile', 0.25))

            buy_threshold = historical_returns.quantile(buy_quantile)
            sell_threshold = historical_returns.quantile(sell_quantile)

            min_gap = float(params.get('min_threshold_gap', 0.005))
            if buy_threshold - abs(sell_threshold) < min_gap:
                buy_threshold = abs(sell_threshold) + min_gap

            labels = pd.Series(1, index=price_data.index, dtype=int)
            valid_end = len(price_data) - lag
            valid_start = fixed_lookback
            if valid_start >= valid_end:
                return self.generate_labels(price_data, params)

            valid_slice = slice(valid_start, valid_end)
            returns_slice = future_returns.iloc[valid_slice]

            labels.iloc[valid_slice] = labels.iloc[valid_slice].where(~(returns_slice >= buy_threshold), 2)
            labels.iloc[valid_slice] = labels.iloc[valid_slice].where(~(returns_slice <= sell_threshold), 0)

            signal_stats = self.validate_signal_authenticity(price_data, labels, lag)
            max_noise_ratio = float(params.get('max_noise_ratio', 0.35))

            if signal_stats['noise_ratio'] > max_noise_ratio:
                self.logger.warning(
                    f"âš ï¸ ä¿¡è™Ÿå™ªè²éé«˜({signal_stats['noise_ratio']:.2f} > {max_noise_ratio:.2f})ï¼Œä½¿ç”¨ä¿å®ˆæ¨™ç±¤"
                )
                labels = self.generate_conservative_labels(price_data, params)

            if lag > 0:
                labels = labels[:-lag]

            self._print_label_statistics(labels, params)
            return labels.dropna()

        except Exception as e:
            self.logger.error(f"ç©©å®šåŒ–æ¨™ç±¤ç”Ÿæˆå¤±æ•—: {e}")
            return self.generate_labels(price_data, params)

    def generate_conservative_labels(self, price_data: pd.Series, params: Dict) -> pd.Series:
        """ç”Ÿæˆæ›´ä¿å®ˆçš„æ¨™ç±¤ï¼ˆæé«˜è²·å…¥é–€æª»/é™ä½è³£å‡ºé–€æª»ï¼‰"""
        conservative_shift = float(params.get('conservative_shift', 0.005))
        fallback_params = params.copy()
        fallback_params['buy_quantile'] = min(0.95, fallback_params.get('buy_quantile', 0.75) + 0.05)
        fallback_params['sell_quantile'] = max(0.05, fallback_params.get('sell_quantile', 0.25) - 0.05)
        fallback_params['profit_threshold'] = fallback_params.get('profit_threshold', 0.02) + conservative_shift
        fallback_params['loss_threshold'] = fallback_params.get('loss_threshold', -0.02) - conservative_shift
        return self.generate_labels(price_data, fallback_params)

    def validate_signal_authenticity(self, prices: pd.Series, labels: pd.Series, lag: int) -> Dict:
        """ä¿¡è™ŸçœŸå¯¦æ€§é©—è­‰ï¼šçµ±è¨ˆä¿¡è™Ÿå¾Œçš„å¯¦éš›èµ°å‹¢"""
        try:
            buy_mask = labels == 2
            sell_mask = labels == 0

            future_prices = prices.shift(-lag)
            buy_accuracy = (
                (future_prices[buy_mask] > prices[buy_mask]).mean()
                if buy_mask.sum() > 0 else 0
            )
            sell_accuracy = (
                (future_prices[sell_mask] < prices[sell_mask]).mean()
                if sell_mask.sum() > 0 else 0
            )

            total_signals = buy_mask.sum() + sell_mask.sum()
            total_accuracy = (
                (buy_accuracy * buy_mask.sum() + sell_accuracy * sell_mask.sum()) / total_signals
                if total_signals > 0 else 0
            )
            noise_ratio = 1 - total_accuracy

            quality = 'high'
            if noise_ratio >= 0.4:
                quality = 'low'
            elif noise_ratio >= 0.2:
                quality = 'medium'

            return {
                'buy_accuracy': float(buy_accuracy),
                'sell_accuracy': float(sell_accuracy),
                'noise_ratio': float(noise_ratio),
                'signal_quality': quality
            }

        except Exception as e:
            self.logger.warning(f"ä¿¡è™ŸçœŸå¯¦æ€§é©—è­‰å¤±æ•—: {e}")
            return {'buy_accuracy': 0, 'sell_accuracy': 0, 'noise_ratio': 1.0, 'signal_quality': 'unknown'}
    
    def calculate_atr(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:
        """è¨ˆç®—å¹³å‡çœŸå¯¦å€é–“ï¼ˆATRï¼‰"""
        try:
            tr1 = high - low
            tr2 = abs(high - close.shift(1))
            tr3 = abs(low - close.shift(1))
            
            tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
            atr = tr.rolling(period).mean()
            
            return atr
        except Exception as e:
            self.logger.error(f"ATRè¨ˆç®—å¤±æ•—: {e}")
            return pd.Series(0, index=close.index)
    
    def generate_triple_barrier_labels(self, price_data: pd.Series, params: Dict) -> pd.Series:
        """âœ… ä¿®å¾©ç‰ˆTriple-Barrieræ¨™ç±¤ç”Ÿæˆ - ä½¿ç”¨ATRå‹•æ…‹é–¾å€¼"""
        try:
            lag = params.get('lag', 12)
            profit_multiplier = params.get('profit_multiplier', 2.0)  # ATRå€æ•¸ï¼ˆæ­¢ç›ˆï¼‰
            stop_multiplier = params.get('stop_multiplier', 1.0)      # ATRå€æ•¸ï¼ˆæ­¢æï¼‰
            max_holding = params.get('max_holding', 16)               # æœ€å¤§æŒæœ‰æœŸ
            atr_period = params.get('atr_period', 14)                 # ATRé€±æœŸ

            if len(price_data) <= max_holding:
                return pd.Series([], dtype=int)
            
            # âœ… è¨ˆç®—ATRï¼ˆéœ€è¦OHLCVæ•¸æ“šï¼‰
            try:
                ohlcv_file = self.data_path / "raw" / self.symbol / f"{self.symbol}_{self.timeframe}_ohlcv.parquet"
                if ohlcv_file.exists():
                    ohlcv_df = pd.read_parquet(ohlcv_file)
                    atr = self.calculate_atr(ohlcv_df['high'], ohlcv_df['low'], ohlcv_df['close'], atr_period)
                    # âœ… ä¿®å¾©ï¼šå°é½Šåˆ°price_dataçš„ç´¢å¼•ï¼Œåªç”¨å‰å‘å¡«å……é¿å…æ•¸æ“šæ³„æ¼
                    atr = atr.reindex(price_data.index).fillna(method='ffill')
                    # è™•ç†å‰©é¤˜çš„NaNï¼ˆé€šå¸¸æ˜¯é–‹é ­çš„ATRé€±æœŸå…§ï¼‰
                    if atr.isna().any():
                        first_valid_idx = atr.first_valid_index()
                        if first_valid_idx is not None:
                            first_valid_value = atr[first_valid_idx]
                            atr = atr.fillna(first_valid_value)
                            self.logger.info(f"âœ… ATRå‰å‘å¡«å……å®Œæˆï¼Œç”¨ç¬¬ä¸€å€‹æœ‰æ•ˆå€¼({first_valid_value:.4f})å¡«å……å‰æœŸNaN")
                        else:
                            atr = atr.fillna(0.01)
                            self.logger.warning("âš ï¸ ATRç„¡æœ‰æ•ˆå€¼ï¼Œä½¿ç”¨é»˜èªå€¼0.01")
                else:
                    # å¦‚æœæ²’æœ‰OHLCVï¼Œä½¿ç”¨ç°¡åŒ–çš„ATRä¼°ç®—
                    returns = price_data.pct_change().abs()
                    atr = returns.rolling(atr_period).mean() * price_data
                    self.logger.warning("âš ï¸ æœªæ‰¾åˆ°OHLCVæ•¸æ“šï¼Œä½¿ç”¨ç°¡åŒ–ATRä¼°ç®—")
            except Exception as e:
                self.logger.warning(f"âš ï¸ ATRè¨ˆç®—å¤±æ•—: {e}ï¼Œä½¿ç”¨ç°¡åŒ–æ–¹æ³•")
                returns = price_data.pct_change().abs()
                atr = returns.rolling(atr_period).mean() * price_data

            labels = pd.Series(1, index=price_data.index, dtype=int)  # é»˜èªæŒæœ‰
            
            for i in range(len(price_data) - max_holding):
                entry_price = price_data.iloc[i]
                current_atr = atr.iloc[i]
                
                if pd.isna(current_atr) or current_atr <= 0:
                    continue
                
                # âœ… å‹•æ…‹æ­¢ç›ˆæ­¢æåŸºæ–¼ATR
                profit_target_price = entry_price + current_atr * profit_multiplier
                stop_loss_price = entry_price - current_atr * stop_multiplier
                
                # âœ… ç¢ºä¿é¢¨éšªæ”¶ç›Šæ¯” â‰¥ 2:1
                actual_profit_distance = profit_target_price - entry_price
                actual_stop_distance = entry_price - stop_loss_price
                
                if actual_stop_distance > 0 and actual_profit_distance / actual_stop_distance < 2.0:
                    # èª¿æ•´æ­¢æä»¥é”åˆ°2:1æ¯”ä¾‹
                    stop_loss_price = entry_price - (actual_profit_distance / 2.0)
                
                # å®šç¾©æœªä¾†åƒ¹æ ¼çª—å£
                future_window = price_data.iloc[i+1:i+max_holding+1]
                
                if len(future_window) == 0:
                    continue
                
                # æª¢æŸ¥ä¸‰é‡éšœç¤™è§¸ç™¼æ¢ä»¶
                hit_profit = (future_window >= profit_target_price).any()
                hit_stop = (future_window <= stop_loss_price).any()
                
                if hit_profit and hit_stop:
                    # éƒ½è§¸ç™¼ï¼Œçœ‹å“ªå€‹å…ˆç™¼ç”Ÿ
                    profit_idx = future_window[future_window >= profit_target_price].index[0]
                    stop_idx = future_window[future_window <= stop_loss_price].index[0]
                    
                    if price_data.index.get_loc(profit_idx) < price_data.index.get_loc(stop_idx):
                        labels.iloc[i] = 2  # è²·å…¥ï¼ˆå…ˆè§¸ç™¼æ­¢ç›ˆï¼‰
                    else:
                        labels.iloc[i] = 0  # è³£å‡ºï¼ˆå…ˆè§¸ç™¼æ­¢æï¼‰
                elif hit_profit:
                    labels.iloc[i] = 2  # è²·å…¥
                elif hit_stop:
                    labels.iloc[i] = 0  # è³£å‡º
                # å¦å‰‡ä¿æŒæŒæœ‰
                
            # ç§»é™¤å¯èƒ½çš„æœªä¾†æ•¸æ“šæ´©éœ²
            if lag > 0:
                labels = labels[:-lag]
            
            self.logger.info(f"âœ… Triple-Barrieræ¨™ç±¤: æ­¢ç›ˆ={profit_multiplier}Ã—ATR, "
                           f"æ­¢æ={stop_multiplier}Ã—ATR, æœ€å¤§æŒæœ‰={max_holding}æœŸ, "
                           f"ATRé€±æœŸ={atr_period}, é¢¨éšªæ”¶ç›Šæ¯”â‰¥2:1")
            
            return labels.dropna()
            
        except Exception as e:
            self.logger.error(f"Triple-Barrieræ¨™ç±¤ç”Ÿæˆå¤±æ•—: {e}")
            return pd.Series([], dtype=int)

    def _print_label_statistics(self, labels: pd.Series, params: Dict) -> None:
        """ğŸš€ æ–°å¢ï¼šè¨ˆç®—ä¸¦æ‰“å°æ¨™ç±¤åˆ†ä½ˆçµ±è¨ˆèˆ‡è³ªé‡æŒ‡æ¨™"""
        try:
            if len(labels) == 0:
                self.logger.warning("ç©ºæ¨™ç±¤åºåˆ—ï¼Œç„¡æ³•è¨ˆç®—çµ±è¨ˆ")
                return

            # æ¨™ç±¤åˆ†ä½ˆçµ±è¨ˆ
            label_counts = labels.value_counts().sort_index()
            total_samples = len(labels)

            self.logger.info(f"ğŸ“Š ä¿®å¾©ç‰ˆæ¨™ç±¤åˆ†ä½ˆçµ±è¨ˆ:")
            self.logger.info(f"   ç¸½æ¨£æœ¬æ•¸: {total_samples}")
            self.logger.info(f"   æ»¾å‹•çª—å£: {params.get('lookback_window', 500)}")
            self.logger.info(f"   lag: {params.get('lag', 12)}æœŸ")

            # å„é¡åˆ¥çµ±è¨ˆ
            for label_val in [0, 1, 2]:
                count = label_counts.get(label_val, 0)
                percentage = (count / total_samples) * 100
                label_name = {0: 'è³£å‡º', 1: 'æŒæœ‰', 2: 'è²·å…¥'}[label_val]
                self.logger.info(f"   {label_name}({label_val}): {count:,} ({percentage:.2f}%)")

            # æ¨™ç±¤è®ŠåŒ–é »ç‡
            if len(labels) > 1:
                changes = (labels.diff() != 0).sum()
                change_rate = changes / len(labels)
                self.logger.info(f"   æ¨™ç±¤è®ŠåŒ–é »ç‡: {change_rate:.3f} ({changes:,}/{total_samples:,})")

            # æª¢æŸ¥æ¨™ç±¤å¹³è¡¡æ€§
            min_class_ratio = min(label_counts) / total_samples
            max_class_ratio = max(label_counts) / total_samples
            imbalance_ratio = max_class_ratio / min_class_ratio

            if imbalance_ratio > 10:
                self.logger.warning(f"âš ï¸ æ¨™ç±¤åš´é‡ä¸å¹³è¡¡: æœ€å¤§/æœ€å°é¡åˆ¥æ¯”ä¾‹ = {imbalance_ratio:.2f}")
            elif imbalance_ratio > 5:
                self.logger.warning(f"âš ï¸ æ¨™ç±¤è¼•åº¦ä¸å¹³è¡¡: æœ€å¤§/æœ€å°é¡åˆ¥æ¯”ä¾‹ = {imbalance_ratio:.2f}")
            else:
                self.logger.info(f"âœ… æ¨™ç±¤å¹³è¡¡æ€§è‰¯å¥½: æœ€å¤§/æœ€å°é¡åˆ¥æ¯”ä¾‹ = {imbalance_ratio:.2f}")

            # æª¢æŸ¥å„é¡åˆ¥æ˜¯å¦éƒ½æœ‰ä»£è¡¨æ¨£æœ¬
            missing_classes = []
            for class_val in [0, 1, 2]:
                if label_counts.get(class_val, 0) == 0:
                    missing_classes.append(class_val)

            if missing_classes:
                class_names = [['è³£å‡º', 'æŒæœ‰', 'è²·å…¥'][i] for i in missing_classes]
                self.logger.error(f"âŒ ç¼ºå¤±é¡åˆ¥: {missing_classes} ({class_names})")
            else:
                self.logger.info("âœ… æ‰€æœ‰é¡åˆ¥éƒ½æœ‰ä»£è¡¨æ¨£æœ¬")

        except Exception as e:
            self.logger.error(f"æ¨™ç±¤çµ±è¨ˆè¨ˆç®—å¤±æ•—: {e}")

    def calculate_label_quality(self, labels: pd.Series, params: Dict) -> Dict:
        """è¨ˆç®—æ¨™ç±¤è³ªé‡æŒ‡æ¨™ï¼ˆå« Precision / Recall / F1 çš„ä»£ç†è©•åˆ†ï¼‰"""
        try:
            if len(labels) == 0:
                return {
                    'balance_score': 0,
                    'stability_score': 0,
                    'f1_score': 0,
                    'precision_macro': 0,
                    'recall_macro': 0
                }

            # 1) åˆ†å¸ƒå¹³è¡¡ï¼ˆè¶Šæ¥è¿‘ç†æƒ³ 25/50/25 è¶Šå¥½ï¼‰
            value_counts = labels.value_counts(normalize=True)
            target_dist = np.array([0.25, 0.5, 0.25])
            actual_dist = np.array([
                value_counts.get(0, 0.0),
                value_counts.get(1, 0.0),
                value_counts.get(2, 0.0)
            ])
            kl_div = np.sum(target_dist * np.log((target_dist + 1e-8) / (actual_dist + 1e-8)))
            balance_score = float(np.exp(-kl_div))

            # 2) ç©©å®šæ€§ï¼šæ¨™ç±¤åˆ‡æ›ç‡è¶Šä½è¶Šç©©å®š
            label_changes = int((labels.diff() != 0).sum())
            stability_score = float(max(0.0, 1.0 - label_changes / max(len(labels), 1)))

            # 3) æº–ç¢ºæ€§ä»£ç†ï¼šç”¨ã€Œé¡åˆ¥è¦†è“‹ç‡ã€è¿‘ä¼¼ precision/recall
            # æ²’æœ‰é æ¸¬å™¨ï¼Œæ¡ç”¨ä¿å®ˆä»£ç†ï¼šè‹¥æŸé¡åš´é‡ç¨€å°‘ï¼Œprecision/recall éƒ½æœƒå—é™
            class_presence = (actual_dist > 0).astype(float)
            precision_macro = float(class_presence.mean())  # è¦†è“‹è¶Šå…¨è¶Šé«˜
            recall_macro = float(1.0 - abs(actual_dist - target_dist).mean() / max(target_dist.max(), 1e-8))
            # ä»£ç† F1
            if precision_macro + recall_macro > 0:
                f1_macro = float(2 * precision_macro * recall_macro / (precision_macro + recall_macro))
            else:
                f1_macro = 0.0

            return {
                'balance_score': balance_score,
                'stability_score': stability_score,
                'f1_score': f1_macro,
                'precision_macro': precision_macro,
                'recall_macro': recall_macro,
                'distribution': actual_dist.tolist(),
                'total_samples': int(len(labels))
            }

        except Exception as e:
            self.logger.error(f"æ¨™ç±¤è³ªé‡è¨ˆç®—å¤±æ•—: {e}")
            return {
                'balance_score': 0,
                'stability_score': 0,
                'f1_score': 0,
                'precision_macro': 0,
                'recall_macro': 0
            }

    def objective(self, trial: optuna.Trial) -> float:
        """ä¿®å¾©ç‰ˆOptunaç›®æ¨™å‡½æ•¸ - ç¬¬1å±¤ï¼šæ»¾å‹•çª—å£æ¨™ç±¤åƒæ•¸å„ªåŒ–"""

        # ğŸš€ ä¿®å¾©ç‰ˆåƒæ•¸ï¼šåŒ…å«æ»¾å‹•çª—å£å¤§å°
        params = {
            # æ ¸å¿ƒåƒæ•¸
            'lag': trial.suggest_int('lag',
                                     self.scaled_config.get('label_lag_min', self.scaled_config.get('label_lag', 12) - 2),
                                     self.scaled_config.get('label_lag_max', self.scaled_config.get('label_lag', 12) + 4)),
            'threshold_method': trial.suggest_categorical('threshold_method',
                                                        ['quantile', 'fixed', 'adaptive', 'triple_barrier', 'stabilized']),

            # ğŸš€ æ–°å¢ï¼šæ»¾å‹•çª—å£å¤§å° (500-800)
            'lookback_window': trial.suggest_int('lookback_window', 500, 800),

            # âœ… ä¿®å¾©å„ªåŒ–ï¼šåŸºæ–¼å­¸è¡“æ–‡ç»çš„åˆ†ä½æ•¸ç¯„åœï¼ˆæ›´ä¿å®ˆï¼Œä¿¡è™Ÿè³ªé‡æ›´é«˜ï¼‰
            'buy_quantile': trial.suggest_float('buy_quantile', 0.70, 0.85),   # å­¸è¡“æ¨è–¦ï¼š70-85%åˆ†ä½
            'sell_quantile': trial.suggest_float('sell_quantile', 0.15, 0.30), # å­¸è¡“æ¨è–¦ï¼š15-30%åˆ†ä½

            # Fixedæ–¹æ³•åƒæ•¸
            'profit_threshold': trial.suggest_float('profit_threshold', 0.005, 0.03),
            'loss_threshold': trial.suggest_float('loss_threshold', -0.03, -0.005),

            # Adaptiveæ–¹æ³•åƒæ•¸
            'vol_multiplier': trial.suggest_float('vol_multiplier', 1.2, 2.0),
            # é¡å¤–é¡¯å¼æ§åˆ¶è‡ªé©æ‡‰æ³¢å‹•çª—å£ï¼Œä¿ƒé€²æ›´å¯†é›†è¨Šè™Ÿ
            'vol_window': trial.suggest_int('vol_window', 20, 40),
            
            # âœ… ä¿®å¾©ï¼šTriple-Barrieræ–¹æ³•åƒæ•¸ï¼ˆATRå€æ•¸ï¼Œå‹•æ…‹èª¿æ•´ï¼‰
            'profit_multiplier': trial.suggest_float('profit_multiplier', 1.6, 3.0),  # æ­¢ç›ˆï¼šâ‰¥1.6å€ATR
            'stop_multiplier': trial.suggest_float('stop_multiplier', 0.6, 1.4),      # æ­¢æï¼šâ‰¤1.4å€ATR
            'max_holding': trial.suggest_int('max_holding', 16, 24),                  # æœ€å¤§æŒæœ‰ï¼š16-24æœŸï¼ˆ4-6å°æ™‚ï¼‰
            'atr_period': trial.suggest_int('atr_period', 10, 20),                    # ATRé€±æœŸï¼š10-20

            # è³ªé‡æ§åˆ¶åƒæ•¸
            'min_samples': trial.suggest_int('min_samples', 1000, 5000),  # æé«˜æœ€å°æ¨£æœ¬è¦æ±‚
            'balance_weight': trial.suggest_float('balance_weight', 0.3, 0.7),
            'stability_weight': trial.suggest_float('stability_weight', 0.2, 0.5),

            # ç©©å®šåŒ–æ¨™ç±¤åƒæ•¸
            'fixed_lookback': trial.suggest_int('fixed_lookback', 1500, 3000),
            'min_threshold_gap': trial.suggest_float('min_threshold_gap', 0.003, 0.01),
            'max_noise_ratio': trial.suggest_float('max_noise_ratio', 0.25, 0.4),
            
            # ğŸš€ æ–°å¢ï¼šæ¨™ç±¤åˆ†å¸ƒæ§åˆ¶åƒæ•¸
            'target_hold_ratio': trial.suggest_float('target_hold_ratio', 0.48, 0.52),  # æ”¶æ–‚æŒæœ‰æ¯”ä¾‹
            'distribution_penalty': trial.suggest_float('distribution_penalty', 0.8, 1.5)  # æº«å’Œåˆ†å¸ƒæ‡²ç½°
        }

        try:
            # ğŸ”§ ä¿®å¾©ç‰ˆï¼šæ˜ç¡®æ„é€ æ–‡ä»¶è·¯å¾„å¹¶æ·»åŠ è°ƒè¯•ä¿¡æ¯
            ohlcv_file = self.data_path / "raw" / self.symbol / f"{self.symbol}_{self.timeframe}_ohlcv.parquet"
            self.logger.info(f"ğŸ” æŸ¥æ‰¾OHLCVæ–‡ä»¶: {ohlcv_file.absolute()}")
            
            if not ohlcv_file.exists():
                alternative_paths = [
                    f"data/raw/{self.symbol}/{self.symbol}_{self.timeframe}_ohlcv.parquet",
                    f"../data/raw/{self.symbol}/{self.symbol}_{self.timeframe}_ohlcv.parquet",
                    f"./{self.symbol}_{self.timeframe}_ohlcv.parquet"
                ]

                df = None
                for alt_path in alternative_paths:
                    if Path(alt_path).exists():
                        self.logger.info(f"ğŸ” æ‰¾åˆ°æ›¿ä»£è·¯å¾„: {alt_path}")
                        df = pd.read_parquet(alt_path, engine='pyarrow')
                        break

                if df is None:
                    self.logger.error(f"âŒ æœªæ‰¾åˆ°OHLCVæ•¸æ“šæ–‡ä»¶: {ohlcv_file.absolute()}")
                    raise FileNotFoundError(f"æœªæ‰¾åˆ°åŸå§‹ OHLCV æ•¸æ“š: {ohlcv_file}")
                else:
                    self.logger.info(f"âœ… æˆåŠŸåŠ è¼‰OHLCVæ•¸æ“š: {df.shape}")
            else:
                df = pd.read_parquet(ohlcv_file, engine='pyarrow')
                self.logger.info(f"âœ… åŠ è¼‰OHLCVæ•¸æ“š: {df.shape}")

            # ç¢ºå®šåƒ¹æ ¼åˆ—
            price_data = df['close']

            # ğŸ”§ ä¿®å¤ï¼šä¸€æ¬¡æ€§é¢„è®¡ç®—å…¨é‡rollingåˆ†ä½æ•°ï¼Œé¿å…é‡å¤è®¡ç®—
            lag = params['lag']
            lookback_window = params['lookback_window']
            actual_profit = price_data.pct_change(lag).shift(-lag)
            
            # å‘é‡åŒ–æ»šåŠ¨åˆ†ä½æ•°è®¡ç®—ï¼ˆä¸€æ¬¡æ€§å®Œæˆï¼‰
            self.logger.info(f"ğŸš€ å¼€å§‹å‘é‡åŒ–åˆ†ä½æ•°è®¡ç®—: window={lookback_window}")
            buy_quantile = params['buy_quantile']
            sell_quantile = params['sell_quantile']
            
            # é¢„è®¡ç®—å…¨é‡æ»šåŠ¨åˆ†ä½æ•°
            rolling_upper = actual_profit.rolling(window=lookback_window, min_periods=100).quantile(buy_quantile)
            rolling_lower = actual_profit.rolling(window=lookback_window, min_periods=100).quantile(sell_quantile)
            
            # ç¼“å­˜åˆ°å®ä¾‹å˜é‡é¿å…é‡å¤è®¡ç®—
            self._cached_rolling_upper = rolling_upper
            self._cached_rolling_lower = rolling_lower
            self.logger.info(f"âœ… åˆ†ä½æ•°é¢„è®¡ç®—å®Œæˆï¼Œç¼“å­˜{len(rolling_upper)}ä¸ªç‚¹")

            # ğŸš€ é¢¨éšªæ¯”ç´„æŸï¼šå¼·åˆ¶ 2:1ï¼ˆæ­¢ç›ˆ >= 2 Ã— æ­¢æï¼‰
            if params.get('threshold_method') == 'triple_barrier':
                pm = float(params.get('profit_multiplier', 2.0))
                sm = float(params.get('stop_multiplier', 1.0))
                if pm < 2.0 * sm:
                    # å°‡æ­¢ç›ˆæŠ¬é«˜åˆ°è‡³å°‘2xæ­¢æ
                    adjusted_pm = max(2.0 * sm, pm)
                    self.logger.info(f"ğŸ”’ é¢¨éšªæ¯”ç´„æŸ: profit_multiplier {pm:.2f} â†’ {adjusted_pm:.2f} (stop={sm:.2f})")
                    params['profit_multiplier'] = adjusted_pm

            # ğŸš€ æ”¹é€²ï¼šæ ¹æ“šæ–¹æ³•é¸æ“‡æ¨™ç±¤ç”Ÿæˆç­–ç•¥
            threshold_method = params.get('threshold_method', 'quantile')
            if threshold_method == 'triple_barrier':
                labels = self.generate_triple_barrier_labels(price_data, params)
                self.logger.info("ğŸš§ ä½¿ç”¨Triple-Barrieræ¨™ç±¤ç”Ÿæˆæ–¹æ³•")
            elif threshold_method == 'stabilized':
                labels = self.stabilized_label_generation(price_data, params)
                self.logger.info("ğŸ“Š ä½¿ç”¨ç©©å®šåŒ–å›ºå®šåˆ†ä½æ¨™ç±¤ç”Ÿæˆæ–¹æ³•")
            else:
                labels = self.generate_labels(price_data, params)
                self.logger.info(f"ğŸ“Š ä½¿ç”¨{threshold_method}åˆ†ä½æ•¸æ¨™ç±¤ç”Ÿæˆæ–¹æ³•")

            if len(labels) < params['min_samples']:
                return -999.0  # æ¨£æœ¬ä¸è¶³

            # è¨ˆç®—æ¨™ç±¤è³ªé‡
            quality_metrics = self.calculate_label_quality(labels, params)

            # ğŸš€ æ”¹é€²ï¼šå¤šç›®æ¨™å„ªåŒ–å¾—åˆ† + åˆ†å¸ƒç´„æŸ
            balance_score = quality_metrics['balance_score']
            stability_score = quality_metrics['stability_score']
            f1_score = quality_metrics['f1_score']
            
            # è¨ˆç®—å¯¦éš›æ¨™ç±¤åˆ†å¸ƒ
            label_counts = labels.value_counts(normalize=True)
            actual_hold_ratio = label_counts.get(1, 0)  # æŒæœ‰æ¯”ä¾‹
            actual_buy_ratio = label_counts.get(2, 0)   # è²·å…¥æ¯”ä¾‹  
            actual_sell_ratio = label_counts.get(0, 0)  # è³£å‡ºæ¯”ä¾‹

            # ğŸš§ ç¡¬æ€§åˆ†ä½ˆç´„æŸï¼šéåº¦ä¸å¹³è¡¡çš„æ–¹æ¡ˆç›´æ¥æ·˜æ±°ï¼Œé¿å…æœç´¢é™·å…¥é•·æœŸæŒæœ‰
            if actual_hold_ratio > 0.70 or actual_buy_ratio < 0.10 or actual_sell_ratio < 0.10:
                self.logger.info(
                    f"â›” åˆ†ä½ˆä¸åˆæ ¼(hold>{actual_hold_ratio:.2%} æˆ– è²·/è³£<{min(actual_buy_ratio, actual_sell_ratio):.2%})ï¼Œé€€å›æ¥µä½åˆ†"
                )
                return -999.0
            
            # ğŸš€ æ–°å¢ï¼šåˆ†å¸ƒåå·®æ‡²ç½°
            target_hold = params['target_hold_ratio']
            hold_deviation = abs(actual_hold_ratio - target_hold)
            
            # ç¢ºä¿è²·è³£ä¿¡è™Ÿå‡è¡¡ï¼ˆå„è‡ªè‡³å°‘15%ï¼‰
            min_trade_ratio = 0.15
            buy_sell_penalty = 0
            if actual_buy_ratio < min_trade_ratio:
                buy_sell_penalty += (min_trade_ratio - actual_buy_ratio)
            if actual_sell_ratio < min_trade_ratio:
                buy_sell_penalty += (min_trade_ratio - actual_sell_ratio)
            # ä½è®ŠåŒ–ç‡æ‡²ç½°ï¼ˆé¼“å‹µé¿å…é•·æœŸæŒæœ‰å–®ä¸€é¡åˆ¥ï¼‰
            change_rate = float(((labels.diff() != 0).sum() / max(len(labels), 1)))
            low_change_penalty = max(0.0, 0.25 - change_rate)  # æœŸæœ›â‰¥0.25
            
            # åˆ†å¸ƒæ‡²ç½°ï¼ˆå¼·åŒ–ç‰ˆï¼‰ï¼šæŒæœ‰åå·® + è²·è³£ä¸è¶³ + ä½è®ŠåŒ–ç‡
            distribution_penalty = params['distribution_penalty'] * (hold_deviation + buy_sell_penalty + 0.5 * low_change_penalty)
            
            # ğŸš€ ä¿®å¾©ç‰ˆï¼šæ¬Šé‡æ­¸ä¸€åŒ–ï¼Œç¢ºä¿f1_scoreæ¬Šé‡ä¸ç‚ºè² 
            balance_weight = params['balance_weight']
            stability_weight = params['stability_weight']
            total_weight = balance_weight + stability_weight
            
            # ğŸ”§ ä¿®å¤ç‰ˆï¼šç¡®ä¿f1æƒé‡è‡³å°‘0.15ï¼ˆå¢åŠ å‡†ç¡®æ€§æƒé‡ï¼‰
            if total_weight > 0.85:  # ä»0.9æ”¹ä¸º0.85ï¼Œç»™f1æ›´å¤šæƒé‡
                scale_factor = 0.85 / total_weight
                balance_weight = balance_weight * scale_factor
                stability_weight = stability_weight * scale_factor
                self.logger.info(f"ğŸ”§ æƒé‡ç¼©æ”¾: åŸå§‹å’Œ={total_weight:.3f}, ç¼©æ”¾å› å­={scale_factor:.3f}")
            
            f1_weight = max(0.15, 1.0 - balance_weight - stability_weight)  # ä»0.1æ”¹ä¸º0.15
            
            # ğŸ”§ æ–°å¢ï¼šè®°å½•æƒé‡è°ƒæ•´è¿‡ç¨‹
            self.logger.info(f"âš–ï¸ æœ€ç»ˆæƒé‡: balance={balance_weight:.3f}, stability={stability_weight:.3f}, f1={f1_weight:.3f}")
            self.logger.info(f"ğŸ“Š åˆ†å¸ƒæƒ©ç½š: æŒæœ‰åå·®={hold_deviation:.3f}, ä¹°å–æƒ©ç½š={buy_sell_penalty:.3f}, æ€»æƒ©ç½š={distribution_penalty:.4f}")
            
            # å¤šç›®æ¨™åŠ æ¬Šç¸½åˆ†ï¼šæº–ç¢ºæ€§ + åˆ†å¸ƒåˆç†æ€§
            accuracy_component = (balance_score * balance_weight +
                                stability_score * stability_weight +
                                f1_score * f1_weight)
            
            # æœ€çµ‚åˆ†æ•¸ = æº–ç¢ºæ€§åˆ†æ•¸ - åˆ†å¸ƒæ‡²ç½°
            final_score = accuracy_component - distribution_penalty
            
            # è¨˜éŒ„åˆ†å¸ƒä¿¡æ¯
            self.logger.info(f"ğŸ“Š æ¨™ç±¤åˆ†å¸ƒ: è³£å‡º={actual_sell_ratio:.1%}, æŒæœ‰={actual_hold_ratio:.1%}, è²·å…¥={actual_buy_ratio:.1%}")
            self.logger.info(f"ğŸ¯ ç›®æ¨™æŒæœ‰ç‡={target_hold:.1%}, å¯¦éš›åå·®={hold_deviation:.3f}")
            self.logger.info(f"âš–ï¸ æ¬Šé‡: balance={balance_weight:.3f}, stability={stability_weight:.3f}, f1={f1_weight:.3f}")
            self.logger.info(f"âš–ï¸ æº–ç¢ºæ€§={accuracy_component:.4f}, åˆ†å¸ƒæ‡²ç½°={distribution_penalty:.4f}, æœ€çµ‚={final_score:.4f}")

            # ğŸ”§ æ–°å¢ï¼šè®¡ç®—æŒæœ‰ç‡è¯¯å·®å¹¶ä¼ é€’ç»™Layer2
            hold_error = abs(actual_hold_ratio - target_hold)
            
            # å°†æŒæœ‰ç‡è¯¯å·®å†™å…¥trial.user_attrsä¾›Layer2å‚è€ƒ
            trial.set_user_attr("hold_error", hold_error)
            trial.set_user_attr("actual_hold_ratio", actual_hold_ratio)
            trial.set_user_attr("buy_sell_balance", actual_buy_ratio / max(actual_sell_ratio, 0.01))
            
            self.logger.info(f"ğŸ“Š æŒæœ‰ç‡ä¼ é€’: ç›®æ ‡={target_hold:.1%}, å®é™…={actual_hold_ratio:.1%}, è¯¯å·®={hold_error:.3f}")

            return final_score

        except Exception as e:
            self.logger.error(f"æ¨™ç±¤å„ªåŒ–éç¨‹å‡ºéŒ¯: {e}")
            return -999.0

    def optimize(self, n_trials: int = 200, timeframes: List[str] = None) -> Dict:
        """åŸ·è¡Œæ¨™ç±¤åƒæ•¸å„ªåŒ–ï¼ˆæ”¯æ´å¤šæ™‚æ¡†ï¼‰"""
        if timeframes is None:
            timeframes = [self.timeframe]

        results = {}
        meta_vol = self.scaled_config.get('meta_vol', 0.02)

        for tf in timeframes:
            self.logger.info(f"ğŸš€ é–‹å§‹æ¨™ç±¤ç”Ÿæˆåƒæ•¸å„ªåŒ–ï¼ˆç¬¬1å±¤ï¼‰ - æ™‚æ¡†: {tf}")
            self.timeframe = tf

            storage_url = None
            try:
                # å¯ç”±ç’°å¢ƒè®Šæ•¸æˆ– scaled_config æ§åˆ¶ï¼Œé è¨­ Noneï¼ˆin-memoryï¼‰
                storage_url = self.scaled_config.get('optuna_storage')
            except Exception:
                storage_url = None
            study = optuna.create_study(
                direction='maximize',
                study_name=f'label_optimization_layer1_{tf}',
                storage=storage_url,
                load_if_exists=bool(storage_url)
            )
            study.set_user_attr('meta_vol', meta_vol)

            study.optimize(self.objective, n_trials=n_trials)

            best_params = study.best_params
            best_score = study.best_value

            self.logger.info(f"æ¨™ç±¤å„ªåŒ–å®Œæˆ! æœ€ä½³å¾—åˆ†: {best_score:.4f}")
            self.logger.info(f"æœ€å„ªåƒæ•¸: {best_params}")

            try:
                processed_cleaned = Path(self.data_path) / "processed" / "cleaned" / f"{self.symbol}_{tf}"
                df2 = None
                # 1) processed ä¸‹çš„å›ºå®šæª”å
                for c in [processed_cleaned / "cleaned_ohlcv.parquet", processed_cleaned / "cleaned_ohlcv.pkl"]:
                    if c.exists():
                        df2 = read_dataframe(c)
                        self.logger.info(f"âœ… ä½¿ç”¨Layer0æ¸…æ´—æ•¸æ“šç”Ÿæˆæœ€çµ‚æ¨™ç±¤: {c}")
                        break
                # 2) processed ä¸‹çš„é›œæ¹Šæª”å
                if df2 is None and processed_cleaned.exists():
                    hashed = sorted(list(processed_cleaned.glob("cleaned_ohlcv_*.parquet")) +
                                    list(processed_cleaned.glob("cleaned_ohlcv_*.pkl")),
                                    key=lambda p: p.stat().st_mtime, reverse=True)
                    for c in hashed:
                        try:
                            df2 = read_dataframe(c)
                            self.logger.info(f"âœ… ä½¿ç”¨Layer0æ¸…æ´—æ•¸æ“š(é›œæ¹Š)ç”Ÿæˆæœ€çµ‚æ¨™ç±¤: {c}")
                            break
                        except Exception:
                            continue
                # 3) å›é€€åˆ° configs èˆŠè·¯å¾‘ï¼ˆå« parquet/pklï¼‰
                if df2 is None:
                    legacy_candidates = [
                        self.config_path / f"cleaned_ohlcv_{tf}.parquet",
                        self.config_path / f"cleaned_ohlcv_{tf}.pkl",
                    ]
                    for c in legacy_candidates:
                        if c.exists():
                            df2 = read_dataframe(c)
                            self.logger.info(f"âœ… ä½¿ç”¨Layer0æ¸…æ´—æ•¸æ“š(legacy)ç”Ÿæˆæœ€çµ‚æ¨™ç±¤: {c}")
                            break
                # 4) æœ€å¾Œå›é€€åŸå§‹ OHLCV
                if df2 is None:
                    ohlcv_file = self.data_path / "raw" / self.symbol / f"{self.symbol}_{tf}_ohlcv.parquet"
                    df2 = read_dataframe(ohlcv_file)
                    self.logger.info(f"âœ… ä½¿ç”¨åŸå§‹OHLCVæ•¸æ“šç”Ÿæˆæ¨™ç±¤: {ohlcv_file}")
                labeled_data = self.apply_labels(df2, best_params)
                final_quality = self.calculate_label_quality(labeled_data['label'], best_params)
            except Exception as e:
                self.logger.warning(f"ç„¡æ³•ç”Ÿæˆæœ€çµ‚æ¨™ç±¤: {e}")
                final_quality = {}
                labeled_data = None

            result = {
                'timeframe': tf,
                'best_params': best_params,
                'best_score': best_score,
                'n_trials': n_trials,
                'final_quality': final_quality,
                'meta_vol': meta_vol,
                'labeled_data': labeled_data,
                'optimization_history': [
                    {'trial': i, 'score': trial.value}
                    for i, trial in enumerate(study.trials)
                    if trial.value is not None
                ]
            }
            lag_min = self.scaled_config.get('label_lag_min', 1)
            lag_max = self.scaled_config.get('label_lag_max', 1000)
            result['best_params']['lag'] = int(max(lag_min, min(result['best_params'].get('lag', lag_min), lag_max)))
 
            json_safe = {k: v for k, v in result.items() if k != 'labeled_data'}
            output_file = self.config_path / "label_params.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(json_safe, f, indent=2, ensure_ascii=False)
 
            tf_output = self.config_path / f"label_params_{tf}.json"
            with open(tf_output, 'w', encoding='utf-8') as f:
                json.dump(json_safe, f, indent=2, ensure_ascii=False)

            self.logger.info(f"çµæœå·²ä¿å­˜è‡³: {output_file}")
            self.logger.info(f"æ™‚æ¡†å°ˆå±¬çµæœå·²ä¿å­˜è‡³: {tf_output}")

            # ç‰©åŒ–æ¨™ç±¤è³‡æ–™åˆ° processed/labelsï¼ˆæ”¯æ´ç‰ˆæœ¬å­ç›®éŒ„ï¼‰
            try:
                if labeled_data is not None and not labeled_data.empty:
                    # è‹¥å”èª¿å™¨å·²å»ºç«‹ results/latest.txtï¼Œå¯è®€å–æœ€æ–°ç‰ˆæœ¬ä½œç‚ºå­ç›®éŒ„
                    results_root = Path(__file__).resolve().parent.parent / "results"
                    latest_file = results_root / "latest.txt"
                    version_sub = None
                    if latest_file.exists():
                        try:
                            version_sub = latest_file.read_text(encoding="utf-8").strip()
                        except Exception:
                            version_sub = None
                    out_dir = Path(self.data_path) / "processed" / "labels" / f"{self.symbol}_{tf}"
                    if version_sub:
                        out_dir = out_dir / version_sub
                    out_dir.mkdir(parents=True, exist_ok=True)
                    target = out_dir / f"labels_{self.symbol}_{tf}.parquet"
                    label_file, _ = write_dataframe(labeled_data, target)
                    self.logger.info(f"âœ… Layer1 æ¨™ç±¤ç‰©åŒ–: {label_file}")
                    result['materialized_path'] = str(label_file)
                else:
                    self.logger.warning("âš ï¸ ç„¡å¯ç‰©åŒ–çš„æ¨™ç±¤è³‡æ–™ (labeled_data ç‚ºç©º)")
            except Exception as exc:
                self.logger.warning(f"âš ï¸ Layer1 æ¨™ç±¤ç‰©åŒ–å¤±æ•—: {exc}")
 
            results[tf] = result
 
        return results[self.timeframe] if len(timeframes) == 1 else results

    def apply_labels(self, data: pd.DataFrame, params: Dict[str, Any]) -> pd.DataFrame:
        """æ ¹æ“šåƒæ•¸ç”Ÿæˆæ¨™ç±¤ä¸¦é™„åŠ è‡³è³‡æ–™"""
        if 'close' not in data.columns:
            raise ValueError("è³‡æ–™å¿…é ˆåŒ…å«closeæ¬„ä½")
        labels = self.generate_labels(data['close'], params)
        result = data.loc[labels.index].copy()
        result['label'] = labels
        return result

    def apply_transform(self, data: pd.DataFrame, params: Dict[str, Any]) -> pd.DataFrame:
        """çµ±ä¸€çš„ç‰©åŒ–æ¥å£"""
        return self.apply_labels(data, params)

    def _rebalance_labels(self, labels: pd.Series, valid_slice: slice,
                           target_ratio: List[float], tolerance: float) -> pd.Series:
        if len(target_ratio) != 3:
            return labels
        try:
            target_ratio = np.array(target_ratio, dtype=float)
            target_ratio = target_ratio / target_ratio.sum()
        except Exception:
            return labels

        portion = labels.iloc[valid_slice]
        counts = portion.value_counts(normalize=True)
        current_ratio = np.array([counts.get(0, 0.0), counts.get(1, 0.0), counts.get(2, 0.0)])

        if np.all(np.abs(current_ratio - target_ratio) <= tolerance):
            return labels

        over_hold = current_ratio[1] > target_ratio[1] + tolerance
        need_buy = current_ratio[2] < max(target_ratio[2] - tolerance, 0)
        need_sell = current_ratio[0] < max(target_ratio[0] - tolerance, 0)

        rng = np.random.default_rng(42)
        idx = portion.index
        if over_hold:
            hold_idx = idx[portion == 1]
            swap_candidates = hold_idx.tolist()
            rng.shuffle(swap_candidates)
            for idx_val in swap_candidates:
                if need_buy and current_ratio[2] < target_ratio[2]:
                    labels.at[idx_val] = 2
                    current_ratio[1] -= 1 / len(portion)
                    current_ratio[2] += 1 / len(portion)
                    need_buy = current_ratio[2] < target_ratio[2] - tolerance
                elif need_sell and current_ratio[0] < target_ratio[0]:
                    labels.at[idx_val] = 0
                    current_ratio[1] -= 1 / len(portion)
                    current_ratio[0] += 1 / len(portion)
                    need_sell = current_ratio[0] < target_ratio[0] - tolerance
                if (not need_buy) and (not need_sell):
                    break
        return labels


def main():
    """ä¸»å‡½æ•¸"""
    optimizer = LabelOptimizer(data_path='../data', config_path='../configs')
    result = optimizer.optimize(n_trials=200)
    print(f"æ¨™ç±¤å„ªåŒ–å®Œæˆ: {result['best_score']:.4f}")


if __name__ == "__main__":
    main()