# -*- coding: utf-8 -*-
"""
æ¨™ç±¤ç”Ÿæˆåƒæ•¸å„ªåŒ–å™¨ (ç¬¬1å±¤)
åŸºæ–¼ä¸»ç³»çµ±çš„label_optimizeré‡æ–°å¯¦ç¾
"""
import json
import logging
import warnings
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any

import numpy as np
import optuna
import pandas as pd

from optuna_system.utils.io_utils import write_dataframe, read_dataframe, atomic_write_json

warnings.filterwarnings('ignore')


class LabelOptimizer:
    """æ¨™ç±¤ç”Ÿæˆåƒæ•¸å„ªåŒ–å™¨ - ç¬¬1å±¤å„ªåŒ–"""

    def __init__(self, data_path: str, config_path: str = "configs/",
                 symbol: str = "BTCUSDT", timeframe: str = "15m", scaled_config: Dict = None):
        self.data_path = Path(data_path)
        self.config_path = Path(config_path)
        self.config_path.mkdir(exist_ok=True)
        self.symbol = symbol
        self.timeframe = timeframe

        # æ™‚é–“æ¡†æ¶ç¸®æ”¾é…ç½®ï¼ˆæ–‡æª”è¨­è¨ˆï¼‰
        self.scaled_config = scaled_config or {}

        # ä½¿ç”¨é›†ä¸­æ—¥èªŒ (ç”±ä¸Šå±¤/å…¥å£åˆå§‹åŒ–)ï¼Œé¿å…é‡è¤‡ basicConfig
        self.logger = logging.getLogger(__name__)

        # Layer1 å…§éƒ¨ç‹€æ…‹ï¼šä¾›å†å¹³è¡¡/å ±å‘Šä½¿ç”¨
        self._last_rebalance_applied: bool = False
        self._last_distribution: Optional[List[float]] = None
        self._last_rebalance_changes: int = 0

    def generate_labels(self, price_data: pd.Series, params: Dict) -> pd.Series:
        """âœ… å®Œå…¨ä¿®å¾©ç‰ˆæ¨™ç±¤ç”Ÿæˆ - æ»¾å‹•çª—å£åˆ†ä½æ•¸ï¼Œåš´æ ¼é¿å…æœªä¾†æ•¸æ“šæ´©éœ²"""
        try:
            lag = params['lag']
            threshold_method = params.get('threshold_method', 'quantile')
            lookback_window = params.get('lookback_window', 500)  # æ»¾å‹•çª—å£å¤§å°

            if len(price_data) <= lag:
                return pd.Series([], dtype=int)

            # âœ… è¨ˆç®—æœªä¾†æ”¶ç›Šç‡ï¼ˆé€™æ˜¯æˆ‘å€‘è¦é æ¸¬çš„ç›®æ¨™ï¼‰
            future_prices = price_data.shift(-lag)
            future_returns = (future_prices - price_data) / price_data

            # åˆå§‹åŒ–æ¨™ç±¤
            labels = pd.Series(1, index=price_data.index, dtype=int)  # é»˜èªæŒæœ‰

            # æ ¹æ“šæ–¹æ³•ç¢ºå®šé–¾å€¼
            if threshold_method == 'quantile':
                # ğŸš€ ä½¿ç”¨ç¨ç«‹çš„è²·å…¥/è³£å‡ºåˆ†ä½æ•¸
                buy_quantile = params.get('buy_quantile', 0.75)
                sell_quantile = params.get('sell_quantile', 0.25)

                # âœ… é—œéµä¿®å¾©ï¼šä½¿ç”¨"æ­·å²çš„æœªä¾†æ”¶ç›Šç‡"è¨ˆç®—é–¾å€¼
                # é€™æ¨£é˜ˆå€¼å’Œç›®æ¨™è®Šé‡çš„åˆ†å¸ƒæ˜¯ä¸€è‡´çš„
                historical_future_returns = future_returns.shift(1)  # å‘å‰åç§»ï¼Œåªç”¨æ­·å²
                
                # âœ… åŸºæ–¼æ­·å²æœªä¾†æ”¶ç›Šç‡è¨ˆç®—æ»¾å‹•åˆ†ä½æ•¸
                rolling_upper = historical_future_returns.rolling(
                    window=lookback_window, 
                    min_periods=100
                ).quantile(buy_quantile)
                
                rolling_lower = historical_future_returns.rolling(
                    window=lookback_window, 
                    min_periods=100
                ).quantile(sell_quantile)
                
                # ç¢ºä¿é–¾å€¼åˆç†ä¸”æœ‰é–“éš”
                rolling_upper = rolling_upper.fillna(0.0001).clip(lower=0.0001)
                rolling_lower = rolling_lower.fillna(-0.0001).clip(upper=-0.0001)
                
                # ç¢ºä¿è²·è³£é–¾å€¼æœ‰è¶³å¤ é–“éš”ï¼Œé¿å…é‡ç–Š
                gap_needed = (rolling_upper + abs(rolling_lower)) * 0.1
                gap_needed = gap_needed.clip(lower=0.0005)
                
                # èª¿æ•´é‡ç–Šçš„é–¾å€¼
                overlap_mask = rolling_upper <= abs(rolling_lower)
                rolling_upper[overlap_mask] = rolling_upper[overlap_mask].clip(lower=gap_needed[overlap_mask])
                rolling_lower[overlap_mask] = rolling_lower[overlap_mask].clip(upper=-gap_needed[overlap_mask])

                # âœ… å‘é‡åŒ–æ¨™ç±¤åˆ†é…ï¼ˆé¡å‹ä¸€è‡´ï¼šéƒ½æ˜¯æœªä¾†æ”¶ç›Šç‡ï¼‰
                valid_range = slice(lookback_window, len(future_returns) - lag)
                labels.iloc[valid_range] = 1  # é‡ç½®ç‚ºæŒæœ‰
                
                # è²·å…¥ä¿¡è™Ÿ
                buy_mask = (future_returns.iloc[valid_range] > rolling_upper.iloc[valid_range]) & rolling_upper.iloc[valid_range].notna()
                labels.iloc[valid_range] = labels.iloc[valid_range].where(~buy_mask, 2)
                
                # è³£å‡ºä¿¡è™Ÿ  
                sell_mask = (future_returns.iloc[valid_range] < rolling_lower.iloc[valid_range]) & rolling_lower.iloc[valid_range].notna()
                labels.iloc[valid_range] = labels.iloc[valid_range].where(~sell_mask, 0)

            elif threshold_method == 'fixed':
                # å›ºå®šé–¾å€¼æ–¹æ³•
                profit_threshold = params.get('profit_threshold', 0.01)
                loss_threshold = params.get('loss_threshold', -0.01)

                # æ‡‰ç”¨å›ºå®šé–¾å€¼
                labels[future_returns > profit_threshold] = 2  # è²·å…¥
                labels[future_returns < loss_threshold] = 0   # è³£å‡º

            elif threshold_method == 'adaptive':
                # âœ… ä¿®å¾©ï¼šè‡ªé©æ‡‰é–¾å€¼ä¹ŸåŸºæ–¼æœªä¾†æ”¶ç›Šç‡
                vol_multiplier = params.get('vol_multiplier', 1.5)
                vol_window = int(params.get('vol_window', min(lookback_window, 40)))

                # âœ… ä½¿ç”¨æ­·å²æœªä¾†æ”¶ç›Šç‡è¨ˆç®—æ³¢å‹•ç‡
                historical_future_returns = future_returns.shift(1)
                rolling_volatility = historical_future_returns.rolling(
                    window=vol_window, 
                    min_periods=20
                ).std()
                
                # åŸºæ–¼æ³¢å‹•ç‡çš„å‹•æ…‹é–¾å€¼
                rolling_profit_threshold = rolling_volatility * vol_multiplier
                rolling_loss_threshold = -rolling_volatility * vol_multiplier
                
                # å¡«è£œç„¡æ•ˆå€¼
                rolling_profit_threshold = rolling_profit_threshold.fillna(0.01)
                rolling_loss_threshold = rolling_loss_threshold.fillna(-0.01)
                
                # âœ… å‘é‡åŒ–æ¨™ç±¤åˆ†é…ï¼ˆé¡å‹ä¸€è‡´ï¼‰
                valid_range = slice(vol_window, len(future_returns) - lag)
                labels.iloc[valid_range] = 1  # é‡ç½®ç‚ºæŒæœ‰
                
                # è²·å…¥ä¿¡è™Ÿ
                buy_mask = future_returns.iloc[valid_range] > rolling_profit_threshold.iloc[valid_range]
                labels.iloc[valid_range] = labels.iloc[valid_range].where(~buy_mask, 2)
                
                # è³£å‡ºä¿¡è™Ÿ
                sell_mask = future_returns.iloc[valid_range] < rolling_loss_threshold.iloc[valid_range]
                labels.iloc[valid_range] = labels.iloc[valid_range].where(~sell_mask, 0)
            else:
                # é»˜èªå›ºå®šé–¾å€¼
                profit_threshold = 0.01
                loss_threshold = -0.01
                labels[future_returns > profit_threshold] = 2
                labels[future_returns < loss_threshold] = 0

            # ç§»é™¤æœªä¾†æ•¸æ“šæ´©éœ²
            labels = labels[:-lag] if lag > 0 else labels

            # æ¨™ç±¤å†å¹³è¡¡ï¼ˆç¸®å°åå·®ï¼‰
            target_ratio = params.get('target_distribution', [0.25, 0.5, 0.25])
            tolerance = params.get('distribution_tolerance', 0.05)
            rebalance_method = params.get('rebalance_method', 'cost_sensitive')
            if len(labels) > 0:
                rebalance_returns = future_returns.shift(1)
                labels = self._rebalance_labels(labels, target_ratio, tolerance,
                                                method=rebalance_method,
                                                rolling_returns=rebalance_returns,
                                                params=params)

            # è¨ˆç®—ä¸¦æ‰“å°æ¨™ç±¤çµ±è¨ˆ
            self._print_label_statistics(labels, params)

            return labels.dropna()

        except Exception as e:
            self.logger.error(f"æ¨™ç±¤ç”Ÿæˆå¤±æ•—: {e}")
            return pd.Series([], dtype=int)

    def stabilized_label_generation(self, price_data: pd.Series, params: Dict) -> pd.Series:
        """ç©©å®šåŒ–æ¨™ç±¤ç”Ÿæˆï¼šå›ºå®šæ­·å²åˆ†ä½æ•¸ + ä¿¡è™Ÿé©—è­‰"""
        try:
            lag = params['lag']
            fixed_lookback = int(params.get('fixed_lookback', 2000))

            if len(price_data) <= max(lag, fixed_lookback):
                return self.generate_labels(price_data, params)

            future_returns = (price_data.shift(-lag) - price_data) / price_data

            historical_returns = future_returns.iloc[:fixed_lookback].dropna()
            if len(historical_returns) < 200:
                return self.generate_labels(price_data, params)

            buy_quantile = float(params.get('buy_quantile', 0.75))
            sell_quantile = float(params.get('sell_quantile', 0.25))

            buy_threshold = historical_returns.quantile(buy_quantile)
            sell_threshold = historical_returns.quantile(sell_quantile)

            min_gap = float(params.get('min_threshold_gap', 0.005))
            if buy_threshold - abs(sell_threshold) < min_gap:
                buy_threshold = abs(sell_threshold) + min_gap

            labels = pd.Series(1, index=price_data.index, dtype=int)
            valid_end = len(price_data) - lag
            valid_start = fixed_lookback
            if valid_start >= valid_end:
                return self.generate_labels(price_data, params)

            valid_slice = slice(valid_start, valid_end)
            returns_slice = future_returns.iloc[valid_slice]

            labels.iloc[valid_slice] = labels.iloc[valid_slice].where(~(returns_slice >= buy_threshold), 2)
            labels.iloc[valid_slice] = labels.iloc[valid_slice].where(~(returns_slice <= sell_threshold), 0)

            signal_stats = self.validate_signal_authenticity(price_data, labels, lag)
            max_noise_ratio = float(params.get('max_noise_ratio', 0.35))

            if signal_stats['noise_ratio'] > max_noise_ratio:
                self.logger.warning(
                    f"âš ï¸ ä¿¡è™Ÿå™ªè²éé«˜({signal_stats['noise_ratio']:.2f} > {max_noise_ratio:.2f})ï¼Œä½¿ç”¨ä¿å®ˆæ¨™ç±¤"
                )
                labels = self.generate_conservative_labels(price_data, params)

            if lag > 0:
                labels = labels[:-lag]

            self._print_label_statistics(labels, params)
            return labels.dropna()

        except Exception as e:
            self.logger.error(f"ç©©å®šåŒ–æ¨™ç±¤ç”Ÿæˆå¤±æ•—: {e}")
            return self.generate_labels(price_data, params)

    def generate_conservative_labels(self, price_data: pd.Series, params: Dict) -> pd.Series:
        """ç”Ÿæˆæ›´ä¿å®ˆçš„æ¨™ç±¤ï¼ˆæé«˜è²·å…¥é–€æª»/é™ä½è³£å‡ºé–€æª»ï¼‰"""
        conservative_shift = float(params.get('conservative_shift', 0.005))
        fallback_params = params.copy()
        fallback_params['buy_quantile'] = min(0.95, fallback_params.get('buy_quantile', 0.75) + 0.05)
        fallback_params['sell_quantile'] = max(0.05, fallback_params.get('sell_quantile', 0.25) - 0.05)
        fallback_params['profit_threshold'] = fallback_params.get('profit_threshold', 0.02) + conservative_shift
        fallback_params['loss_threshold'] = fallback_params.get('loss_threshold', -0.02) - conservative_shift
        return self.generate_labels(price_data, fallback_params)

    def validate_signal_authenticity(self, prices: pd.Series, labels: pd.Series, lag: int) -> Dict:
        """ä¿¡è™ŸçœŸå¯¦æ€§é©—è­‰ï¼šçµ±è¨ˆä¿¡è™Ÿå¾Œçš„å¯¦éš›èµ°å‹¢"""
        try:
            buy_mask = labels == 2
            sell_mask = labels == 0

            future_prices = prices.shift(-lag)
            buy_accuracy = (
                (future_prices[buy_mask] > prices[buy_mask]).mean()
                if buy_mask.sum() > 0 else 0
            )
            sell_accuracy = (
                (future_prices[sell_mask] < prices[sell_mask]).mean()
                if sell_mask.sum() > 0 else 0
            )

            total_signals = buy_mask.sum() + sell_mask.sum()
            total_accuracy = (
                (buy_accuracy * buy_mask.sum() + sell_accuracy * sell_mask.sum()) / total_signals
                if total_signals > 0 else 0
            )
            noise_ratio = 1 - total_accuracy

            quality = 'high'
            if noise_ratio >= 0.4:
                quality = 'low'
            elif noise_ratio >= 0.2:
                quality = 'medium'

            return {
                'buy_accuracy': float(buy_accuracy),
                'sell_accuracy': float(sell_accuracy),
                'noise_ratio': float(noise_ratio),
                'signal_quality': quality
            }

        except Exception as e:
            self.logger.warning(f"ä¿¡è™ŸçœŸå¯¦æ€§é©—è­‰å¤±æ•—: {e}")
            return {'buy_accuracy': 0, 'sell_accuracy': 0, 'noise_ratio': 1.0, 'signal_quality': 'unknown'}
    
    def _timeframe_to_minutes(self, timeframe: Optional[str] = None) -> float:
        tf = (timeframe or self.timeframe or '').lower()
        try:
            if tf.endswith('m'):
                return max(1.0, float(tf[:-1]))
            if tf.endswith('h'):
                return max(1.0, float(tf[:-1]) * 60.0)
            if tf.endswith('d'):
                return max(1.0, float(tf[:-1]) * 1440.0)
            if tf.endswith('s'):
                return max(1.0, float(tf[:-1]) / 60.0)
        except Exception:
            pass
        # é»˜èª15åˆ†é˜
        return 15.0

    def _normalize_sharpe(self, sharpe: float) -> float:
        capped = min(max(sharpe, -1.0), 3.0)
        return float((capped + 1.0) / 4.0)

    def _normalize_trade_frequency(self, trades_per_day: float, params: Dict) -> float:
        target = params.get('target_trades_per_day', self.scaled_config.get('target_trades_per_day', 2.0))
        if target <= 0:
            target = 2.0
        score = trades_per_day / target
        return float(max(0.0, min(score, 1.2)))  # å…è¨±æœ€é«˜1.2çµ¦äºˆäº›è¨±çå‹µ

    def _compute_strategy_metrics(self, labels: pd.Series, actual_returns: pd.Series, params: Dict) -> Dict[str, float]:
        default_metrics = {
            'sharpe': 0.0,
            'win_rate': 0.0,
            'trades_per_day': 0.0,
            'avg_return': 0.0,
            'exposure': 0.0,
            'trades': 0,
            'avg_holding_minutes': 0.0,
            'cost_per_trade_bps': float(params.get('transaction_cost_bps', self.scaled_config.get('transaction_cost_bps', 7)))
        }

        if labels is None or labels.empty:
            return default_metrics

        returns_series = actual_returns.reindex(labels.index).fillna(0.0)
        position = labels.astype(float).map({2: 1.0, 1: 0.0, 0: -1.0}).fillna(0.0)

        cost_bps = params.get('transaction_cost_bps', self.scaled_config.get('transaction_cost_bps', 7))
        cost_per_trade = (cost_bps or 0.0) / 10000.0

        pos_change = position.diff().abs()
        if not pos_change.empty:
            pos_change.iloc[0] = abs(position.iloc[0])
        trade_cost = pos_change * cost_per_trade

        strategy_returns = position * returns_series - trade_cost

        trades = int((pos_change > 0).sum())
        exposure = float((position != 0).mean()) if len(position) > 0 else 0.0

        if isinstance(labels.index, pd.DatetimeIndex) and len(labels) > 1:
            total_seconds = (labels.index[-1] - labels.index[0]).total_seconds()
            total_days = total_seconds / 86400.0 if total_seconds > 0 else len(labels) * self._timeframe_to_minutes() / (60.0 * 24.0)
        else:
            minutes = self._timeframe_to_minutes()
            total_days = (len(labels) * minutes) / (60.0 * 24.0)

        total_days = max(total_days, 1 / 24)  # è‡³å°‘ä¸€å°æ™‚é¿å…é™¤ä»¥0
        trades_per_day = trades / total_days

        in_position_mask = position != 0
        if in_position_mask.any():
            position_returns = strategy_returns[in_position_mask]
        else:
            position_returns = strategy_returns

        win_rate = float((position_returns > 0).mean()) if len(position_returns) > 0 else 0.0
        avg_return = float(position_returns.mean()) if len(position_returns) > 0 else 0.0

        mean_ret = float(strategy_returns.mean()) if len(strategy_returns) > 0 else 0.0
        std_ret = float(strategy_returns.std(ddof=0)) if len(strategy_returns) > 1 else 0.0

        periods_per_day = len(strategy_returns) / total_days if total_days > 0 else len(strategy_returns)
        periods_per_year = periods_per_day * 252.0
        if std_ret > 1e-9 and periods_per_year > 0:
            sharpe = float(mean_ret / std_ret * np.sqrt(periods_per_year))
        else:
            sharpe = 0.0

        minutes_per_bar = self._timeframe_to_minutes()
        avg_holding_minutes = 0.0
        if trades > 0 and minutes_per_bar > 0:
            avg_holding_minutes = float(((position != 0).sum() / trades) * minutes_per_bar)

        return {
            'sharpe': sharpe,
            'win_rate': win_rate,
            'trades_per_day': float(trades_per_day),
            'avg_return': avg_return,
            'exposure': exposure,
            'trades': trades,
            'avg_holding_minutes': avg_holding_minutes,
            'cost_per_trade_bps': float(cost_bps)
        }

    def _rebalance_labels(self,
                          labels: pd.Series,
                          target_ratio: List[float],
                          tolerance: float,
                          method: str = 'cost_sensitive',
                          rolling_returns: Optional[pd.Series] = None,
                          params: Optional[Dict] = None) -> pd.Series:
        params = params or {}

        if labels is None or labels.empty:
            self._last_rebalance_applied = False
            self._last_distribution = None
            self._last_rebalance_changes = 0
            return labels

        adjusted = labels.copy()
        total = len(adjusted)
        if total == 0:
            self._last_rebalance_applied = False
            self._last_distribution = None
            self._last_rebalance_changes = 0
            return adjusted

        try:
            target = np.array(target_ratio, dtype=float)
            if target.sum() <= 0:
                raise ValueError
            target = target / target.sum()
        except Exception:
            target = np.array([0.25, 0.5, 0.25])

        counts = adjusted.value_counts()
        actual = np.array([
            counts.get(0, 0) / total,
            counts.get(1, 0) / total,
            counts.get(2, 0) / total
        ])
        self._last_distribution = actual.tolist()

        if method == 'none' or np.all(np.abs(actual - target) <= tolerance):
            self._last_rebalance_applied = False
            self._last_rebalance_changes = 0
            return adjusted

        if rolling_returns is not None:
            try:
                returns = rolling_returns.reindex(adjusted.index).fillna(0.0)
            except Exception:
                returns = pd.Series(0.0, index=adjusted.index)
        else:
            returns = pd.Series(0.0, index=adjusted.index)

        desired_counts = np.floor(target * total).astype(int)
        remainder = total - desired_counts.sum()
        if remainder > 0:
            order = np.argsort(-(target - desired_counts / total))
            for idx in order[:remainder]:
                desired_counts[idx] += 1

        def promote(from_label: int, to_label: int, need: int) -> int:
            if need <= 0:
                return 0
            candidates = adjusted[adjusted == from_label]
            if candidates.empty:
                return 0

            ascending = to_label == 0
            ordered = returns.loc[candidates.index].sort_values(ascending=ascending)

            if method == 'threshold_shift':
                k = max(0, int(np.ceil(need * params.get('threshold_adjust_pct', 0.35))))
                chosen = ordered.head(max(k, need)).index
            else:  # cost_sensitive or others
                chosen = ordered.head(need).index

            for idx in chosen[:need]:
                adjusted.at[idx] = to_label
            return min(len(chosen), need)

        changes = 0

        current_buy = counts.get(2, 0)
        desired_buy = desired_counts[2]
        if current_buy < desired_buy:
            changes += promote(1, 2, desired_buy - current_buy)
        elif current_buy > desired_buy:
            changes += promote(2, 1, current_buy - desired_buy)

        counts = adjusted.value_counts()
        current_sell = counts.get(0, 0)
        desired_sell = desired_counts[0]
        if current_sell < desired_sell:
            changes += promote(1, 0, desired_sell - current_sell)
        elif current_sell > desired_sell:
            changes += promote(0, 1, current_sell - desired_sell)

        counts_post = adjusted.value_counts()
        actual_post = np.array([
            counts_post.get(0, 0) / total,
            counts_post.get(1, 0) / total,
            counts_post.get(2, 0) / total
        ])
        self._last_distribution = actual_post.tolist()
        self._last_rebalance_applied = changes > 0
        self._last_rebalance_changes = int(changes)

        return adjusted

    def calculate_atr(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:
        """è¨ˆç®—å¹³å‡çœŸå¯¦å€é–“ï¼ˆATRï¼‰"""
        try:
            tr1 = high - low
            tr2 = abs(high - close.shift(1))
            tr3 = abs(low - close.shift(1))
            
            tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
            atr = tr.rolling(period).mean()
            
            return atr
        except Exception as e:
            self.logger.error(f"ATRè¨ˆç®—å¤±æ•—: {e}")
            return pd.Series(0, index=close.index)
    
    def generate_triple_barrier_labels(self, price_data: pd.Series, params: Dict) -> pd.Series:
        """ğŸš€ å¢å¼·ç‰ˆTriple-Barrieræ¨™ç±¤ç”Ÿæˆ - æ”¯æŒ1:1.3ç§»å‹•æ­¢æç­–ç•¥ï¼ˆæ–¹æ¡ˆBï¼‰
        
        ç§»å‹•æ­¢æç­–ç•¥ï¼š
        - åˆå§‹æ­¢æ: 1.2-1.5Ã—ATRï¼ˆçµ¦äºˆåˆç†ç©ºé–“ï¼‰
        - æ­¢ç›ˆç›®æ¨™: 1.6-2.0Ã—ATRï¼ˆåˆç†ç›®æ¨™ï¼‰
        - é¢¨éšªå›å ±æ¯”: â‰¥1.3:1ï¼ˆç”¨æˆ¶è¦æ±‚ï¼‰
        - ç§»å‹•æ­¢æ: ç›ˆåˆ©å¾Œè‡ªå‹•æŠ¬é«˜æ­¢æï¼Œé–å®šåˆ©æ½¤
        
        ç§»å‹•è¦å‰‡ï¼š
        1. ç›ˆåˆ©é”activation_ratioÃ—ç›®æ¨™ â†’ å•Ÿå‹•ç§»å‹•æ­¢æ
        2. æ­¢æè·é›¢: æœ€é«˜é»ä¸‹æ–¹ trailing_distanceÃ—ATR
        3. ä¿è­‰é–å®š: è‡³å°‘ lock_min_profitÃ—ATR åˆ©æ½¤
        4. æ­¢æåªå‡ä¸é™
        
        é æœŸæ•ˆæœï¼š
        - å‹ç‡: +8-12%
        - å¹³å‡è™§æ: -33%
        - æœ€å¤§å›æ’¤: -20-30%
        - è³‡é‡‘æ›²ç·šæ›´å¹³æ»‘
        """
        try:
            lag = params.get('lag', 12)
            profit_multiplier = params.get('profit_multiplier', 1.8)
            stop_multiplier = params.get('stop_multiplier', 1.3)
            max_holding = params.get('max_holding', 16)
            atr_period = params.get('atr_period', 14)
            transaction_cost_bps = params.get('transaction_cost_bps', self.scaled_config.get('transaction_cost_bps', 7))
            round_trip_cost = (transaction_cost_bps or 0.0) / 10000.0 * 2.0
            
            # ğŸš€ ç§»å‹•æ­¢æåƒæ•¸
            enable_trailing = params.get('enable_trailing_stop', True)
            trail_activation = params.get('trailing_activation_ratio', 0.5)  # ç›ˆåˆ©é”50%ç›®æ¨™æ™‚å•Ÿå‹•
            trail_distance = params.get('trailing_distance_ratio', 0.7)  # è·æœ€é«˜é»0.7Ã—ATR
            trail_lock_min = params.get('trailing_lock_min_profit', 0.3)  # è‡³å°‘é–å®š0.3Ã—ATRåˆ©æ½¤

            if len(price_data) <= max_holding:
                return pd.Series([], dtype=int)
            
            # ğŸ”’ é¢¨éšªå›å ±æ¯”ç´„æŸï¼ˆTask 2.2åŒæ­¥å¯¦æ–½ï¼‰
            min_rr = params.get('min_risk_reward_ratio', 1.3)
            if profit_multiplier / stop_multiplier < min_rr:
                adjusted_profit = stop_multiplier * min_rr
                self.logger.info(
                    f"ğŸ”’ R:Rç´„æŸè§¸ç™¼: "
                    f"{profit_multiplier:.2f}/{stop_multiplier:.2f}="
                    f"{profit_multiplier/stop_multiplier:.2f}:1 < {min_rr}:1 "
                    f"â†’ æ­¢ç›ˆèª¿æ•´è‡³ {adjusted_profit:.2f}Ã—ATR"
                )
                profit_multiplier = adjusted_profit
            
            # è¨ˆç®—ATR
            try:
                ohlcv_file = self.data_path / "raw" / self.symbol / f"{self.symbol}_{self.timeframe}_ohlcv.parquet"
                if ohlcv_file.exists():
                    ohlcv_df = pd.read_parquet(ohlcv_file)
                    atr = self.calculate_atr(ohlcv_df['high'], ohlcv_df['low'], ohlcv_df['close'], atr_period)
                    atr = atr.reindex(price_data.index).fillna(method='ffill')
                    
                    if atr.isna().any():
                        first_valid_idx = atr.first_valid_index()
                        if first_valid_idx is not None:
                            atr = atr.fillna(atr[first_valid_idx])
                        else:
                            atr = atr.fillna(price_data.std() * 0.02)
                else:
                    returns = price_data.pct_change().abs()
                    atr = returns.rolling(atr_period).mean() * price_data
                    self.logger.warning("âš ï¸ ä½¿ç”¨ç°¡åŒ–ATRä¼°ç®—")
            except Exception as e:
                self.logger.warning(f"âš ï¸ ATRè¨ˆç®—å¤±æ•—: {e}")
                returns = price_data.pct_change().abs()
                atr = returns.rolling(atr_period).mean() * price_data
            
            labels = pd.Series(1, index=price_data.index, dtype=int)
            
            # çµ±è¨ˆè®Šé‡
            stats = {
                'total_signals': 0,
                'profit_hits': 0,
                'initial_stop_hits': 0,
                'trailing_stop_hits': 0,
                'break_even_stops': 0,
                'profit_locks': 0,
                'timeout_holds': 0
            }
            
            # ========== ä¸»å¾ªç’°ï¼šé€å€‹å…¥å ´é»æ¨¡æ“¬ ==========
            for i in range(len(price_data) - max_holding):
                entry_price = price_data.iloc[i]
                current_atr = atr.iloc[i]
                
                if pd.isna(current_atr) or current_atr <= 0:
                    continue
                
                stats['total_signals'] += 1
                
                # åˆå§‹æ­¢ç›ˆæ­¢æåƒ¹æ ¼
                profit_target = entry_price + current_atr * profit_multiplier
                initial_stop = entry_price - current_atr * stop_multiplier
                
                # è€ƒæ…®äº¤æ˜“æˆæœ¬
                profit_target *= (1 + round_trip_cost)
                initial_stop *= (1 - round_trip_cost)
                
                # ç§»å‹•æ­¢æè®Šé‡
                current_stop = initial_stop
                highest_price = entry_price
                trailing_activated = False
                locked_profit = False
                
                # å®šç¾©æœªä¾†åƒ¹æ ¼çª—å£
                future_window_end = min(i + max_holding + 1, len(price_data))
                
                # ========== é€Kç·šæª¢æŸ¥è§¸ç™¼æ¢ä»¶ ==========
                for j in range(i + 1, future_window_end):
                    future_price = price_data.iloc[j]
                    current_profit = future_price - entry_price
                    current_profit_atr = current_profit / current_atr
                    
                    # ğŸš€ ç§»å‹•æ­¢æé‚è¼¯ï¼ˆæ–¹æ¡ˆBï¼‰
                    if enable_trailing:
                        # æ›´æ–°æœ€é«˜åƒ¹
                        if future_price > highest_price:
                            highest_price = future_price
                        
                        # è¨ˆç®—ç›ˆåˆ©é€²åº¦ï¼ˆç›¸å°æ–¼ç›®æ¨™ï¼‰
                        profit_progress = (future_price - entry_price) / (profit_target - entry_price)
                        
                        # å•Ÿå‹•æ¢ä»¶ï¼šç›ˆåˆ©é”åˆ°trail_activationæ¯”ä¾‹
                        if profit_progress >= trail_activation and not trailing_activated:
                            trailing_activated = True
                            self.logger.debug(
                                f"  ğŸ”“ i={i}: ç§»å‹•æ­¢æå•Ÿå‹• "
                                f"(ç›ˆåˆ©{current_profit_atr:.2f}Ã—ATR, "
                                f"é€²åº¦{profit_progress:.0%})"
                            )
                        
                        # ç§»å‹•æ­¢ææ›´æ–°
                        if trailing_activated:
                            # åŸºæœ¬ç§»å‹•æ­¢æï¼šè·æœ€é«˜é» trail_distanceÃ—ATR
                            new_trail_stop = highest_price - trail_distance * current_atr
                            
                            # ç¢ºä¿è‡³å°‘é–å®š trail_lock_minÃ—ATR åˆ©æ½¤
                            min_lock_stop = entry_price + trail_lock_min * current_atr
                            new_trail_stop = max(new_trail_stop, min_lock_stop)
                            
                            # æ­¢æåªèƒ½ä¸Šç§»ï¼Œä¸èƒ½ä¸‹ç§»
                            if new_trail_stop > current_stop:
                                # æª¢æŸ¥æ˜¯å¦é”åˆ°ä¿æœ¬æˆ–é–åˆ©ç‹€æ…‹
                                if new_trail_stop >= entry_price and not locked_profit:
                                    locked_profit = True
                                    stats['profit_locks'] += 1
                                
                                current_stop = new_trail_stop
                    
                    # ========== æª¢æŸ¥è§¸ç™¼æ¢ä»¶ ==========
                    # 1. è§¸ç™¼æ­¢ç›ˆ
                    if future_price >= profit_target:
                        labels.iloc[i] = 2  # è²·å…¥ä¿¡è™Ÿ
                        stats['profit_hits'] += 1
                        break
                    
                    # 2. è§¸ç™¼æ­¢æ
                    elif future_price <= current_stop:
                        labels.iloc[i] = 0  # è³£å‡ºä¿¡è™Ÿ
                        
                        # å€åˆ†ä¸åŒé¡å‹çš„æ­¢æ
                        if trailing_activated:
                            if current_stop >= entry_price:
                                stats['break_even_stops'] += 1  # ä¿æœ¬æˆ–ç›ˆåˆ©æ­¢æ
                            else:
                                stats['trailing_stop_hits'] += 1  # ç§»å‹•æ­¢æï¼ˆä»å°è™§ï¼‰
                        else:
                            stats['initial_stop_hits'] += 1  # åˆå§‹æ­¢æ
                        break
                
                else:
                    # æœªè§¸ç™¼ä»»ä½•éšœç¤™ï¼ŒæŒæœ‰åˆ°æœŸ
                    stats['timeout_holds'] += 1
            
            # ç§»é™¤æœªä¾†æ•¸æ“šæ´©éœ²
            if lag > 0:
                labels = labels[:-lag]
            
            # ========== ç­–ç•¥çµ±è¨ˆå ±å‘Š ==========
            self.logger.info("=" * 60)
            self.logger.info("ğŸ¯ Triple-Barrier ç§»å‹•æ­¢æç­–ç•¥ï¼ˆæ–¹æ¡ˆBï¼‰:")
            self.logger.info(f"  æ­¢ç›ˆç›®æ¨™:     {profit_multiplier:.2f}Ã—ATR")
            self.logger.info(f"  åˆå§‹æ­¢æ:     {stop_multiplier:.2f}Ã—ATR")
            self.logger.info(f"  é¢¨éšªå›å ±æ¯”:   {profit_multiplier/stop_multiplier:.2f}:1 âœ…")
            self.logger.info(f"  äº¤æ˜“æˆæœ¬:     {transaction_cost_bps:.1f} bps (å–®é‚Š)")
            self.logger.info(f"  ATRé€±æœŸ:      {atr_period} bars")
            self.logger.info(f"  æœ€å¤§æŒæœ‰:     {max_holding} bars ({max_holding*self._timeframe_to_minutes()/60:.1f}å°æ™‚)")
            
            if enable_trailing:
                self.logger.info(f"\n  ç§»å‹•æ­¢æé…ç½®:")
                self.logger.info(f"    å•Ÿå‹•æ¢ä»¶:   ç›ˆåˆ©é”{trail_activation:.0%}ç›®æ¨™")
                self.logger.info(f"    è·Ÿéš¨è·é›¢:   è·æœ€é«˜é»{trail_distance:.2f}Ã—ATR")
                self.logger.info(f"    é–åˆ©ä¿è­·:   è‡³å°‘{trail_lock_min:.2f}Ã—ATR")
            
            if stats['total_signals'] > 0:
                total = stats['total_signals']
                self.logger.info(f"\n  è§¸ç™¼çµ±è¨ˆ (å…±{total:,}å€‹å…¥å ´ä¿¡è™Ÿ):")
                self.logger.info(
                    f"    æ­¢ç›ˆè§¸ç™¼:   {stats['profit_hits']:>6} "
                    f"({stats['profit_hits']/total*100:>5.1f}%)"
                )
                self.logger.info(
                    f"    åˆå§‹æ­¢æ:   {stats['initial_stop_hits']:>6} "
                    f"({stats['initial_stop_hits']/total*100:>5.1f}%)"
                )
                
                if enable_trailing:
                    trail_total = stats['trailing_stop_hits'] + stats['break_even_stops']
                    self.logger.info(
                        f"    ç§»å‹•æ­¢æ:   {stats['trailing_stop_hits']:>6} "
                        f"({stats['trailing_stop_hits']/total*100:>5.1f}%)"
                    )
                    self.logger.info(
                        f"    ä¿æœ¬æ­¢æ:   {stats['break_even_stops']:>6} "
                        f"({stats['break_even_stops']/total*100:>5.1f}%)"
                    )
                    self.logger.info(
                        f"    é–åˆ©æ¬¡æ•¸:   {stats['profit_locks']:>6} "
                        f"({stats['profit_locks']/total*100:>5.1f}%)"
                    )
                    self.logger.info(
                        f"    ç§»å‹•æ­¢ææ•ˆç‡: {trail_total/total*100:.1f}% "
                        f"(ç›®æ¨™>25%)"
                    )
                
                self.logger.info(
                    f"    æŒæœ‰åˆ°æœŸ:   {stats['timeout_holds']:>6} "
                    f"({stats['timeout_holds']/total*100:>5.1f}%)"
                )
                
                # æ•ˆç‡è©•ä¼°
                if enable_trailing and trail_total > 0:
                    trail_efficiency = trail_total / total
                    if trail_efficiency > 0.30:
                        self.logger.info(f"  âœ… ç§»å‹•æ­¢ææ•ˆç‡å„ªç§€: {trail_efficiency:.1%}")
                    elif trail_efficiency > 0.20:
                        self.logger.info(f"  ğŸ“Š ç§»å‹•æ­¢ææ•ˆç‡è‰¯å¥½: {trail_efficiency:.1%}")
                    else:
                        self.logger.warning(f"  âš ï¸ ç§»å‹•æ­¢ææ•ˆç‡åä½: {trail_efficiency:.1%} < 20%")
            
            self.logger.info("=" * 60)
            
            return labels.dropna()
            
        except Exception as e:
            self.logger.error(f"âŒ Triple-Barrierç§»å‹•æ­¢æç”Ÿæˆå¤±æ•—: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return pd.Series([], dtype=int)

    def _print_label_statistics(self, labels: pd.Series, params: Dict) -> None:
        """ğŸš€ æ–°å¢ï¼šè¨ˆç®—ä¸¦æ‰“å°æ¨™ç±¤åˆ†ä½ˆçµ±è¨ˆèˆ‡è³ªé‡æŒ‡æ¨™"""
        try:
            if len(labels) == 0:
                self.logger.warning("ç©ºæ¨™ç±¤åºåˆ—ï¼Œç„¡æ³•è¨ˆç®—çµ±è¨ˆ")
                return

            # æ¨™ç±¤åˆ†ä½ˆçµ±è¨ˆ
            label_counts = labels.value_counts().sort_index()
            total_samples = len(labels)

            self.logger.info(f"ğŸ“Š ä¿®å¾©ç‰ˆæ¨™ç±¤åˆ†ä½ˆçµ±è¨ˆ:")
            self.logger.info(f"   ç¸½æ¨£æœ¬æ•¸: {total_samples}")
            self.logger.info(f"   æ»¾å‹•çª—å£: {params.get('lookback_window', 500)}")
            self.logger.info(f"   lag: {params.get('lag', 12)}æœŸ")

            # å„é¡åˆ¥çµ±è¨ˆ
            for label_val in [0, 1, 2]:
                count = label_counts.get(label_val, 0)
                percentage = (count / total_samples) * 100
                label_name = {0: 'è³£å‡º', 1: 'æŒæœ‰', 2: 'è²·å…¥'}[label_val]
                self.logger.info(f"   {label_name}({label_val}): {count:,} ({percentage:.2f}%)")

            # æ¨™ç±¤è®ŠåŒ–é »ç‡
            if len(labels) > 1:
                changes = (labels.diff() != 0).sum()
                change_rate = changes / len(labels)
                self.logger.info(f"   æ¨™ç±¤è®ŠåŒ–é »ç‡: {change_rate:.3f} ({changes:,}/{total_samples:,})")

            # æª¢æŸ¥æ¨™ç±¤å¹³è¡¡æ€§
            min_class_ratio = min(label_counts) / total_samples
            max_class_ratio = max(label_counts) / total_samples
            imbalance_ratio = max_class_ratio / min_class_ratio

            if imbalance_ratio > 10:
                self.logger.warning(f"âš ï¸ æ¨™ç±¤åš´é‡ä¸å¹³è¡¡: æœ€å¤§/æœ€å°é¡åˆ¥æ¯”ä¾‹ = {imbalance_ratio:.2f}")
            elif imbalance_ratio > 5:
                self.logger.warning(f"âš ï¸ æ¨™ç±¤è¼•åº¦ä¸å¹³è¡¡: æœ€å¤§/æœ€å°é¡åˆ¥æ¯”ä¾‹ = {imbalance_ratio:.2f}")
            else:
                self.logger.info(f"âœ… æ¨™ç±¤å¹³è¡¡æ€§è‰¯å¥½: æœ€å¤§/æœ€å°é¡åˆ¥æ¯”ä¾‹ = {imbalance_ratio:.2f}")

            # æª¢æŸ¥å„é¡åˆ¥æ˜¯å¦éƒ½æœ‰ä»£è¡¨æ¨£æœ¬
            missing_classes = []
            for class_val in [0, 1, 2]:
                if label_counts.get(class_val, 0) == 0:
                    missing_classes.append(class_val)

            if missing_classes:
                class_names = [['è³£å‡º', 'æŒæœ‰', 'è²·å…¥'][i] for i in missing_classes]
                self.logger.error(f"âŒ ç¼ºå¤±é¡åˆ¥: {missing_classes} ({class_names})")
            else:
                self.logger.info("âœ… æ‰€æœ‰é¡åˆ¥éƒ½æœ‰ä»£è¡¨æ¨£æœ¬")

        except Exception as e:
            self.logger.error(f"æ¨™ç±¤çµ±è¨ˆè¨ˆç®—å¤±æ•—: {e}")

    def calculate_label_quality(self, labels: pd.Series, params: Dict) -> Dict:
        """è¨ˆç®—æ¨™ç±¤è³ªé‡æŒ‡æ¨™ï¼ˆå« Precision / Recall / F1 çš„ä»£ç†è©•åˆ†ï¼‰"""
        try:
            if len(labels) == 0:
                return {
                    'balance_score': 0,
                    'stability_score': 0,
                    'f1_score': 0,
                    'precision_macro': 0,
                    'recall_macro': 0
                }

            # 1) åˆ†å¸ƒå¹³è¡¡ï¼ˆè¶Šæ¥è¿‘ç†æƒ³ 25/50/25 è¶Šå¥½ï¼‰
            value_counts = labels.value_counts(normalize=True)
            target_dist = np.array([0.25, 0.5, 0.25])
            actual_dist = np.array([
                value_counts.get(0, 0.0),
                value_counts.get(1, 0.0),
                value_counts.get(2, 0.0)
            ])
            kl_div = np.sum(target_dist * np.log((target_dist + 1e-8) / (actual_dist + 1e-8)))
            balance_score = float(np.exp(-kl_div))

            # 2) ç©©å®šæ€§ï¼šæ¨™ç±¤åˆ‡æ›ç‡è¶Šä½è¶Šç©©å®š
            label_changes = int((labels.diff() != 0).sum())
            stability_score = float(max(0.0, 1.0 - label_changes / max(len(labels), 1)))

            # 3) æº–ç¢ºæ€§ä»£ç†ï¼šç”¨ã€Œé¡åˆ¥è¦†è“‹ç‡ã€è¿‘ä¼¼ precision/recall
            # æ²’æœ‰é æ¸¬å™¨ï¼Œæ¡ç”¨ä¿å®ˆä»£ç†ï¼šè‹¥æŸé¡åš´é‡ç¨€å°‘ï¼Œprecision/recall éƒ½æœƒå—é™
            class_presence = (actual_dist > 0).astype(float)
            precision_macro = float(class_presence.mean())  # è¦†è“‹è¶Šå…¨è¶Šé«˜
            recall_macro = float(1.0 - abs(actual_dist - target_dist).mean() / max(target_dist.max(), 1e-8))
            # ä»£ç† F1
            if precision_macro + recall_macro > 0:
                f1_macro = float(2 * precision_macro * recall_macro / (precision_macro + recall_macro))
            else:
                f1_macro = 0.0

            return {
                'balance_score': balance_score,
                'stability_score': stability_score,
                'f1_score': f1_macro,
                'precision_macro': precision_macro,
                'recall_macro': recall_macro,
                'distribution': actual_dist.tolist(),
                'total_samples': int(len(labels))
            }

        except Exception as e:
            self.logger.error(f"æ¨™ç±¤è³ªé‡è¨ˆç®—å¤±æ•—: {e}")
            return {
                'balance_score': 0,
                'stability_score': 0,
                'f1_score': 0,
                'precision_macro': 0,
                'recall_macro': 0
            }

    def objective(self, trial: optuna.Trial) -> float:
        """ä¿®å¾©ç‰ˆOptunaç›®æ¨™å‡½æ•¸ - ç¬¬1å±¤ï¼šæ»¾å‹•çª—å£æ¨™ç±¤åƒæ•¸å„ªåŒ–"""

        # ğŸš€ ä¿®å¾©ç‰ˆåƒæ•¸ï¼šåŒ…å«æ»¾å‹•çª—å£å¤§å°
        lag_min = self.scaled_config.get('label_lag_min', self.scaled_config.get('label_lag', 12) - 6)
        lag_max = self.scaled_config.get('label_lag_max', self.scaled_config.get('label_lag', 12) + 24)
        buy_q_min = self.scaled_config.get('label_buy_q_min', 0.68)
        buy_q_max = self.scaled_config.get('label_buy_q_max', 0.88)
        sell_q_min = self.scaled_config.get('label_sell_q_min', 0.12)
        sell_q_max = self.scaled_config.get('label_sell_q_max', 0.32)
        lookback_min = self.scaled_config.get('lookback_window_min', 400)
        lookback_max = self.scaled_config.get('lookback_window_max', 900)

        params = {
            # æ ¸å¿ƒåƒæ•¸
            'lag': trial.suggest_int('lag', lag_min, max(lag_min + 1, lag_max)),
            'threshold_method': trial.suggest_categorical('threshold_method',
                                                        ['quantile', 'fixed', 'adaptive', 'triple_barrier', 'stabilized']),

            # ğŸš€ æ–°å¢ï¼šæ»¾å‹•çª—å£å¤§å° (500-800)
            'lookback_window': trial.suggest_int('lookback_window', lookback_min, max(lookback_min + 50, lookback_max)),

            # âœ… ä¿®å¾©å„ªåŒ–ï¼šåŸºæ–¼å­¸è¡“æ–‡ç»çš„åˆ†ä½æ•¸ç¯„åœï¼ˆæ›´ä¿å®ˆï¼Œä¿¡è™Ÿè³ªé‡æ›´é«˜ï¼‰
            'buy_quantile': trial.suggest_float('buy_quantile', buy_q_min, buy_q_max),   # ä¾†è‡ª timeframe profile çš„ç¯„åœ
            'sell_quantile': trial.suggest_float('sell_quantile', sell_q_min, sell_q_max), # ä¾†è‡ª timeframe profile çš„ç¯„åœ

            # Fixedæ–¹æ³•åƒæ•¸
            'profit_threshold': trial.suggest_float('profit_threshold', 0.005, 0.03),
            'loss_threshold': trial.suggest_float('loss_threshold', -0.03, -0.005),

            # Adaptiveæ–¹æ³•åƒæ•¸
            'vol_multiplier': trial.suggest_float('vol_multiplier', 1.2, 2.0),
            # é¡å¤–é¡¯å¼æ§åˆ¶è‡ªé©æ‡‰æ³¢å‹•çª—å£ï¼Œä¿ƒé€²æ›´å¯†é›†è¨Šè™Ÿ
            'vol_window': trial.suggest_int('vol_window', 20, 40),
            
            # ğŸš€ å„ªåŒ–ï¼šTriple-Barrierç§»å‹•æ­¢æåƒæ•¸ï¼ˆæ–¹æ¡ˆBï¼š1:1.3ç­–ç•¥ï¼‰
            'profit_multiplier': trial.suggest_float('profit_multiplier', 1.4, 2.2),  # æ­¢ç›ˆï¼š1.4-2.2Ã—ATR
            'stop_multiplier': trial.suggest_float('stop_multiplier', 1.0, 1.7),      # æ­¢æï¼š1.0-1.7Ã—ATR
            'max_holding': trial.suggest_int('max_holding', 16, 24),                  # æœ€å¤§æŒæœ‰ï¼š16-24æœŸ
            'atr_period': trial.suggest_int('atr_period', 14, 18),                    # ATRé€±æœŸï¼š14-18ï¼ˆTask 2.3ï¼‰
            
            # ğŸš€ æ–°å¢ï¼šç§»å‹•æ­¢æåƒæ•¸ï¼ˆTask 2.1ï¼‰
            'enable_trailing_stop': trial.suggest_categorical('enable_trailing_stop', [True]),  # å¼·åˆ¶å•Ÿç”¨
            'trailing_activation_ratio': trial.suggest_float('trailing_activation_ratio', 0.4, 0.7),  # å•Ÿå‹•é–¾å€¼
            'trailing_distance_ratio': trial.suggest_float('trailing_distance_ratio', 0.5, 0.9),     # è·Ÿéš¨è·é›¢
            'trailing_lock_min_profit': trial.suggest_float('trailing_lock_min_profit', 0.2, 0.5),   # æœ€å°é–åˆ©
            
            # ğŸ”’ ç¡¬æ€§ç´„æŸï¼šé¢¨éšªå›å ±æ¯”ï¼ˆTask 2.2ï¼‰
            'min_risk_reward_ratio': 1.3,  # ç”¨æˆ¶è¦æ±‚ï¼šè‡³å°‘1:1.3

            # è³ªé‡æ§åˆ¶åƒæ•¸
            'min_samples': trial.suggest_int('min_samples', 1000, 5000),  # æé«˜æœ€å°æ¨£æœ¬è¦æ±‚
            'balance_weight': trial.suggest_float('balance_weight', 0.3, 0.7),
            'stability_weight': trial.suggest_float('stability_weight', 0.2, 0.5),

            # ç©©å®šåŒ–æ¨™ç±¤åƒæ•¸
            'fixed_lookback': trial.suggest_int('fixed_lookback', 1500, 3000),
            'min_threshold_gap': trial.suggest_float('min_threshold_gap', 0.003, 0.01),
            'max_noise_ratio': trial.suggest_float('max_noise_ratio', 0.25, 0.4),
            
            # ğŸš€ æ–°å¢ï¼šæ¨™ç±¤åˆ†å¸ƒæ§åˆ¶åƒæ•¸
            'target_hold_ratio': trial.suggest_float('target_hold_ratio', 0.48, 0.52),  # æ”¶æ–‚æŒæœ‰æ¯”ä¾‹
            'distribution_penalty': trial.suggest_float('distribution_penalty', 0.8, 1.5),  # æº«å’Œåˆ†å¸ƒæ‡²ç½°
            'target_distribution': trial.suggest_categorical('target_distribution', [
                (0.2, 0.5, 0.3),
                (0.25, 0.5, 0.25),
                (0.3, 0.4, 0.3)
            ]),
            'distribution_tolerance': trial.suggest_float('distribution_tolerance', 0.03, 0.08),
            'rebalance_method': trial.suggest_categorical('rebalance_method', ['cost_sensitive', 'threshold_shift', 'none']),
            'transaction_cost_bps': trial.suggest_float('transaction_cost_bps',
                                                        self.scaled_config.get('transaction_cost_bps_min', 5.0),
                                                        self.scaled_config.get('transaction_cost_bps_max', 15.0)),
            'sharpe_weight': trial.suggest_float('sharpe_weight', 0.30, 0.45),
            'win_weight': trial.suggest_float('win_weight', 0.20, 0.35),
            'trade_weight': trial.suggest_float('trade_weight', 0.15, 0.30),
            'label_weight': trial.suggest_float('label_weight', 0.15, 0.30),
            'target_trades_per_day': trial.suggest_float('target_trades_per_day', 2.0, 4.0)
        }

        try:
            # ğŸ”§ ä¿®å¾©ç‰ˆï¼šæ˜ç¡®æ„é€ æ–‡ä»¶è·¯å¾„å¹¶æ·»åŠ è°ƒè¯•ä¿¡æ¯
            ohlcv_file = self.data_path / "raw" / self.symbol / f"{self.symbol}_{self.timeframe}_ohlcv.parquet"
            self.logger.info(f"ğŸ” æŸ¥æ‰¾OHLCVæ–‡ä»¶: {ohlcv_file.absolute()}")
            
            if not ohlcv_file.exists():
                alternative_paths = [
                    f"data/raw/{self.symbol}/{self.symbol}_{self.timeframe}_ohlcv.parquet",
                    f"../data/raw/{self.symbol}/{self.symbol}_{self.timeframe}_ohlcv.parquet",
                    f"./{self.symbol}_{self.timeframe}_ohlcv.parquet"
                ]

                df = None
                for alt_path in alternative_paths:
                    if Path(alt_path).exists():
                        self.logger.info(f"ğŸ” æ‰¾åˆ°æ›¿ä»£è·¯å¾„: {alt_path}")
                        df = pd.read_parquet(alt_path, engine='pyarrow')
                        break

                if df is None:
                    self.logger.error(f"âŒ æœªæ‰¾åˆ°OHLCVæ•¸æ“šæ–‡ä»¶: {ohlcv_file.absolute()}")
                    raise FileNotFoundError(f"æœªæ‰¾åˆ°åŸå§‹ OHLCV æ•¸æ“š: {ohlcv_file}")
                else:
                    self.logger.info(f"âœ… æˆåŠŸåŠ è¼‰OHLCVæ•¸æ“š: {df.shape}")
            else:
                df = pd.read_parquet(ohlcv_file, engine='pyarrow')
                self.logger.info(f"âœ… åŠ è¼‰OHLCVæ•¸æ“š: {df.shape}")

            # ç¢ºå®šåƒ¹æ ¼åˆ—
            price_data = df['close']

            # ğŸ”§ ä¿®å¤ï¼šä¸€æ¬¡æ€§é¢„è®¡ç®—å…¨é‡rollingåˆ†ä½æ•°ï¼Œé¿å…é‡å¤è®¡ç®—
            lag = params['lag']
            lookback_window = params['lookback_window']
            actual_profit = price_data.pct_change(lag).shift(-lag)
            
            # å‘é‡åŒ–æ»šåŠ¨åˆ†ä½æ•°è®¡ç®—ï¼ˆä¸€æ¬¡æ€§å®Œæˆï¼‰
            self.logger.info(f"ğŸš€ å¼€å§‹å‘é‡åŒ–åˆ†ä½æ•°è®¡ç®—: window={lookback_window}")
            buy_quantile = params['buy_quantile']
            sell_quantile = params['sell_quantile']
            
            # é¢„è®¡ç®—å…¨é‡æ»šåŠ¨åˆ†ä½æ•°
            rolling_upper = actual_profit.rolling(window=lookback_window, min_periods=100).quantile(buy_quantile)
            rolling_lower = actual_profit.rolling(window=lookback_window, min_periods=100).quantile(sell_quantile)
            
            # ç¼“å­˜åˆ°å®ä¾‹å˜é‡é¿å…é‡å¤è®¡ç®—
            self._cached_rolling_upper = rolling_upper
            self._cached_rolling_lower = rolling_lower
            self.logger.info(f"âœ… åˆ†ä½æ•°é¢„è®¡ç®—å®Œæˆï¼Œç¼“å­˜{len(rolling_upper)}ä¸ªç‚¹")

            # ğŸš€ é¢¨éšªæ¯”ç´„æŸï¼šå¼·åˆ¶ 2:1ï¼ˆæ­¢ç›ˆ >= 2 Ã— æ­¢æï¼‰
            if params.get('threshold_method') == 'triple_barrier':
                pm = float(params.get('profit_multiplier', 2.0))
                sm = float(params.get('stop_multiplier', 1.0))
                if pm < 2.0 * sm:
                    # å°‡æ­¢ç›ˆæŠ¬é«˜åˆ°è‡³å°‘2xæ­¢æ
                    adjusted_pm = max(2.0 * sm, pm)
                    self.logger.info(f"ğŸ”’ é¢¨éšªæ¯”ç´„æŸ: profit_multiplier {pm:.2f} â†’ {adjusted_pm:.2f} (stop={sm:.2f})")
                    params['profit_multiplier'] = adjusted_pm

            # ğŸš€ æ”¹é€²ï¼šæ ¹æ“šæ–¹æ³•é¸æ“‡æ¨™ç±¤ç”Ÿæˆç­–ç•¥
            threshold_method = params.get('threshold_method', 'quantile')
            if threshold_method == 'triple_barrier':
                labels = self.generate_triple_barrier_labels(price_data, params)
                self.logger.info("ğŸš§ ä½¿ç”¨Triple-Barrieræ¨™ç±¤ç”Ÿæˆæ–¹æ³•")
            elif threshold_method == 'stabilized':
                labels = self.stabilized_label_generation(price_data, params)
                self.logger.info("ğŸ“Š ä½¿ç”¨ç©©å®šåŒ–å›ºå®šåˆ†ä½æ¨™ç±¤ç”Ÿæˆæ–¹æ³•")
            else:
                labels = self.generate_labels(price_data, params)
                self.logger.info(f"ğŸ“Š ä½¿ç”¨{threshold_method}åˆ†ä½æ•¸æ¨™ç±¤ç”Ÿæˆæ–¹æ³•")

            if len(labels) < params['min_samples']:
                return -999.0  # æ¨£æœ¬ä¸è¶³

            # è¨ˆç®—æ¨™ç±¤è³ªé‡
            quality_metrics = self.calculate_label_quality(labels, params)

            # è¨ˆç®—å¯¦éš›äº¤æ˜“ç¸¾æ•ˆæŒ‡æ¨™
            actual_returns = price_data.pct_change(params['lag']).shift(-params['lag'])
            strategy_metrics = self._compute_strategy_metrics(labels, actual_returns, params)
            sharpe_norm = self._normalize_sharpe(strategy_metrics['sharpe'])
            trade_freq_norm = self._normalize_trade_frequency(strategy_metrics['trades_per_day'], params)
            win_rate = strategy_metrics['win_rate']

            # KPI æ¬Šé‡è¨­å®š
            sharpe_weight = params.get('sharpe_weight', 0.35)
            win_weight = params.get('win_weight', 0.25)
            trade_weight = params.get('trade_weight', 0.20)
            label_weight = params.get('label_weight', 0.20)
            weight_sum = sharpe_weight + win_weight + trade_weight + label_weight
            if weight_sum <= 0:
                sharpe_weight = 0.35
                win_weight = 0.25
                trade_weight = 0.20
                label_weight = 0.20
                weight_sum = 1.0
            if weight_sum != 1.0:
                sharpe_weight /= weight_sum
                win_weight /= weight_sum
                trade_weight /= weight_sum
                label_weight /= weight_sum

            # å¤šç›®æ¨™å„ªåŒ–å¾—åˆ† + åˆ†å¸ƒç´„æŸ
            balance_score = quality_metrics['balance_score']
            stability_score = quality_metrics['stability_score']
            f1_score = quality_metrics['f1_score']
            
            # è¨ˆç®—å¯¦éš›æ¨™ç±¤åˆ†å¸ƒ
            label_counts = labels.value_counts(normalize=True)
            actual_hold_ratio = label_counts.get(1, 0)  # æŒæœ‰æ¯”ä¾‹
            actual_buy_ratio = label_counts.get(2, 0)   # è²·å…¥æ¯”ä¾‹  
            actual_sell_ratio = label_counts.get(0, 0)  # è³£å‡ºæ¯”ä¾‹

            # ğŸ”§ ç·Šæ€¥ä¿®å¾©ï¼šå°‡ç¡¬æ€§ç´„æŸæ”¹ç‚ºè»Ÿæ€§æ‡²ç½°ï¼Œé¿å…éåº¦æ‹’çµ•
            default_target_hold = self.scaled_config.get('target_hold_ratio', 0.50)
            default_trade_ratio = max(0.10, min(0.35, (1 - default_target_hold) / 2))  # é™ä½ä¸‹é™è‡³10%
            min_buy_ratio = self.scaled_config.get('label_min_buy_ratio', max(0.10, default_trade_ratio))
            min_sell_ratio = self.scaled_config.get('label_min_sell_ratio', max(0.10, default_trade_ratio))
            max_hold_ratio = self.scaled_config.get('label_max_hold_ratio', 0.80)  # æ”¾å¯¬è‡³80%
            target_distribution = params.get('target_distribution')
            if target_distribution is None:
                target_distribution = (
                    self.scaled_config.get('target_sell_ratio', default_trade_ratio),
                    params.get('target_hold_ratio', default_target_hold),
                    self.scaled_config.get('target_buy_ratio', default_trade_ratio)
                )
            
            # æ”¹ç‚ºè»Ÿæ€§æ‡²ç½°è€Œéç›´æ¥æ‹’çµ•ï¼ˆé™ä½æ‡²ç½°ä¿‚æ•¸é¿å…è² åˆ†ï¼‰
            severe_imbalance_penalty = 0.0
            if actual_hold_ratio > max_hold_ratio:
                severe_imbalance_penalty += (actual_hold_ratio - max_hold_ratio) * 0.5  # é™ä½è‡³0.5
                self.logger.warning(
                    f"âš ï¸ æŒæœ‰æ¯”ä¾‹éé«˜: {actual_hold_ratio:.2%} > {max_hold_ratio:.2%}ï¼Œ"
                    f"æ‡²ç½°={severe_imbalance_penalty:.3f}"
                )
            if actual_buy_ratio < min_buy_ratio:
                severe_imbalance_penalty += (min_buy_ratio - actual_buy_ratio) * 0.5  # é™ä½è‡³0.5
                self.logger.warning(
                    f"âš ï¸ è²·å…¥æ¯”ä¾‹éä½: {actual_buy_ratio:.2%} < {min_buy_ratio:.2%}ï¼Œ"
                    f"æ‡²ç½°={severe_imbalance_penalty:.3f}"
                )
            if actual_sell_ratio < min_sell_ratio:
                severe_imbalance_penalty += (min_sell_ratio - actual_sell_ratio) * 0.5  # é™ä½è‡³0.5
                self.logger.warning(
                    f"âš ï¸ è³£å‡ºæ¯”ä¾‹éä½: {actual_sell_ratio:.2%} < {min_sell_ratio:.2%}ï¼Œ"
                    f"æ‡²ç½°={severe_imbalance_penalty:.3f}"
                )
            
            # åªæœ‰æ¥µç«¯ä¸å¹³è¡¡ï¼ˆå¦‚æŸé¡å®Œå…¨ç¼ºå¤±ï¼‰æ‰ç›´æ¥æ‹’çµ•
            if actual_buy_ratio < 0.05 or actual_sell_ratio < 0.05:
                self.logger.error(
                    f"âŒ æ¥µç«¯ä¸å¹³è¡¡ï¼šè²·={actual_buy_ratio:.2%}, è³£={actual_sell_ratio:.2%}ï¼Œ"
                    f"æŸé¡å¹¾ä¹ç¼ºå¤±"
                )
                return -999.0
            
            # ğŸš€ æ–°å¢ï¼šåˆ†å¸ƒåå·®æ‡²ç½°
            target_hold = params['target_hold_ratio']
            hold_deviation = abs(actual_hold_ratio - target_hold)
            
            # ç¢ºä¿è²·è³£ä¿¡è™Ÿå‡è¡¡ï¼ˆå„è‡ªè‡³å°‘15%ï¼‰
            min_trade_ratio = 0.15
            buy_sell_penalty = 0
            if actual_buy_ratio < min_trade_ratio:
                buy_sell_penalty += (min_trade_ratio - actual_buy_ratio)
            if actual_sell_ratio < min_trade_ratio:
                buy_sell_penalty += (min_trade_ratio - actual_sell_ratio)
            # ä½è®ŠåŒ–ç‡æ‡²ç½°ï¼ˆé¼“å‹µé¿å…é•·æœŸæŒæœ‰å–®ä¸€é¡åˆ¥ï¼‰
            change_rate = float(((labels.diff() != 0).sum() / max(len(labels), 1)))
            low_change_penalty = max(0.0, 0.25 - change_rate)  # æœŸæœ›â‰¥0.25
            
            # åˆ†å¸ƒæ‡²ç½°ï¼ˆå¼·åŒ–ç‰ˆï¼‰ï¼šæŒæœ‰åå·® + è²·è³£ä¸è¶³ + ä½è®ŠåŒ–ç‡
            distribution_penalty = params['distribution_penalty'] * (hold_deviation + buy_sell_penalty + 0.5 * low_change_penalty)
            
            # ğŸš€ ä¿®å¾©ç‰ˆï¼šæ¬Šé‡æ­¸ä¸€åŒ–ï¼Œç¢ºä¿f1_scoreæ¬Šé‡ä¸ç‚ºè² 
            balance_weight = params['balance_weight']
            stability_weight = params['stability_weight']
            total_weight = balance_weight + stability_weight
            
            # ğŸ”§ ä¿®å¤ç‰ˆï¼šç¡®ä¿f1æƒé‡è‡³å°‘0.15ï¼ˆå¢åŠ å‡†ç¡®æ€§æƒé‡ï¼‰
            if total_weight > 0.85:  # ä»0.9æ”¹ä¸º0.85ï¼Œç»™f1æ›´å¤šæƒé‡
                scale_factor = 0.85 / total_weight
                balance_weight = balance_weight * scale_factor
                stability_weight = stability_weight * scale_factor
                self.logger.info(f"ğŸ”§ æƒé‡ç¼©æ”¾: åŸå§‹å’Œ={total_weight:.3f}, ç¼©æ”¾å› å­={scale_factor:.3f}")
            
            f1_weight = max(0.15, 1.0 - balance_weight - stability_weight)  # ä»0.1æ”¹ä¸º0.15
            
            # ğŸ”§ æ–°å¢ï¼šè®°å½•æƒé‡è°ƒæ•´è¿‡ç¨‹
            self.logger.info(f"âš–ï¸ æœ€ç»ˆæƒé‡: balance={balance_weight:.3f}, stability={stability_weight:.3f}, f1={f1_weight:.3f}")
            self.logger.info(f"ğŸ“Š åˆ†å¸ƒæƒ©ç½š: æŒæœ‰åå·®={hold_deviation:.3f}, ä¹°å–æƒ©ç½š={buy_sell_penalty:.3f}, æ€»æƒ©ç½š={distribution_penalty:.4f}")
            
            # å¤šç›®æ¨™åŠ æ¬Šç¸½åˆ†ï¼šæ¨™ç±¤å“è³ª + KPI - æ‡²ç½°
            label_component = (balance_score * balance_weight +
                               stability_score * stability_weight +
                               f1_score * f1_weight)
            kpi_component = (sharpe_norm * sharpe_weight +
                             win_rate * win_weight +
                             trade_freq_norm * trade_weight)
            final_score = (label_component * label_weight + 
                          kpi_component - 
                          distribution_penalty - 
                          severe_imbalance_penalty)
            
            # è¨˜éŒ„åˆ†å¸ƒä¿¡æ¯
            self.logger.info(f"ğŸ“Š æ¨™ç±¤åˆ†å¸ƒ: è³£å‡º={actual_sell_ratio:.1%}, æŒæœ‰={actual_hold_ratio:.1%}, è²·å…¥={actual_buy_ratio:.1%}")
            if self._last_distribution:
                dist_after = self._last_distribution
                self.logger.info(f"â™»ï¸ å†å¹³è¡¡åˆ†å¸ƒ -> è³£å‡º={dist_after[0]:.1%}, æŒæœ‰={dist_after[1]:.1%}, è²·å…¥={dist_after[2]:.1%}, èª¿æ•´ç­†æ•¸={self._last_rebalance_changes}")
            self.logger.info(f"ğŸ¯ ç›®æ¨™æŒæœ‰ç‡={target_hold:.1%}, å¯¦éš›åå·®={hold_deviation:.3f}")
            self.logger.info(f"âš–ï¸ æ¨™ç±¤æ¬Šé‡: balance={balance_weight:.3f}, stability={stability_weight:.3f}, f1={f1_weight:.3f}")
            self.logger.info(f"ğŸ“ˆ KPI: sharpe={strategy_metrics['sharpe']:.2f}, win={win_rate:.2f}, trades/day={strategy_metrics['trades_per_day']:.2f}")
            self.logger.info(f"âš–ï¸ Labelçµ„åˆ†={label_component:.4f}, KPIçµ„åˆ†={kpi_component:.4f}, åˆ†å¸ƒæ‡²ç½°={distribution_penalty:.4f}, æœ€çµ‚={final_score:.4f}")

            trial.set_user_attr("sharpe", strategy_metrics['sharpe'])
            trial.set_user_attr("win_rate", win_rate)
            trial.set_user_attr("trades_per_day", strategy_metrics['trades_per_day'])
            trial.set_user_attr("avg_return", strategy_metrics['avg_return'])
            trial.set_user_attr("kpi_component", kpi_component)
            trial.set_user_attr("label_component", label_component)
            trial.set_user_attr("distribution_penalty", distribution_penalty)
            trial.set_user_attr("params_sharpe_weight", sharpe_weight)
            trial.set_user_attr("params_win_weight", win_weight)
            trial.set_user_attr("params_trade_weight", trade_weight)
            trial.set_user_attr("params_label_weight", label_weight)

            # ğŸ”§ æ–°å¢ï¼šè®¡ç®—æŒæœ‰ç‡è¯¯å·®å¹¶ä¼ é€’ç»™Layer2
            hold_error = abs(actual_hold_ratio - target_hold)
            
            # å°†æŒæœ‰ç‡è¯¯å·®å†™å…¥trial.user_attrsä¾›Layer2å‚è€ƒ
            trial.set_user_attr("hold_error", hold_error)
            trial.set_user_attr("actual_hold_ratio", actual_hold_ratio)
            trial.set_user_attr("buy_sell_balance", actual_buy_ratio / max(actual_sell_ratio, 0.01))
            
            self.logger.info(f"ğŸ“Š æŒæœ‰ç‡ä¼ é€’: ç›®æ ‡={target_hold:.1%}, å®é™…={actual_hold_ratio:.1%}, è¯¯å·®={hold_error:.3f}")

            return final_score

        except Exception as e:
            self.logger.error(f"æ¨™ç±¤å„ªåŒ–éç¨‹å‡ºéŒ¯: {e}")
            return -999.0

    def optimize(self, n_trials: int = 200, timeframes: List[str] = None) -> Dict:
        """åŸ·è¡Œæ¨™ç±¤åƒæ•¸å„ªåŒ–ï¼ˆæ”¯æ´å¤šæ™‚æ¡†ï¼‰"""
        if timeframes is None:
            timeframes = [self.timeframe]

        results = {}
        meta_vol = self.scaled_config.get('meta_vol', 0.02)

        for tf in timeframes:
            self.logger.info(f"ğŸš€ é–‹å§‹æ¨™ç±¤ç”Ÿæˆåƒæ•¸å„ªåŒ–ï¼ˆç¬¬1å±¤ï¼‰ - æ™‚æ¡†: {tf}")
            self.timeframe = tf

            storage_url = None
            try:
                # å¯ç”±ç’°å¢ƒè®Šæ•¸æˆ– scaled_config æ§åˆ¶ï¼Œé è¨­ Noneï¼ˆin-memoryï¼‰
                storage_url = self.scaled_config.get('optuna_storage')
            except Exception:
                storage_url = None
            study = optuna.create_study(
                direction='maximize',
                study_name=f'label_optimization_layer1_{tf}',
                storage=storage_url,
                load_if_exists=bool(storage_url)
            )
            study.set_user_attr('meta_vol', meta_vol)

            study.optimize(self.objective, n_trials=n_trials)

            best_params = study.best_params
            best_score = study.best_value

            self.logger.info(f"æ¨™ç±¤å„ªåŒ–å®Œæˆ! æœ€ä½³å¾—åˆ†: {best_score:.4f}")
            self.logger.info(f"æœ€å„ªåƒæ•¸: {best_params}")

            try:
                processed_cleaned = Path(self.data_path) / "processed" / "cleaned" / f"{self.symbol}_{tf}"
                df2 = None
                # 1) processed ä¸‹çš„å›ºå®šæª”å
                for c in [processed_cleaned / "cleaned_ohlcv.parquet", processed_cleaned / "cleaned_ohlcv.pkl"]:
                    if c.exists():
                        df2 = read_dataframe(c)
                        self.logger.info(f"âœ… ä½¿ç”¨Layer0æ¸…æ´—æ•¸æ“šç”Ÿæˆæœ€çµ‚æ¨™ç±¤: {c}")
                        break
                # 2) processed ä¸‹çš„é›œæ¹Šæª”å
                if df2 is None and processed_cleaned.exists():
                    hashed = sorted(list(processed_cleaned.glob("cleaned_ohlcv_*.parquet")) +
                                    list(processed_cleaned.glob("cleaned_ohlcv_*.pkl")),
                                    key=lambda p: p.stat().st_mtime, reverse=True)
                    for c in hashed:
                        try:
                            df2 = read_dataframe(c)
                            self.logger.info(f"âœ… ä½¿ç”¨Layer0æ¸…æ´—æ•¸æ“š(é›œæ¹Š)ç”Ÿæˆæœ€çµ‚æ¨™ç±¤: {c}")
                            break
                        except Exception:
                            continue
                # 3) å›é€€åˆ° configs èˆŠè·¯å¾‘ï¼ˆå« parquet/pklï¼‰
                if df2 is None:
                    legacy_candidates = [
                        self.config_path / f"cleaned_ohlcv_{tf}.parquet",
                        self.config_path / f"cleaned_ohlcv_{tf}.pkl",
                    ]
                    for c in legacy_candidates:
                        if c.exists():
                            df2 = read_dataframe(c)
                            self.logger.info(f"âœ… ä½¿ç”¨Layer0æ¸…æ´—æ•¸æ“š(legacy)ç”Ÿæˆæœ€çµ‚æ¨™ç±¤: {c}")
                            break
                # 4) æœ€å¾Œå›é€€åŸå§‹ OHLCV
                if df2 is None:
                    ohlcv_file = self.data_path / "raw" / self.symbol / f"{self.symbol}_{tf}_ohlcv.parquet"
                    df2 = read_dataframe(ohlcv_file)
                    self.logger.info(f"âœ… ä½¿ç”¨åŸå§‹OHLCVæ•¸æ“šç”Ÿæˆæ¨™ç±¤: {ohlcv_file}")
                labeled_data = self.apply_labels(df2, best_params)
                final_quality = self.calculate_label_quality(labeled_data['label'], best_params)
            except Exception as e:
                self.logger.warning(f"ç„¡æ³•ç”Ÿæˆæœ€çµ‚æ¨™ç±¤: {e}")
                final_quality = {}
                labeled_data = None

            result = {
                'timeframe': tf,
                'best_params': best_params,
                'best_score': best_score,
                'n_trials': n_trials,
                'final_quality': final_quality,
                'meta_vol': meta_vol,
                'labeled_data': labeled_data,
                'optimization_history': [
                    {'trial': i, 'score': trial.value}
                    for i, trial in enumerate(study.trials)
                    if trial.value is not None
                ]
            }
            lag_min = self.scaled_config.get('label_lag_min', 1)
            lag_max = self.scaled_config.get('label_lag_max', 1000)
            result['best_params']['lag'] = int(max(lag_min, min(result['best_params'].get('lag', lag_min), lag_max)))
 
            json_safe = {k: v for k, v in result.items() if k != 'labeled_data'}
            output_file = self.config_path / "label_params.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(json_safe, f, indent=2, ensure_ascii=False)
 
            tf_output = self.config_path / f"label_params_{tf}.json"
            with open(tf_output, 'w', encoding='utf-8') as f:
                json.dump(json_safe, f, indent=2, ensure_ascii=False)

            self.logger.info(f"çµæœå·²ä¿å­˜è‡³: {output_file}")
            self.logger.info(f"æ™‚æ¡†å°ˆå±¬çµæœå·²ä¿å­˜è‡³: {tf_output}")

            # ç‰©åŒ–æ¨™ç±¤è³‡æ–™åˆ° processed/labelsï¼ˆæ”¯æ´ç‰ˆæœ¬å­ç›®éŒ„ï¼‰
            try:
                if labeled_data is not None and not labeled_data.empty:
                    # è‹¥å”èª¿å™¨å·²å»ºç«‹ results/latest.txtï¼Œå¯è®€å–æœ€æ–°ç‰ˆæœ¬ä½œç‚ºå­ç›®éŒ„
                    results_root = Path(__file__).resolve().parent.parent / "results"
                    latest_file = results_root / "latest.txt"
                    version_sub = None
                    if latest_file.exists():
                        try:
                            version_sub = latest_file.read_text(encoding="utf-8").strip()
                        except Exception:
                            version_sub = None
                    out_dir = Path(self.data_path) / "processed" / "labels" / f"{self.symbol}_{tf}"
                    if version_sub:
                        out_dir = out_dir / version_sub
                    out_dir.mkdir(parents=True, exist_ok=True)
                    target = out_dir / f"labels_{self.symbol}_{tf}.parquet"
                    label_file, _ = write_dataframe(labeled_data, target)
                    self.logger.info(f"âœ… Layer1 æ¨™ç±¤ç‰©åŒ–: {label_file}")
                    result['materialized_path'] = str(label_file)
                else:
                    self.logger.warning("âš ï¸ ç„¡å¯ç‰©åŒ–çš„æ¨™ç±¤è³‡æ–™ (labeled_data ç‚ºç©º)")
            except Exception as exc:
                self.logger.warning(f"âš ï¸ Layer1 æ¨™ç±¤ç‰©åŒ–å¤±æ•—: {exc}")
 
            results[tf] = result
 
        return results[self.timeframe] if len(timeframes) == 1 else results

    def apply_labels(self, data: pd.DataFrame, params: Dict[str, Any]) -> pd.DataFrame:
        """æ ¹æ“šåƒæ•¸ç”Ÿæˆæ¨™ç±¤ä¸¦é™„åŠ è‡³è³‡æ–™"""
        if 'close' not in data.columns:
            raise ValueError("è³‡æ–™å¿…é ˆåŒ…å«closeæ¬„ä½")

        labels = self.generate_labels(data['close'], params)
        if labels.empty:
            raise ValueError("Layer1é•·åº¦ä¸ä¸€è‡´: aligned=0, expected={}".format(len(data)))

        result = data.loc[labels.index].copy()
        if result.empty:
            raise ValueError("Layer1é•·åº¦ä¸ä¸€è‡´: aligned=0, expected={}".format(len(data)))

        result['label'] = labels

        # é™„åŠ è¡ç”Ÿæ¬„ä½ï¼ˆå¯¦éš›æ”¶ç›Šã€ä¿¡è™ŸæŒå€‰ã€KPIç²—ç®—ï¼‰ä¾›å¾ŒçºŒå±¤åƒè€ƒ
        try:
            lag = max(1, int(params.get('lag', 1)))
            aligned_close = data.loc[result.index, 'close']
            actual_returns = aligned_close.pct_change(lag).shift(-lag)
            metrics = self._compute_strategy_metrics(labels, actual_returns, params)

            result['forward_return'] = actual_returns
            result['label_position'] = labels.map({2: 1, 1: 0, 0: -1}).astype(int)
            result.attrs['layer1_metrics'] = metrics
        except Exception as exc:
            self.logger.warning(f"âš ï¸ é™„åŠ Layer1 KPIæ¬„ä½å¤±æ•—: {exc}")

        return result

    def apply_transform(self, data: pd.DataFrame, params: Dict[str, Any]) -> pd.DataFrame:
        """çµ±ä¸€çš„ç‰©åŒ–æ¥å£"""
        return self.apply_labels(data, params)


def main():
    """ä¸»å‡½æ•¸"""
    optimizer = LabelOptimizer(data_path='../data', config_path='../configs')
    result = optimizer.optimize(n_trials=200)
    print(f"æ¨™ç±¤å„ªåŒ–å®Œæˆ: {result['best_score']:.4f}")


if __name__ == "__main__":
    main()