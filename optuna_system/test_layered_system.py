# -*- coding: utf-8 -*-
"""
ğŸš€ é‡æ§‹ç‰ˆï¼šåˆ†å±¤Optunaç³»çµ±æ¸¬è©¦æ¨¡å¡Šï¼ˆè¤‡é›œåº¦ < 10ï¼‰
å°‡åŸæœ¬å¾©é›œåº¦45çš„å¤§å‡½æ•¸æ‹†åˆ†ç‚ºå¤šå€‹ç°¡å–®æ¸¬è©¦å‡½æ•¸
"""
import json
import logging
import sys
import importlib
from pathlib import Path

# æ·»åŠ è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))
sys.path.append(str(current_dir.parent))

from optuna_system.utils.logging_utils import setup_logging


def test_directory_structure() -> tuple:
    """æ¸¬è©¦ç›®éŒ„çµæ§‹"""
    print("ğŸ“‹ æ¸¬è©¦1: ç›®éŒ„çµæ§‹")
    print("-" * 40)
    
    try:
        required_dirs = ['optimizers', 'configs', 'results']
        missing_dirs = []

        for dir_name in required_dirs:
            dir_path = current_dir / dir_name
            if dir_path.exists():
                print(f"âœ… {dir_name}/ ç›®éŒ„å­˜åœ¨")
            else:
                print(f"âŒ {dir_name}/ ç›®éŒ„ç¼ºå¤±")
                missing_dirs.append(dir_name)

        success = not missing_dirs
        if success:
            print("âœ… ç›®éŒ„çµæ§‹ æ¸¬è©¦é€šé")
        else:
            print(f"âŒ ç›®éŒ„çµæ§‹ æ¸¬è©¦å¤±æ•—: ç¼ºå¤± {missing_dirs}")
        
        return success, None

    except Exception as e:
        print(f"âŒ ç›®éŒ„çµæ§‹æ¸¬è©¦ç•°å¸¸: {e}")
        return False, str(e)


def test_config_files() -> tuple:
    """æ¸¬è©¦é…ç½®æ–‡ä»¶"""
    print("ğŸ“‹ æ¸¬è©¦2: é…ç½®æ–‡ä»¶")
    print("-" * 40)

    try:
        config_files = [
            'kelly_params.json',
            'ensemble_params.json', 
            'polynomial_params.json',
            'confidence_params.json',
            'layer_params.json'
        ]

        missing_configs = []

        for config_file in config_files:
            config_path = current_dir / 'configs' / config_file
            if config_path.exists():
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        json.load(f)
                    print(f"âœ… {config_file} å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢º")
                except json.JSONDecodeError:
                    print(f"âš ï¸ {config_file} å­˜åœ¨ä½†JSONæ ¼å¼éŒ¯èª¤")
            else:
                print(f"âŒ {config_file} ä¸å­˜åœ¨")
                missing_configs.append(config_file)

        success = not missing_configs
        if success:
            print("âœ… é…ç½®æ–‡ä»¶ æ¸¬è©¦é€šé")
        else:
            print(f"âŒ é…ç½®æ–‡ä»¶ æ¸¬è©¦å¤±æ•—: ç¼ºå¤± {missing_configs}")
        
        return success, None

    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æ¸¬è©¦ç•°å¸¸: {e}")
        return False, str(e)


def test_module_imports() -> tuple:
    """æ¸¬è©¦æ¨¡å¡Šå°å…¥"""
    print("ğŸ“‹ æ¸¬è©¦3: æ¨¡å¡Šå°å…¥")
    print("-" * 40)

    try:
        # æ¸¬è©¦ç‰ˆæœ¬ç®¡ç†å™¨
        try:
            from version_manager import OptunaVersionManager
            print("âœ… OptunaVersionManager å°å…¥æˆåŠŸ")
        except ImportError as e:
            print(f"âŒ OptunaVersionManager å°å…¥å¤±æ•—: {e}")
            return False, str(e)

        # æ¸¬è©¦å”èª¿å™¨
        try:
            from coordinator import OptunaCoordinator
            print("âœ… OptunaCoordinator å°å…¥æˆåŠŸ")
        except ImportError as e:
            print(f"âŒ OptunaCoordinator å°å…¥å¤±æ•—: {e}")
            return False, str(e)

        # æ¸¬è©¦å„ªåŒ–å™¨æ¨¡å¡Š
        optimizer_modules = [
            ('optimizers.optuna_feature', 'FeatureOptimizer'),
            ('optimizers.optuna_label', 'LabelOptimizer'), 
            ('optimizers.optuna_cleaning', 'DataCleaningOptimizer'),
            ('optimizers.ensemble_optimizer', 'EnsembleOptimizer'),
            ('optimizers.kelly_optimizer', 'KellyOptimizer'),
        ]

        for module_path, module_name in optimizer_modules:
            try:
                module = importlib.import_module(module_path)
                getattr(module, module_name)
                print(f"âœ… {module_name} å°å…¥æˆåŠŸ")
            except (ImportError, AttributeError) as e:
                print(f"âŒ {module_name} å°å…¥å¤±æ•—: {e}")

        print("âœ… æ¨¡å¡Šå°å…¥ æ¸¬è©¦é€šé")
        return True, None

    except Exception as e:
        print(f"âŒ æ¨¡å¡Šå°å…¥æ¸¬è©¦ç•°å¸¸: {e}")
        return False, str(e)


def test_coordinator_creation() -> tuple:
    """æ¸¬è©¦å”èª¿å™¨å‰µå»º"""
    print("ğŸ“‹ æ¸¬è©¦4: å”èª¿å™¨å‰µå»º")
    print("-" * 40)

    try:
        from coordinator import OptunaCoordinator
        
        coordinator = OptunaCoordinator(
            data_path="data",
            symbol="BTCUSDT",
            timeframe="15m"
        )
        print("âœ… å”èª¿å™¨å‰µå»ºæˆåŠŸ")
        
        # æ¸¬è©¦åŸºæœ¬å±¬æ€§
        assert hasattr(coordinator, 'data_path')
        assert hasattr(coordinator, 'symbol') 
        assert hasattr(coordinator, 'timeframe')
        print("âœ… å”èª¿å™¨å±¬æ€§æª¢æŸ¥é€šé")
        
        return True, None

    except Exception as e:
        print(f"âŒ å”èª¿å™¨å‰µå»ºå¤±æ•—: {e}")
        return False, str(e)


def test_optimization_functions() -> tuple:
    """æ¸¬è©¦å„ªåŒ–å‡½æ•¸å¯ç”¨æ€§"""
    print("ğŸ“‹ æ¸¬è©¦5: å„ªåŒ–å‡½æ•¸")
    print("-" * 40)

    try:
        from coordinator import OptunaCoordinator
        
        coordinator = OptunaCoordinator(
            data_path="data",
            symbol="BTCUSDT",
            timeframe="15m"
        )
        
        # æª¢æŸ¥é—œéµæ–¹æ³•æ˜¯å¦å­˜åœ¨
        methods_to_check = [
            'run_layer0_data_cleaning',
            'run_layer1_label_optimization', 
            'run_layer2_feature_optimization',
            'quick_complete_optimization'
        ]
        
        for method_name in methods_to_check:
            if hasattr(coordinator, method_name):
                print(f"âœ… {method_name} æ–¹æ³•å­˜åœ¨")
            else:
                print(f"âŒ {method_name} æ–¹æ³•ç¼ºå¤±")
                return False, f"Missing method: {method_name}"
        
        print("âœ… å„ªåŒ–å‡½æ•¸ æ¸¬è©¦é€šé")
        return True, None

    except Exception as e:
        print(f"âŒ å„ªåŒ–å‡½æ•¸æ¸¬è©¦å¤±æ•—: {e}")
        return False, str(e)


def test_io_and_integrity() -> tuple:
    """æ¸¬è©¦ IO åŸå­å¯«å…¥èˆ‡ MD5 å®Œæ•´æ€§"""
    print("ğŸ“‹ æ¸¬è©¦6: IO åŸå­å¯«å…¥èˆ‡ MD5")
    print("-" * 40)

    try:
        from optuna_system.utils.io_utils import compute_file_md5, atomic_write_json
        import tempfile
        
        # æ¸¬è©¦ atomic_write_json
        test_data = {"test_key": "test_value", "score": 0.95}
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp:
            tmp_name = tmp.name
        tmp_path = Path(tmp_name)
        
        atomic_write_json(tmp_path, test_data)
        if tmp_path.exists():
            print(f"âœ… atomic_write_json å¯«å…¥æˆåŠŸ")
            with open(tmp_path, 'r', encoding='utf-8') as f:
                loaded = json.load(f)
            if loaded == test_data:
                print(f"âœ… atomic_write_json å…§å®¹é©—è­‰é€šé")
            else:
                print(f"âŒ atomic_write_json å…§å®¹ä¸ä¸€è‡´")
                return False, "Content mismatch"
        else:
            print(f"âŒ atomic_write_json æª”æ¡ˆæœªç”Ÿæˆ")
            return False, "File not created"
        
        # æ¸¬è©¦ MD5
        md5 = compute_file_md5(tmp_path)
        if md5 and len(md5) == 32:
            print(f"âœ… compute_file_md5 ç”Ÿæˆ MD5: {md5}")
        else:
            print(f"âŒ compute_file_md5 å¤±æ•—æˆ–æ ¼å¼éŒ¯èª¤")
            return False, "MD5 generation failed"
        
        tmp_path.unlink()
        print("âœ… IO åŸå­å¯«å…¥èˆ‡ MD5 æ¸¬è©¦é€šé")
        return True, None

    except Exception as e:
        print(f"âŒ IO æ¸¬è©¦ç•°å¸¸: {e}")
        return False, str(e)


def test_metadata_fields() -> tuple:
    """æ¸¬è©¦ metadata æ¬„ä½å­˜åœ¨æ€§"""
    print("ğŸ“‹ æ¸¬è©¦7: Metadata æ¬„ä½")
    print("-" * 40)

    try:
        # æª¢æŸ¥æœ€æ–°çš„ä¸‰å±¤ JSON æ˜¯å¦åŒ…å«å¿…è¦æ¬„ä½
        required_fields = ['params_hash', 'file_md5', 'file_path', 'data_shape', 'best_params', 'best_score']
        
        config_files = [
            current_dir / 'configs' / 'cleaning_params_15m.json',
            current_dir / 'configs' / 'label_params_15m.json',
            current_dir / 'configs' / 'feature_params_15m.json'
        ]
        
        for config_file in config_files:
            if not config_file.exists():
                print(f"âš ï¸ {config_file.name} ä¸å­˜åœ¨ï¼Œè·³é")
                continue
            
            with open(config_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            metadata = data.get('metadata', {})
            missing = [f for f in required_fields if f not in metadata and f not in data]
            if missing:
                print(f"âš ï¸ {config_file.name} ç¼ºå°‘æ¬„ä½: {missing}")
            else:
                print(f"âœ… {config_file.name} metadata æ¬„ä½å®Œæ•´")
        
        print("âœ… Metadata æ¬„ä½ æ¸¬è©¦é€šé")
        return True, None

    except Exception as e:
        print(f"âŒ Metadata æ¸¬è©¦ç•°å¸¸: {e}")
        return False, str(e)


def test_layered_system():
    """ğŸš€ é‡æ§‹ç‰ˆï¼šæ¸¬è©¦åˆ†å±¤Optunaç³»çµ±ï¼ˆè¤‡é›œåº¦ < 10ï¼‰"""
    print("ğŸš€ é–‹å§‹åˆ†å±¤Optunaç³»çµ±å®Œæ•´æ¸¬è©¦")
    print("=" * 60)

    # è¨­ç½®æ—¥èªŒ
    setup_logging()

    # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
    test_functions = [
        ('directory_structure', test_directory_structure),
        ('config_files', test_config_files),
        ('module_imports', test_module_imports),
        ('coordinator_creation', test_coordinator_creation),
        ('optimization_functions', test_optimization_functions),
        ('io_and_integrity', test_io_and_integrity),
        ('metadata_fields', test_metadata_fields),
    ]

    test_results = {}
    total_tests = len(test_functions)
    passed_tests = 0

    for test_name, test_func in test_functions:
        success, error = test_func()
        test_results[test_name] = success
        if success:
            passed_tests += 1
        print()  # æ·»åŠ ç©ºè¡Œåˆ†éš”

    # ============================================================
    # ç¸½çµæ¸¬è©¦çµæœ  
    # ============================================================
    print("=" * 60)
    print("ğŸ“Š æ¸¬è©¦çµæœç¸½çµ")
    print("=" * 60)

    for test_name, result in test_results.items():
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"{test_name}: {status}")

    print("-" * 60)
    success_rate = passed_tests / total_tests if total_tests > 0 else 0
    print(f"é€šéç‡: {passed_tests}/{total_tests} ({success_rate:.1%})")

    if success_rate >= 0.8:
        print("ğŸ‰ åˆ†å±¤ç³»çµ±æ¸¬è©¦åŸºæœ¬é€šé!")
        print("ğŸ’¡ å»ºè­°:")
        print("1. å¿«é€Ÿæ¸¬è©¦: python -c \"from coordinator import OptunaCoordinator; c=OptunaCoordinator(); print('åˆ†å±¤ç³»çµ±å°±ç·’')\"")
        print("2. å®Œæ•´æ¸¬è©¦: python run_layered_test.py")
        print("3. å°è¦æ¨¡å„ªåŒ–: python run_optimization.py --n_trials=10")
    else:
        print("âš ï¸ åˆ†å±¤ç³»çµ±å­˜åœ¨å•é¡Œï¼Œè«‹æª¢æŸ¥ä¸Šè¿°å¤±æ•—é …ç›®")

    return test_results


if __name__ == "__main__":
    # åŸ·è¡Œæ¸¬è©¦
    results = test_layered_system()
    
    # æ ¹æ“šçµæœé€€å‡º
    success_count = sum(results.values())
    total_count = len(results)
    
    if success_count >= total_count * 0.8:
        sys.exit(0)  # æˆåŠŸ
    else:
        sys.exit(1)  # å¤±æ•—