"""
ç”Ÿå­˜è€…åå·®æ ¡æ­£æ¨¡å—

åŸºäºå­¦æœ¯æ–‡çŒ®:
- Brown & Goetzmann (1995): Performance Persistence
- Elton et al. (1996): Survivorship Bias in Mutual Fund Performance  
- Efron & Tibshirani (1993): An Introduction to the Bootstrap

ä½œè€…: Optuna System Team
æ—¥æœŸ: 2025-10-31
"""

import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import numpy as np
import pandas as pd
from scipy import stats

logger = logging.getLogger(__name__)


class SurvivorshipBiasCorrector:
    """
    ç”Ÿå­˜è€…åå·®æ ¡æ­£å™¨
    
    ä½¿ç”¨Bootstrapæ–¹æ³•æ ¡æ­£ä»…åŒ…å«å¹¸å­˜èµ„äº§çš„å›æµ‹ç»“æœ
    """
    
    def __init__(self,
                 failure_db_path: str = "data/raw/failure_events.json"):
        """
        åˆå§‹åŒ–æ ¡æ­£å™¨
        
        Args:
            failure_db_path: å¤±è´¥äº‹ä»¶æ•°æ®åº“è·¯å¾„
        """
        self.logger = logger  # å…ˆåˆå§‹åŒ–logger
        self.failure_db_path = Path(failure_db_path)
        self.failure_events = self._load_failure_events()
        
    def _load_failure_events(self) -> List[Dict]:
        """åŠ è½½å¤±è´¥äº‹ä»¶æ•°æ®åº“"""
        try:
            with open(self.failure_db_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('events', [])
        except FileNotFoundError:
            self.logger.warning(f"å¤±è´¥äº‹ä»¶æ•°æ®åº“æœªæ‰¾åˆ°: {self.failure_db_path}")
            return []
    
    def calculate_bias(self,
                      strategy_returns: pd.Series,
                      method: str = 'bootstrap',
                      n_bootstrap: int = 1000) -> Dict:
        """
        è®¡ç®—ç”Ÿå­˜è€…åå·®
        
        Args:
            strategy_returns: ç­–ç•¥æ”¶ç›Šç‡åºåˆ—
            method: æ ¡æ­£æ–¹æ³• ('bootstrap', 'analytical')
            n_bootstrap: Bootstrapè¿­ä»£æ¬¡æ•°
            
        Returns:
            DictåŒ…å«:
                - raw_sharpe: åŸå§‹å¤æ™®æ¯”ç‡
                - corrected_sharpe: æ ¡æ­£åå¤æ™®æ¯”ç‡
                - sharpe_bias: å¤æ™®åå·®
                - raw_return: åŸå§‹å¹´åŒ–æ”¶ç›Š
                - corrected_return: æ ¡æ­£åå¹´åŒ–æ”¶ç›Š
                - return_bias: æ”¶ç›Šåå·®
                - ci_lower: 95%ç½®ä¿¡åŒºé—´ä¸‹ç•Œ
                - ci_upper: 95%ç½®ä¿¡åŒºé—´ä¸Šç•Œ
        """
        if strategy_returns.empty:
            return self._empty_result()
        
        # è®¡ç®—åŸå§‹æŒ‡æ ‡
        raw_sharpe = self._calculate_sharpe(strategy_returns)
        raw_return = strategy_returns.mean() * 252  # å¹´åŒ–
        
        if method == 'bootstrap':
            result = self._bootstrap_correction(strategy_returns, n_bootstrap)
        elif method == 'analytical':
            result = self._analytical_correction(strategy_returns)
        else:
            raise ValueError(f"Unknown method: {method}")
        
        result.update({
            'raw_sharpe': raw_sharpe,
            'raw_return': raw_return,
        })
        
        self.logger.info(f"ğŸ“Š ç”Ÿå­˜è€…åå·®æ ¡æ­£:")
        self.logger.info(f"   åŸå§‹Sharpe: {raw_sharpe:.3f}")
        self.logger.info(f"   æ ¡æ­£Sharpe: {result['corrected_sharpe']:.3f}")
        self.logger.info(f"   åå·®: {result['sharpe_bias']:.3f} ({result['sharpe_bias']/raw_sharpe*100:.1f}%)")
        
        return result
    
    def _bootstrap_correction(self,
                             returns: pd.Series,
                             n_iterations: int = 1000) -> Dict:
        """
        Bootstrapæ ¡æ­£æ–¹æ³•
        
        åŸºäºEfron & Tibshirani (1993)
        """
        self.logger.info(f"ğŸ”„ æ‰§è¡ŒBootstrapæ ¡æ­£ (n={n_iterations})...")
        
        sharpes = []
        annual_returns = []
        
        for i in range(n_iterations):
            # é‡é‡‡æ ·ï¼Œæ¨¡æ‹ŸåŒ…å«å¤±è´¥æ¡ˆä¾‹
            sampled_returns = self._resample_with_failures(returns)
            
            # è®¡ç®—æŒ‡æ ‡
            sharpe = self._calculate_sharpe(sampled_returns)
            annual_ret = sampled_returns.mean() * 252
            
            sharpes.append(sharpe)
            annual_returns.append(annual_ret)
            
            if (i + 1) % 200 == 0:
                self.logger.debug(f"   å®Œæˆ {i+1}/{n_iterations} æ¬¡è¿­ä»£")
        
        # è®¡ç®—ç»Ÿè®¡é‡
        sharpes = np.array(sharpes)
        annual_returns = np.array(annual_returns)
        
        corrected_sharpe = np.mean(sharpes)
        corrected_return = np.mean(annual_returns)
        
        # 95%ç½®ä¿¡åŒºé—´
        ci_lower_sharpe = np.percentile(sharpes, 2.5)
        ci_upper_sharpe = np.percentile(sharpes, 97.5)
        
        ci_lower_return = np.percentile(annual_returns, 2.5)
        ci_upper_return = np.percentile(annual_returns, 97.5)
        
        return {
            'corrected_sharpe': corrected_sharpe,
            'sharpe_bias': self._calculate_sharpe(returns) - corrected_sharpe,
            'corrected_return': corrected_return,
            'return_bias': (returns.mean() * 252) - corrected_return,
            'ci_lower_sharpe': ci_lower_sharpe,
            'ci_upper_sharpe': ci_upper_sharpe,
            'ci_lower_return': ci_lower_return,
            'ci_upper_return': ci_upper_return,
            'bootstrap_samples': n_iterations
        }
    
    def _resample_with_failures(self, returns: pd.Series) -> pd.Series:
        """
        é‡é‡‡æ ·ï¼Œæ³¨å…¥å¤±è´¥æ¡ˆä¾‹
        
        æ¨¡æ‹Ÿç­–ç•¥åœ¨åŒ…å«å¤±è´¥èµ„äº§çš„å®‡å®™ä¸­çš„è¡¨ç°
        """
        n = len(returns)
        
        # éšæœºé€‰æ‹©æ˜¯å¦æ³¨å…¥å¤±è´¥äº‹ä»¶
        # åŸºäºå†å²å¤±è´¥ç‡ï¼ˆçº¦10-15%çš„å¸ç§æœ€ç»ˆå¤±è´¥ï¼‰
        if np.random.rand() < 0.12 and self.failure_events:
            # é€‰æ‹©ä¸€ä¸ªå¤±è´¥äº‹ä»¶
            event = np.random.choice(self.failure_events)
            
            # åœ¨éšæœºä½ç½®æ³¨å…¥å¤±è´¥
            inject_idx = np.random.randint(n // 4, 3 * n // 4)  # ä¸­é—´æ®µ
            crash_duration = event.get('time_to_crash_days', 5)
            crash_pct = event.get('drawdown_pct', -95) / 100
            
            # åˆ›å»ºå‰¯æœ¬
            modified_returns = returns.copy()
            
            # æ³¨å…¥å´©ç›˜æ”¶ç›Š
            for i in range(inject_idx, min(inject_idx + crash_duration, n)):
                # åˆ†å¸ƒå¼å´©ç›˜ï¼ˆä¸æ˜¯å•æ—¥ï¼‰
                modified_returns.iloc[i] = crash_pct / crash_duration
            
            return modified_returns
        else:
            # æ­£å¸¸Bootstrapé‡é‡‡æ ·
            return returns.sample(n=n, replace=True).reset_index(drop=True)
    
    def _analytical_correction(self, returns: pd.Series) -> Dict:
        """
        è§£ææ ¡æ­£æ–¹æ³•
        
        åŸºäºElton et al. (1996)çš„ç ”ç©¶
        å‡è®¾åå·®ä¸ºå¹´åŒ–æ”¶ç›Šçš„2-3%ï¼ŒSharpeçš„15-20%
        """
        raw_sharpe = self._calculate_sharpe(returns)
        raw_return = returns.mean() * 252
        
        # ä¿å®ˆä¼°è®¡åå·®
        sharpe_bias_pct = 0.18  # 18% Sharpeé«˜ä¼°
        return_bias_annual = 0.025  # 2.5% å¹´åŒ–æ”¶ç›Šé«˜ä¼°
        
        corrected_sharpe = raw_sharpe * (1 - sharpe_bias_pct)
        corrected_return = raw_return - return_bias_annual
        
        return {
            'corrected_sharpe': corrected_sharpe,
            'sharpe_bias': raw_sharpe - corrected_sharpe,
            'corrected_return': corrected_return,
            'return_bias': return_bias_annual,
            'ci_lower_sharpe': corrected_sharpe * 0.9,
            'ci_upper_sharpe': corrected_sharpe * 1.1,
            'ci_lower_return': corrected_return - 0.01,
            'ci_upper_return': corrected_return + 0.01
        }
    
    def _calculate_sharpe(self, returns: pd.Series, risk_free_rate: float = 0.02) -> float:
        """è®¡ç®—å¹´åŒ–å¤æ™®æ¯”ç‡"""
        if returns.empty:
            return 0.0
        
        excess_returns = returns - (risk_free_rate / 252)
        std = excess_returns.std()
        
        # é›¶æ ‡å‡†å·®æˆ–æ¥è¿‘é›¶
        if std == 0 or std < 1e-10:
            return 0.0
        
        sharpe = (excess_returns.mean() / std) * np.sqrt(252)
        return sharpe
    
    def _empty_result(self) -> Dict:
        """ç©ºç»“æœ"""
        return {
            'raw_sharpe': 0.0,
            'corrected_sharpe': 0.0,
            'sharpe_bias': 0.0,
            'raw_return': 0.0,
            'corrected_return': 0.0,
            'return_bias': 0.0,
            'ci_lower_sharpe': 0.0,
            'ci_upper_sharpe': 0.0
        }
    
    def get_failure_statistics(self) -> Dict:
        """è·å–å¤±è´¥äº‹ä»¶ç»Ÿè®¡"""
        if not self.failure_events:
            return {}
        
        drawdowns = [e.get('drawdown_pct', 0) for e in self.failure_events]
        crash_days = [e.get('time_to_crash_days', 0) for e in self.failure_events]
        
        return {
            'total_events': len(self.failure_events),
            'avg_drawdown': np.mean(drawdowns),
            'median_drawdown': np.median(drawdowns),
            'avg_crash_days': np.mean(crash_days),
            'recovery_rate': sum(1 for e in self.failure_events if e.get('recovery', False)) / len(self.failure_events)
        }


class FailureEventDatabase:
    """å¤±è´¥äº‹ä»¶æ•°æ®åº“"""
    
    def __init__(self, db_path: str = "data/raw/failure_events.json"):
        self.db_path = Path(db_path)
        self.events = self._load_events()
        self.logger = logger
    
    def _load_events(self) -> List[Dict]:
        """åŠ è½½äº‹ä»¶"""
        try:
            with open(self.db_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('events', [])
        except FileNotFoundError:
            self.logger.warning(f"æ•°æ®åº“æœªæ‰¾åˆ°: {self.db_path}")
            return []
    
    def get_event_by_symbol(self, symbol: str) -> Optional[Dict]:
        """æ ¹æ®äº¤æ˜“å¯¹è·å–äº‹ä»¶"""
        for event in self.events:
            if event.get('symbol') == symbol:
                return event
        return None
    
    def get_events_by_type(self, event_type: str) -> List[Dict]:
        """æ ¹æ®ç±»å‹è·å–äº‹ä»¶"""
        return [e for e in self.events if e.get('event_type') == event_type]
    
    def get_similar_events(self,
                          features: Dict,
                          k: int = 5) -> List[Dict]:
        """
        æ‰¾åˆ°ç›¸ä¼¼çš„å†å²äº‹ä»¶
        
        ä½¿ç”¨ç®€å•çš„æ¬§æ°è·ç¦»
        """
        if not self.events:
            return []
        
        similarities = []
        
        for event in self.events:
            event_features = event.get('pre_crash_features', {})
            
            # è®¡ç®—ç‰¹å¾ç›¸ä¼¼åº¦
            distance = self._calculate_feature_distance(features, event_features)
            similarities.append((event, distance))
        
        # æ’åºå¹¶è¿”å›æœ€ç›¸ä¼¼çš„kä¸ª
        similarities.sort(key=lambda x: x[1])
        return [e[0] for e in similarities[:k]]
    
    def _calculate_feature_distance(self,
                                    features1: Dict,
                                    features2: Dict) -> float:
        """è®¡ç®—ç‰¹å¾æ¬§æ°è·ç¦»"""
        common_keys = set(features1.keys()) & set(features2.keys())
        
        if not common_keys:
            return float('inf')
        
        distance = 0.0
        for key in common_keys:
            v1 = features1[key]
            v2 = features2[key]
            distance += (v1 - v2) ** 2
        
        return np.sqrt(distance / len(common_keys))
    
    def calculate_failure_probability(self,
                                     current_features: Dict) -> float:
        """
        è®¡ç®—å½“å‰ç‰¹å¾ä¸‹çš„å¤±è´¥æ¦‚ç‡
        
        ç®€å•æ–¹æ³•ï¼šåŸºäºç›¸ä¼¼å†å²äº‹ä»¶çš„å¤±è´¥ç‡
        """
        similar_events = self.get_similar_events(current_features, k=5)
        
        if not similar_events:
            return 0.05  # é»˜è®¤5%å¤±è´¥ç‡
        
        # è®¡ç®—ç›¸ä¼¼äº‹ä»¶çš„å¤±è´¥ç‡
        failed_count = sum(1 for e in similar_events if not e.get('recovery', False))
        
        return failed_count / len(similar_events)


def apply_survivorship_correction(backtest_results: Dict,
                                  method: str = 'bootstrap',
                                  n_bootstrap: int = 1000) -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šåº”ç”¨ç”Ÿå­˜è€…åå·®æ ¡æ­£åˆ°å›æµ‹ç»“æœ
    
    Args:
        backtest_results: åŒ…å«returns_seriesçš„å›æµ‹ç»“æœå­—å…¸
        method: æ ¡æ­£æ–¹æ³•
        n_bootstrap: Bootstrapæ¬¡æ•°
        
    Returns:
        å¢å¼ºçš„ç»“æœå­—å…¸ï¼ŒåŒ…å«æ ¡æ­£åçš„æŒ‡æ ‡
    """
    corrector = SurvivorshipBiasCorrector()
    
    returns = backtest_results.get('returns_series', pd.Series())
    
    if returns.empty:
        logger.warning("æœªæ‰¾åˆ°æ”¶ç›Šç‡åºåˆ—ï¼Œè·³è¿‡ç”Ÿå­˜è€…åå·®æ ¡æ­£")
        return backtest_results
    
    correction = corrector.calculate_bias(returns, method=method, n_bootstrap=n_bootstrap)
    
    # æ·»åŠ æ ¡æ­£ç»“æœ
    backtest_results['survivorship_correction'] = correction
    backtest_results['corrected_sharpe'] = correction['corrected_sharpe']
    backtest_results['corrected_annual_return'] = correction['corrected_return']
    
    return backtest_results

