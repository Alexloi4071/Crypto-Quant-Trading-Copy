from pathlib import Path
import os
import sys

from optuna_system.coordinator import OptunaCoordinator
from config.timeframe_scaler import MultiTimeframeCoordinator


def ensure_utf8_console() -> None:
    """å¼·åˆ¶ Windows ä¸»æ§å°èˆ‡ Python I/O ä½¿ç”¨ UTF-8ï¼Œé¿å…ä¸­æ–‡/ç¬¦è™Ÿäº‚ç¢¼"""
    os.environ.setdefault("PYTHONIOENCODING", "utf-8")
    os.environ.setdefault("PYTHONUTF8", "1")

    if os.name == "nt":
        try:
            import ctypes

            kernel32 = ctypes.windll.kernel32
            kernel32.SetConsoleOutputCP(65001)
            kernel32.SetConsoleCP(65001)
        except Exception:
            pass

    for stream in (sys.stdout, sys.stderr):
        if hasattr(stream, "reconfigure"):
            try:
                stream.reconfigure(encoding="utf-8")
            except Exception:
                pass


ensure_utf8_console()

PROJECT_ROOT = Path(__file__).resolve().parent
DATA_PATH = PROJECT_ROOT / "data"

# ğŸ¯ Trialsæ•°é‡é…ç½®ï¼ˆåŸºäºå­¦æœ¯è®¡ç®—ï¼‰
# 
# å‚æ•°ç©ºé—´åˆ†æï¼š
# - Layer1 Primary: 10ç»´å‚æ•° â†’ æœ€å°100 trials (Bergstra: 10Ã—d)
# - Layer1 Meta: 6ç»´å‚æ•°ï¼ŒåŒç›®æ ‡ â†’ NSGA-IIæ¨è400-600 trials
# - Layer2: 20ç»´å‚æ•° (7ç‰¹å¾+13æ¨¡å‹) â†’ æœ€å°200 trials
# 
# å­¦æœ¯ä¾æ®ï¼š
# - Bergstra & Bengio (2012): n_trials â‰¥ 10 Ã— å‚æ•°ç»´åº¦
# - Akiba et al. (2019): TPEé‡‡æ ·å™¨30+ trialsåæ•ˆæœæ˜¾è‘—
# - Deb et al. (2002): NSGA-IIæ¨è population(30-40) Ã— generations(10-20)
# 
# ä¸‰ç§è¿è¡Œæ¨¡å¼ï¼š
#   1. BUGæ£€æŸ¥:  L1=5,   L2=5   (3-5åˆ†é’Ÿï¼ŒéªŒè¯æ— é”™è¯¯)
#   2. æ ‡å‡†æµ‹è¯•: L1=50,  L2=100 (30-40åˆ†é’Ÿï¼Œå……åˆ†éªŒè¯) âœ… æ¨è
#   3. å®Œæ•´ä¼˜åŒ–: L1=600, L2=250 (2-4å°æ—¶ï¼Œç”Ÿäº§ç¯å¢ƒ)
# 
# å½“å‰é…ç½®: å®Œæ•´ä¼˜åŒ–æ¨¡å¼
TEST_MODE = False  # æ”¹ä¸º True ä½¿ç”¨æ ‡å‡†æµ‹è¯•æ¨¡å¼
if TEST_MODE:
    # ğŸ¯ æ ‡å‡†æµ‹è¯•æ¨¡å¼ï¼šå……åˆ†éªŒè¯æ‰€æœ‰ä¿®å¤
    DEFAULT_L1_TRIALS = 50   # Primaryæœ€ä¼˜(from 10) + Meta NSGA-II(40, pop=30)
    DEFAULT_L2_TRIALS = 100  # 5ç§ç‰¹å¾æ–¹æ³• Ã— 20 trials = å……åˆ†æ¢ç´¢
    print("ğŸ¯ æ ‡å‡†æµ‹è¯•æ¨¡å¼: L1=50 trials, L2=100 trials")
    print("   é¢„è®¡æ—¶é—´: 30-40åˆ†é’Ÿ")
    print("   ç›®æ ‡: å……åˆ†éªŒè¯æ‰€æœ‰ä¿®å¤æ•ˆæœ")
    print("   å­¦æœ¯ä¾æ®: Bergstra (10Ã—d), Akiba (TPE 30+)")
else:
    # ğŸš€ å®Œæ•´ä¼˜åŒ–æ¨¡å¼ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
    DEFAULT_L1_TRIALS = 600  # Primaryæœ€ä¼˜(from 200) + Meta NSGA-II(400, pop=40Ã—gen=15)
    DEFAULT_L2_TRIALS = 250  # 5ç§ç‰¹å¾æ–¹æ³• Ã— 50 trials = å……åˆ†æ¢ç´¢
    print("ğŸš€ å®Œæ•´ä¼˜åŒ–æ¨¡å¼: L1=600 trials, L2=250 trials")
    print("   é¢„è®¡æ—¶é—´: 2-4å°æ—¶")
    print("   ç›®æ ‡: æœ€ç»ˆç”Ÿäº§ç¯å¢ƒä¼˜åŒ–")
    print("   NSGA-IIé…ç½®: population=40, generations=15")

# Force reload and print optimizer module info to ensure latest version
try:
    import importlib
    import optuna_system.optimizers.optuna_feature as _ofeat
    print("FeatureOptimizer file =>", _ofeat.__file__)
    print("FeatureOptimizer PATCH_ID =>", getattr(_ofeat, "PATCH_ID", None))
    importlib.reload(_ofeat)
except Exception as _e:
    print("[WARN] Could not pre-load FeatureOptimizer:", _e)

multi_scaler = MultiTimeframeCoordinator(symbol='BTCUSDT', data_path=str(DATA_PATH))
scaled_config = multi_scaler.get_scaled_config_for_timeframe('15m')

coordinator = OptunaCoordinator(
    symbol='BTCUSDT',
    timeframe='15m',
    data_path=str(DATA_PATH),
    scaled_config=scaled_config
)

print('--- Layer0 ---')
processed_cleaned_dir = DATA_PATH / 'processed' / 'cleaned' / 'BTCUSDT_15m'
L1_TRIALS = int(os.getenv('L1_TRIALS', str(DEFAULT_L1_TRIALS)))
L2_TRIALS = int(os.getenv('L2_TRIALS', str(DEFAULT_L2_TRIALS)))
need_layer0 = True
try:
    if processed_cleaned_dir.exists():
        has_any = any(processed_cleaned_dir.glob('cleaned_ohlcv*.parquet')) or \
                  any(processed_cleaned_dir.glob('cleaned_ohlcv*.pkl')) or \
                  any(processed_cleaned_dir.glob('cleaned_ohlcv*.pickle'))
        need_layer0 = not has_any
except Exception:
    pass

if need_layer0:
    layer0_result = coordinator.run_layer0_data_cleaning(n_trials=50)
    print(layer0_result)
else:
    print(f"è·³é Layer0ï¼Œå·²å­˜åœ¨æ¸…æ´—æª”: {processed_cleaned_dir}")

print('--- Layer1 ---')
layer1_result = coordinator.run_layer1_label_optimization(n_trials=L1_TRIALS)
print(layer1_result)

# âœ… Layer1çµæœé©—è­‰
if isinstance(layer1_result, dict):
    if 'best_score' in layer1_result:
        print(f"\nğŸ“Š Layer1åˆ†æ:")
        print(f"  F1åˆ†æ•¸: {layer1_result['best_score']:.4f}")
        if layer1_result['best_score'] < 0.45:
            print(f"  âš ï¸ è­¦å‘Š: åˆ†æ•¸ä½æ–¼é–¾å€¼0.45")

        # æª¢æŸ¥æ¨™ç±¤åˆ†å¸ƒ
        metadata = layer1_result.get('metadata', {})
        if 'label_distribution' in metadata or 'data_columns' in metadata:
            print(f"  ç‰¹å¾µä¿¡æ¯: {metadata.get('data_shape', 'N/A')}")
    else:
        print("âš ï¸ Layer1 æœªæä¾› best_scoreï¼Œè¼¸å‡º: ", layer1_result)

print('\n' + '='*60)

print('--- Layer2 ---')
layer2_result = coordinator.run_layer2_feature_optimization(n_trials=L2_TRIALS)
print(layer2_result)

if isinstance(layer2_result, dict):
    if 'best_score' in layer2_result:
        print(f"\nğŸ“Š Layer2åˆ†æ:")
        print(f"  æœ€ä½³åˆ†æ•¸: {layer2_result['best_score']:.4f}")
        mat_path = layer2_result.get('materialized_path') or layer2_result.get('metadata', {}).get('materialized_path')
        if mat_path:
            print(f"  ç‰©åŒ–ç‰¹å¾µæª”æ¡ˆ: {mat_path}")
    else:
        print("âš ï¸ Layer2 æœªæä¾› best_scoreï¼Œè¼¸å‡º: ", layer2_result)

print('\n' + '='*60)