import os
import json
import pandas as pd
import optuna
from optuna import Trial
from optuna.samplers import TPESampler
from optuna.pruners import MedianPruner

# å¼•å…¥ä½ çš„ feature pipeline å’Œ model trainer
from feature_pipeline import load_features, evaluate_model

def objective(trial: Trial):
    # å®šç¾©ä½ è¦å„ªåŒ–çš„è¶…åƒæ•¸ç¯„åœ
    params = {
        'feature_selection_method': trial.suggest_categorical('feature_selection_method', ['mutual_info', 'f_classif']),
        'noise_reduction': trial.suggest_categorical('noise_reduction', [True, False]),
        'feature_interaction': trial.suggest_categorical('feature_interaction', [True, False]),
        'lag': trial.suggest_int('lag', 1, 20),
        'profit_quantile': trial.suggest_float('profit_quantile', 0.5, 1.0),
        'loss_quantile': trial.suggest_float('loss_quantile', 0.0, 0.5),
        'lookback_window': trial.suggest_int('lookback_window', 100, 1000),
        'coarse_k': trial.suggest_int('coarse_k', 10, 200),
        'fine_ratio': trial.suggest_float('fine_ratio', 0.1, 1.0),
        'stability_threshold': trial.suggest_float('stability_threshold', 0.1, 1.0),
        'correlation_threshold': trial.suggest_float('correlation_threshold', 0.1, 1.0),
        'model_type': trial.suggest_categorical('model_type', ['xgboost', 'extra_trees']),
    }

    # ä¾ model_type è¨­å®šæ¨¡å‹ç›¸é—œåƒæ•¸
    if params['model_type'] == 'xgboost':
        params.update({
            'xgb_n_estimators': trial.suggest_int('xgb_n_estimators', 100, 1000),
            'xgb_learning_rate': trial.suggest_float('xgb_learning_rate', 0.001, 0.1),
            'xgb_max_depth': trial.suggest_int('xgb_max_depth', 3, 12),
            'xgb_subsample': trial.suggest_float('xgb_subsample', 0.5, 1.0),
            'xgb_colsample': trial.suggest_float('xgb_colsample', 0.5, 1.0),
            'xgb_min_child_weight': trial.suggest_float('xgb_min_child_weight', 1, 10),
            'xgb_reg_lambda': trial.suggest_float('xgb_reg_lambda', 0.1, 10.0),
            'xgb_reg_alpha': trial.suggest_float('xgb_reg_alpha', 0.0, 1.0),
        })
    else:
        params.update({
            'et_n_estimators': trial.suggest_int('et_n_estimators', 50, 300),
            'et_max_depth': trial.suggest_int('et_max_depth', 3, 20),
            'et_min_samples_split': trial.suggest_int('et_min_samples_split', 2, 20),
            'et_min_samples_leaf': trial.suggest_int('et_min_samples_leaf', 1, 20),
            'et_max_features': trial.suggest_float('et_max_features', 0.1, 1.0),
        })

    # è®€å–å‰ç½®ç‰¹å¾µ
    df = load_features(
        symbol='BTCUSDT',
        timeframe='15m',
        version='v30'
    )

    # è©•ä¼°æ¨¡å‹ï¼Œè¿”å› CV åˆ†æ•¸ dict
    metrics = evaluate_model(df, params)

    # Optuna objective åªéœ€è¦ä¸€å€‹ scalar
    return metrics['cv_scores_mean']


def main():
    # è¨­å®š Optuna å­˜å„²
    study = optuna.create_study(
        sampler=TPESampler(seed=42),
        pruner=MedianPruner(n_warmup_steps=5),
        direction='maximize'
    )
    # ç¢ºä¿è·‘è¶³ 250 æ¬¡è©¦é©—
    study.optimize(objective, n_trials=250)

    # å–å¾—æœ€ä½³çµæœ
    best = study.best_trial
    result = {
        'best_value': best.value,
        'best_params': best.params,
        'n_trials': best.number,
        'state': str(best.state),
        'cv_scores': best.user_attrs.get('cv_scores', []),
        'cv_scores_mean': best.user_attrs.get('cv_scores_mean', None),
        'cv_scores_std': best.user_attrs.get('cv_scores_std', None)
    }

    # é¿å…åºåˆ—åŒ– DataFrameï¼šå°‡æ‰€æœ‰ DataFrame è½‰ç‚º dict
    for k, v in list(result.items()):
        if isinstance(v, pd.DataFrame):
            result[k] = v.to_dict(orient='records')

    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    os.makedirs('optuna_results', exist_ok=True)
    output_json = os.path.join('optuna_results', 'layer2_optimization_result.json')
    with open(output_json, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)

    print(f"âœ… Layer2 å„ªåŒ–å®Œæˆï¼Œçµæœä¿å­˜åœ¨ {output_json}")


if __name__ == '__main__':
    main()
    for vdir in version_dirs:
        selected = vdir / 'BTCUSDT_15m_selected_features.parquet'
        if selected.exists():
            return vdir.name, str(selected)

        # fallback: ä»»ä¸€ features_*.parquet
        candidates = sorted(vdir.glob('features_BTCUSDT_15m_*.parquet'))
        if candidates:
            return vdir.name, str(candidates[0])

    return None, None


def main():
    print("ğŸš€ é–‹å§‹ BTCUSDT_15m ç‰¹å¾µé¸æ“‡è¶…åƒæ•¸å„ªåŒ–...")

    # è‡ªå‹•åµæ¸¬æœ€æ–°ç‰ˆæœ¬ç‰¹å¾µæª”æ¡ˆ
    version, feature_file = find_latest_feature_artifact()
    if not version or not feature_file:
        print("âŒ æ‰¾ä¸åˆ°ä»»ä½•å¯ç”¨çš„ç‰¹å¾µæª” (data/processed/features/BTCUSDT_15m/v*/)")
        sys.exit(1)

    print(f"âœ… æ‰¾åˆ°ç‰¹å¾µæ–‡ä»¶: {feature_file} (version={version})")

    # å¾é›¶ç”Ÿæˆæµç¨‹ï¼šå…ˆ L0â†’L1ï¼Œæœ€å¾ŒåŸ·è¡Œ L2
    try:
        n_trials = int(os.getenv("L2_TRIALS", "250"))
    except Exception:
        n_trials = 250
    

    coordinator = OptunaCoordinator(
        symbol="BTCUSDT",
        timeframe="15m",
        data_path="data",
    )

    print("ğŸ”§ å…ˆåŸ·è¡Œ Layer0 æ•¸æ“šæ¸…æ´—èˆ‡ç‰©åŒ–â€¦")
    coordinator.run_layer0_data_cleaning(n_trials=max(10, 15))

    print("ğŸ·ï¸ æ¥è‘—åŸ·è¡Œ Layer1 æ¨™ç±¤å„ªåŒ–èˆ‡ç‰©åŒ–â€¦")
    coordinator.run_layer1_label_optimization(n_trials=max(50, 75))

    # æœ€å¾ŒåŸ·è¡Œ L2 ç‰¹å¾µå„ªåŒ–ï¼ˆä½¿ç”¨å‰å…©å±¤ç‰©åŒ–çµæœä½œç‚ºè¼¸å…¥ï¼‰
    print("ğŸ“Š åŸ·è¡Œç¬¬2å±¤ï¼šç‰¹å¾µå·¥ç¨‹åƒæ•¸å„ªåŒ–â€¦")
    result = coordinator.run_layer2_feature_optimization(n_trials=n_trials)

    if 'error' in result:
        print(f"âŒ å„ªåŒ–å¤±æ•—: {result['error']}")
    else:
        print(f"âœ… å„ªåŒ–å®Œæˆ! æœ€ä½³å¾—åˆ†: {result.get('best_score', 'N/A')}")
        print(f"ğŸ“Š æœ€å„ªåƒæ•¸: {result.get('best_params', 'N/A')}")

        # ä¿å­˜çµæœ
        result_file = f"optuna_system/results/feature_optimization_BTCUSDT_15m.json"
        os.makedirs("optuna_system/results", exist_ok=True)

        import json
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ çµæœå·²ä¿å­˜è‡³: {result_file}")


if __name__ == "__main__":
    main()
