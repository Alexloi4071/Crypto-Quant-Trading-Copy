#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Layer3 äº”æ¨¡å‹è¶…å‚æ•°ä¼˜åŒ–å’Œè®­ç»ƒè„šæœ¬
"""

import sys
import logging
from pathlib import Path
from datetime import datetime
import pandas as pd
import os

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'layer3_optimization_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

def find_latest_file(directory, pattern):
    """æ‰¾åˆ°æœ€æ–°çš„æ–‡ä»¶"""
    files = list(Path(directory).rglob(pattern))
    if not files:
        return None
    latest = max(files, key=lambda x: os.path.getmtime(x))
    return latest

def check_prerequisites():
    """æ£€æŸ¥å‰ç½®æ¡ä»¶"""
    logger.info("="*80)
    logger.info("æ£€æŸ¥Layer3å‰ç½®æ¡ä»¶...")
    logger.info("="*80)
    
    # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶
    labels_dir = Path("data/processed/labels/BTCUSDT_15m")
    labels_file = find_latest_file(labels_dir, "*.parquet")
    
    if labels_file:
        size_mb = os.path.getsize(labels_file) / (1024*1024)
        mtime = datetime.fromtimestamp(os.path.getmtime(labels_file))
        df = pd.read_parquet(labels_file)
        logger.info(f"âœ… Layer1 æ ‡ç­¾æ–‡ä»¶:")
        logger.info(f"   è·¯å¾„: {labels_file}")
        logger.info(f"   å¤§å°: {size_mb:.2f}MB")
        logger.info(f"   ä¿®æ”¹æ—¶é—´: {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"   å½¢çŠ¶: {df.shape}")
        if 'label' in df.columns:
            label_dist = df['label'].value_counts().to_dict()
            logger.info(f"   æ ‡ç­¾åˆ†å¸ƒ: {label_dist}")
    else:
        logger.error("âŒ æœªæ‰¾åˆ°Layer1æ ‡ç­¾æ–‡ä»¶")
        return False, None, None
    
    # æ£€æŸ¥ç‰¹å¾æ–‡ä»¶
    features_dir = Path("data/processed/features/BTCUSDT_15m")
    features_file = find_latest_file(features_dir, "*.parquet")
    
    if features_file:
        size_mb = os.path.getsize(features_file) / (1024*1024)
        mtime = datetime.fromtimestamp(os.path.getmtime(features_file))
        df = pd.read_parquet(features_file)
        logger.info(f"âœ… Layer2 ç‰¹å¾æ–‡ä»¶:")
        logger.info(f"   è·¯å¾„: {features_file}")
        logger.info(f"   å¤§å°: {size_mb:.2f}MB")
        logger.info(f"   ä¿®æ”¹æ—¶é—´: {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"   å½¢çŠ¶: {df.shape} (æ ·æœ¬æ•° Ã— ç‰¹å¾æ•°)")
    else:
        logger.error("âŒ æœªæ‰¾åˆ°Layer2ç‰¹å¾æ–‡ä»¶")
        return False, None, None
    
    # æ£€æŸ¥æ¸…æ´—æ–‡ä»¶
    cleaned_file = Path("data/processed/cleaned/BTCUSDT_15m/cleaned_ohlcv.parquet")
    if cleaned_file.exists():
        logger.info(f"âœ… Layer0 æ¸…æ´—æ–‡ä»¶: {cleaned_file}")
    else:
        logger.warning("âš ï¸ æœªæ‰¾åˆ°cleaned_ohlcv.parquet (æ”¶ç›Šç‡è®¡ç®—å¯èƒ½å—å½±å“)")
    
    logger.info("\nâœ… æ‰€æœ‰å‰ç½®æ¡ä»¶æ»¡è¶³ï¼å‡†å¤‡å¼€å§‹Layer3ä¼˜åŒ–...\n")
    return True, labels_file, features_file

def prepare_config_files(labels_file, features_file):
    """å‡†å¤‡configsç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶é“¾æ¥"""
    logger.info("å‡†å¤‡é…ç½®æ–‡ä»¶...")
    
    configs_dir = Path("configs")
    configs_dir.mkdir(exist_ok=True)
    
    # å¤åˆ¶æˆ–é“¾æ¥æ–‡ä»¶åˆ°configsç›®å½•
    target_labels = configs_dir / "labels_15m.parquet"
    target_features = configs_dir / "selected_features_15m.parquet"
    
    # è¯»å–å¹¶ä¿å­˜åˆ°configs
    labels_df = pd.read_parquet(labels_file)
    labels_df.to_parquet(target_labels)
    logger.info(f"âœ… æ ‡ç­¾æ–‡ä»¶å·²å¤åˆ¶åˆ°: {target_labels}")
    
    features_df = pd.read_parquet(features_file)
    features_df.to_parquet(target_features)
    logger.info(f"âœ… ç‰¹å¾æ–‡ä»¶å·²å¤åˆ¶åˆ°: {target_features}")
    
    # å¤åˆ¶cleanedæ–‡ä»¶
    cleaned_source = Path("data/processed/cleaned/BTCUSDT_15m/cleaned_ohlcv.parquet")
    if cleaned_source.exists():
        cleaned_target = configs_dir / "cleaned_ohlcv_15m.parquet"
        cleaned_df = pd.read_parquet(cleaned_source)
        cleaned_df.to_parquet(cleaned_target)
        logger.info(f"âœ… æ¸…æ´—æ–‡ä»¶å·²å¤åˆ¶åˆ°: {cleaned_target}")

def run_layer3_optimization(n_trials=50):
    """è¿è¡ŒLayer3ä¼˜åŒ–"""
    logger.info("="*80)
    logger.info("å¼€å§‹Layer3äº”æ¨¡å‹è¶…å‚æ•°ä¼˜åŒ–...")
    logger.info("="*80)
    
    try:
        from optuna_system.optimizers.optuna_model import ModelOptimizer
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = ModelOptimizer(
            data_path='data',
            config_path='configs',
            results_path='optuna_system/results/BTCUSDT_15m',
            symbol='BTCUSDT',
            timeframe='15m'
        )
        
        logger.info(f"\né…ç½®å‚æ•°:")
        logger.info(f"  - æ•°æ®è·¯å¾„: data")
        logger.info(f"  - é…ç½®è·¯å¾„: configs")
        logger.info(f"  - ç»“æœè·¯å¾„: optuna_system/results/BTCUSDT_15m")
        logger.info(f"  - äº¤æ˜“å¯¹: BTCUSDT")
        logger.info(f"  - æ—¶é—´æ¡†æ¶: 15m")
        logger.info(f"  - æ¯ä¸ªæ¨¡å‹trials: {n_trials}")
        logger.info(f"  - æ€»è®¡trials: {n_trials * 5}")
        logger.info(f"  - æ¨¡å‹åˆ—è¡¨: {optimizer.models_to_train}")
        logger.info("")
        
        # å¼€å§‹ä¼˜åŒ–
        start_time = datetime.now()
        logger.info(f"â° å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("="*80)
        
        result = optimizer.optimize(n_trials=n_trials)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("="*80)
        logger.info("ğŸ‰ Layer3ä¼˜åŒ–å®Œæˆï¼")
        logger.info("="*80)
        logger.info(f"â° ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"â±ï¸ æ€»è€—æ—¶: {duration/60:.1f}åˆ†é’Ÿ ({duration:.0f}ç§’)")
        logger.info(f"ğŸ† æœ€ä½³æ¨¡å‹: {result.get('best_model_type', 'N/A')}")
        logger.info(f"ğŸ“Š æœ€ä½³å¾—åˆ†: {result.get('best_score', 0):.4f}")
        
        if 'all_models' in result:
            logger.info("\nå„æ¨¡å‹æ€§èƒ½:")
            for model_name, model_result in result['all_models'].items():
                logger.info(f"  - {model_name}: {model_result['best_score']:.4f}")
        
        # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
        logger.info("\nç”Ÿæˆçš„æ–‡ä»¶:")
        results_path = Path("optuna_system/results/BTCUSDT_15m")
        for pred_file in results_path.glob("*_predictions.parquet"):
            size_kb = os.path.getsize(pred_file) / 1024
            df = pd.read_parquet(pred_file)
            logger.info(f"  âœ… {pred_file.name}: {size_kb:.1f}KB, å½¢çŠ¶: {df.shape}")
        
        config_file = Path("configs/model_params.json")
        if config_file.exists():
            size_kb = os.path.getsize(config_file) / 1024
            logger.info(f"  âœ… model_params.json: {size_kb:.1f}KB")
        
        logger.info("\nğŸŠ Layer3ä¼˜åŒ–æˆåŠŸå®Œæˆï¼å¯ä»¥ç»§ç»­æ‰§è¡ŒLayer4-9ã€‚")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Layer3ä¼˜åŒ–å¤±è´¥: {e}", exc_info=True)
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("="*80)
    logger.info("Layer3 äº”æ¨¡å‹é›†æˆä¼˜åŒ–å¯åŠ¨å™¨")
    logger.info("="*80)
    logger.info(f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"å·¥ä½œç›®å½•: {Path.cwd()}")
    logger.info("")
    
    # æ­¥éª¤1: æ£€æŸ¥å‰ç½®æ¡ä»¶
    ready, labels_file, features_file = check_prerequisites()
    if not ready:
        logger.error("å‰ç½®æ¡ä»¶ä¸æ»¡è¶³ï¼Œæ— æ³•ç»§ç»­")
        return False
    
    # æ­¥éª¤2: å‡†å¤‡é…ç½®æ–‡ä»¶
    prepare_config_files(labels_file, features_file)
    
    # æ­¥éª¤3: è¿è¡Œä¼˜åŒ–
    # ä½¿ç”¨è¾ƒå°‘çš„trialsè¿›è¡Œå¿«é€Ÿæµ‹è¯•ï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®50-100
    success = run_layer3_optimization(n_trials=30)  # 5æ¨¡å‹ Ã— 30 = 150 trials
    
    if success:
        logger.info("\n" + "="*80)
        logger.info("âœ… æ‰€æœ‰æ­¥éª¤æˆåŠŸå®Œæˆï¼")
        logger.info("="*80)
        logger.info("\nä¸‹ä¸€æ­¥:")
        logger.info("1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶äº†è§£è¯¦ç»†ä¿¡æ¯")
        logger.info("2. æ£€æŸ¥optuna_system/results/BTCUSDT_15m/ç›®å½•ä¸‹çš„é¢„æµ‹æ–‡ä»¶")
        logger.info("3. è¿è¡ŒLayer6é›†æˆä¼˜åŒ–: python run_9layers_optimization.py")
    else:
        logger.error("\n" + "="*80)
        logger.error("âŒ ä¼˜åŒ–è¿‡ç¨‹å‡ºç°é”™è¯¯")
        logger.error("="*80)
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

