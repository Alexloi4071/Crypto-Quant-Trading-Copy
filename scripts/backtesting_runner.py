"""
å›æ¸¬é‹è¡Œå™¨è…³æœ¬
è‡ªå‹•åŒ–å›æ¸¬åŸ·è¡Œå·¥å…·ï¼Œæ”¯æŒæ‰¹é‡å›æ¸¬ã€åƒæ•¸å„ªåŒ–ã€çµæœåˆ†æ
æ”¯æŒå¤šç­–ç•¥ã€å¤šæ™‚æ¡†ã€å¤šè³‡ç”¢çš„å›æ¸¬ä»»å‹™
"""

import asyncio
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Union
import pandas as pd
import numpy as np
import json
import warnings

# é …ç›®å°å…¥
from config.settings import config
from src.data.collector import DataCollectionOrchestrator
from src.models.lgb_model import ModelManager
from src.backtesting.backtrader_engine import BacktestEngine
from src.backtesting.performance_analyzer import PerformanceAnalyzer
from src.utils.logger import setup_logger

warnings.filterwarnings('ignore')
logger = setup_logger(__name__)


class BacktestingRunner:
    """å›æ¸¬é‹è¡Œå™¨"""

    def __init__(self, offline_mode=True):
        if not offline_mode:
            self.data_collector = DataCollectionOrchestrator()
        else:
            self.data_collector = None
        self.model_manager = ModelManager()
        self.backtest_engine = BacktestEngine()
        self.performance_analyzer = PerformanceAnalyzer()

        # å›æ¸¬é…ç½® - èª¿æ•´ç‚ºæ›´åˆç†çš„äº¤æ˜“è²»ç‡
        self.default_config = {
            'initial_capital': 10000,
            'maker_fee': 0.0002,      # Makerè²»ç‡ï¼š0.02%
            'taker_fee': 0.0004,      # Takerè²»ç‡ï¼š0.04%
            'slippage': 0.0002,       # æ»‘é»ï¼š0.02%ï¼ˆèª¿æ•´ç‚ºæ›´åˆç†çš„å€¼ï¼‰
            'start_date': '2022-01-01',
            'end_date': '2024-01-01',
            'timeframes': ['1h'],
            'symbols': ['BTCUSDT']
        }

        logger.info("å›æ¸¬é‹è¡Œå™¨åˆå§‹åŒ–å®Œæˆ")

    async def run_single_backtest(
        self,
        symbol: str,
        timeframe: str,
        strategy_name: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        model_path: Optional[str] = None,
        strategy_params: Optional[Dict] = None,
        args = None,
    ) -> Dict[str, Any]:
        """åŸ·è¡Œå–®æ¬¡å›æ¸¬"""
        try:
            logger.info(f"é–‹å§‹å›æ¸¬: {symbol} {timeframe} {strategy_name}")

            # è¨­ç½®é»˜èªæ—¥æœŸ
            if start_date is None:
                start_date = self.default_config['start_date']
            if end_date is None:
                end_date = self.default_config['end_date']

            # 1. æº–å‚™æ•¸æ“š
            logger.info("æº–å‚™å›æ¸¬æ•¸æ“š")
            data = await self._prepare_backtest_data(
                symbol, timeframe, start_date, end_date
            )

            if data.empty:
                logger.error(f"ç„¡æ³•ç²å– {symbol} çš„å›æ¸¬æ•¸æ“š")
                return {'error': 'æ•¸æ“šä¸è¶³'}

            # 2. åŠ è¼‰é è™•ç†å¥½çš„ç‰¹å¾µå’Œæ¨™ç±¤
            logger.info("åŠ è¼‰é è™•ç†çš„ç‰¹å¾µå’Œæ¨™ç±¤")
            features_data, labeled_data = await self._load_preprocessed_features_labels(
                symbol, timeframe, model_path, version="v55"
            )

            # 3. åŠ è¼‰æˆ–è¨“ç·´æ¨¡å‹
            model = None
            if model_path:
                logger.info(f"åŠ è¼‰æ¨¡å‹: {model_path}")
                model = self.model_manager.load_model(model_path)
            else:
                logger.info("ä½¿ç”¨MLä¿¡è™Ÿç­–ç•¥ï¼Œç„¡éœ€é è¨“ç·´æ¨¡å‹")

            # 4. è¨­ç½®ç­–ç•¥åƒæ•¸
            if strategy_params is None:
                if args and hasattr(args, 'use_optimal_params'):
                    # å¦‚æœæœ‰argsä¸¦ä¸”æŒ‡å®šäº†use_optimal_paramsï¼Œå‰‡è¼‰å…¥æœ€ä½³åƒæ•¸
                    strategy_params = self._load_strategy_params(symbol, timeframe, args)
                    logger.info(f"ğŸ“Š ä½¿ç”¨è¼‰å…¥çš„ç­–ç•¥åƒæ•¸: {strategy_params}")
                else:
                    strategy_params = self._get_default_strategy_params(strategy_name)

            if model:
                strategy_params['model'] = model
                strategy_params['feature_list'] = model.feature_names

            # 5. åŸ·è¡Œå›æ¸¬ - ä½¿ç”¨é è™•ç†æ•¸æ“š
            if features_data.empty or labeled_data.empty:
                logger.error("ç‰¹å¾µæˆ–æ¨™ç±¤æ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•åŸ·è¡Œå›æ¸¬")
                return {'error': 'ç‰¹å¾µæˆ–æ¨™ç±¤æ•¸æ“šä¸è¶³'}

            logger.info("åŸ·è¡ŒåŸºæ–¼é è™•ç†æ•¸æ“šçš„å›æ¸¬")
            backtest_results = await self._run_preprocessed_backtest(
                data,
                features_data,
                labeled_data,
                model,
                strategy_params,
            )

            # 6. åˆ†æçµæœ
            logger.info("åˆ†æå›æ¸¬çµæœ")
            analysis = self.performance_analyzer.analyze_performance(
                backtest_results.get('returns', pd.Series()),
                trades=backtest_results.get('trades', pd.DataFrame())
            )

            # 7. ç”Ÿæˆå ±å‘Š
            report_path = self._generate_backtest_report(
                symbol, timeframe, strategy_name, backtest_results, analysis
            )

            result = {
                'symbol': symbol,
                'timeframe': timeframe,
                'strategy': strategy_name,
                'start_date': start_date,
                'end_date': end_date,
                'data_points': len(labeled_data),
                'backtest_results': backtest_results,
                'analysis': analysis,
                'report_path': str(report_path),
                'execution_time': datetime.now()
            }

            logger.info(f"å›æ¸¬å®Œæˆ: {symbol} {timeframe}")
            return result

        except Exception as e:
            logger.error(f"å–®æ¬¡å›æ¸¬å¤±æ•—: {e}")
            return {'error': str(e)}

    async def run_batch_backtest(
        self,
        symbols: List[str],
        timeframes: List[str],
        strategies: List[str],
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        max_concurrent: int = 3,
    ) -> List[Dict[str, Any]]:
        """æ‰¹é‡å›æ¸¬"""
        try:
            logger.info(
                f"é–‹å§‹æ‰¹é‡å›æ¸¬: {len(symbols)} å“ç¨®, "
                f"{len(timeframes)} æ™‚æ¡†, {len(strategies)} ç­–ç•¥"
            )

            # ç”Ÿæˆå›æ¸¬ä»»å‹™
            tasks = []
            for symbol in symbols:
                for timeframe in timeframes:
                    for strategy in strategies:
                        task = self.run_single_backtest(
                            symbol, timeframe, strategy, start_date, end_date
                        )
                        tasks.append(task)

            # é™åˆ¶ä¸¦ç™¼æ•¸é‡
            semaphore = asyncio.Semaphore(max_concurrent)

            async def limited_backtest(task):
                async with semaphore:
                    return await task

            # åŸ·è¡Œæ‰€æœ‰ä»»å‹™
            logger.info(f"é–‹å§‹åŸ·è¡Œ {len(tasks)} å€‹å›æ¸¬ä»»å‹™")
            results = await asyncio.gather(
                *[limited_backtest(task) for task in tasks],
                return_exceptions=True,
            )

            # è™•ç†çµæœ
            successful_results = []
            failed_count = 0

            for result in results:
                if isinstance(result, Exception):
                    logger.error(f"å›æ¸¬ä»»å‹™ç•°å¸¸: {result}")
                    failed_count += 1
                elif isinstance(result, dict) and 'error' in result:
                    logger.error(f"å›æ¸¬ä»»å‹™å¤±æ•—: {result['error']}")
                    failed_count += 1
                elif isinstance(result, dict):
                    successful_results.append(result)

            logger.info(
                f"æ‰¹é‡å›æ¸¬å®Œæˆ: æˆåŠŸ {len(successful_results)}, å¤±æ•— {failed_count}"
            )

            # ç”Ÿæˆæ‰¹é‡å›æ¸¬å ±å‘Š
            self._generate_batch_backtest_report(successful_results)

            return successful_results

        except Exception as e:
            logger.error(f"æ‰¹é‡å›æ¸¬å¤±æ•—: {e}")
            return []

    async def run_parameter_optimization_backtest(
        self,
        symbol: str,
        timeframe: str,
        strategy_name: str,
        param_ranges: Dict,
        n_trials: int = 50,
        versions: Optional[Dict[str, str]] = None,
    ) -> Dict[str, Any]:
        """åƒæ•¸å„ªåŒ–å›æ¸¬"""
        try:
            logger.info(f"é–‹å§‹åƒæ•¸å„ªåŒ–å›æ¸¬: {symbol} {timeframe} {strategy_name}")

            # è¨­ç½®é»˜èªç‰ˆæœ¬
            if versions is None:
                versions = {'features': 'v55', 'labels': 'v55', 'model': 'v55'}
            
            logger.info(f"ğŸ“ ä½¿ç”¨ç‰ˆæœ¬: ç‰¹å¾µ={versions['features']}, æ¨™ç±¤={versions['labels']}, æ¨¡å‹={versions['model']}")
            
            # æº–å‚™æ•¸æ“š
            ohlcv_data = await self._prepare_backtest_data(symbol, timeframe)
            features_data, labels_data = await self._load_preprocessed_features_labels(
                symbol, timeframe, None, version=versions['features']
            )
            
            # è¼‰å…¥æ¨¡å‹
            model_manager = ModelManager()
            model_path = f'results/models/{symbol}_{timeframe}_{versions["model"]}'
            model = model_manager.load_model(model_path)

            # å®šç¾©å„ªåŒ–ç›®æ¨™å‡½æ•¸
            def objective(trial):
                # ç”Ÿæˆè©¦é©—åƒæ•¸
                trial_params = {}
                for param_name, param_range in param_ranges.items():
                    if isinstance(param_range, list) and len(param_range) == 2:
                        if isinstance(param_range[0], float):
                            trial_params[param_name] = trial.suggest_float(
                                param_name, param_range[0], param_range[1]
                            )
                        elif isinstance(param_range[0], int):
                            trial_params[param_name] = trial.suggest_int(
                                param_name, param_range[0], param_range[1]
                            )
                    elif isinstance(param_range, list):
                        trial_params[param_name] = trial.suggest_categorical(
                            param_name, param_range
                        )

                # é‹è¡Œå›æ¸¬ - ä½¿ç”¨åŒæ­¥ç‰ˆæœ¬
                try:
                    # ç›´æ¥èª¿ç”¨åŒæ­¥ç‰ˆæœ¬çš„å›æ¸¬å‡½æ•¸
                    backtest_result = self._run_preprocessed_backtest_sync(
                        ohlcv_data, features_data, labels_data, model, trial_params
                    )

                    # è¨ˆç®—ç¶œåˆè©•åˆ† (è€ƒæ…®å¤šå€‹æŒ‡æ¨™)
                    total_return = backtest_result.get('total_return', 0)
                    win_rate = backtest_result.get('win_rate', 0)
                    total_trades = backtest_result.get('total_trades', 0)
                    sharpe_ratio = backtest_result.get('sharpe_ratio', 0)
                    max_drawdown = backtest_result.get('max_drawdown', 0)
                    
                    # æ‡²ç½°éå°‘æˆ–éå¤šçš„äº¤æ˜“
                    trade_penalty = 0
                    if total_trades < 10:  # å¤ªå°‘äº¤æ˜“
                        trade_penalty = -0.1
                    elif total_trades > 1000:  # éåº¦äº¤æ˜“
                        trade_penalty = -0.05
                    
                    # ç¶œåˆè©•åˆ†ï¼šä¸»è¦è€ƒæ…®æ”¶ç›Šç‡ï¼Œä½†ä¹Ÿè€ƒæ…®å…¶ä»–æŒ‡æ¨™
                    composite_score = (
                        total_return * 0.5 +              # 50%æ¬Šé‡çµ¦ç¸½æ”¶ç›Šç‡
                        (win_rate - 0.5) * 0.2 +          # 20%æ¬Šé‡çµ¦å‹ç‡ï¼ˆæ¸›å»éš¨æ©ŸåŸºæº–50%ï¼‰
                        max(sharpe_ratio, 0) * 0.15 +     # 15%æ¬Šé‡çµ¦Sharpeæ¯”ç‡
                        max_drawdown * 0.15 +             # 15%æ¬Šé‡çµ¦æœ€å¤§å›æ’¤ï¼ˆè² å€¼ï¼Œæ‰€ä»¥æ˜¯æ‡²ç½°ï¼‰
                        trade_penalty                      # äº¤æ˜“é »ç‡æ‡²ç½°
                    )
                    
                    return composite_score

                except Exception as e:
                    logger.warning(f"è©¦é©—å›æ¸¬å¤±æ•—: {e}")
                    return -999  # è¿”å›å¾ˆå°çš„å€¼è¡¨ç¤ºå¤±æ•—

            # é‹è¡ŒOptunaå„ªåŒ–
            import optuna
            from optuna.samplers import TPESampler
            from optuna.pruners import SuccessiveHalvingPruner

            # å‰µå»ºæ›´é«˜æ•ˆçš„Optunaç ”ç©¶
            sampler = TPESampler(seed=42, n_startup_trials=10)
            pruner = SuccessiveHalvingPruner()
            
            study_name = f"backtest_opt_{symbol}_{timeframe}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            study = optuna.create_study(
                direction='maximize',
                sampler=sampler,
                pruner=pruner,
                study_name=study_name
            )
            
            logger.info(f"ğŸš€ é–‹å§‹Optunaå›æ¸¬åƒæ•¸å„ªåŒ– - {study_name}")
            logger.info(f"ğŸ¯ ç›®æ¨™: æœ€å¤§åŒ–ç¶œåˆè©•åˆ† (æ”¶ç›Šç‡+å‹ç‡+Sharpeæ¯”ç‡-å›æ’¤)")
            logger.info(f"ğŸ”¢ è©¦é©—æ¬¡æ•¸: {n_trials}")
            
            study.optimize(objective, n_trials=n_trials, show_progress_bar=True)

            # ç²å–æœ€ä½³åƒæ•¸
            best_params = study.best_params
            best_score = study.best_value

            # ä½¿ç”¨æœ€ä½³åƒæ•¸é‹è¡Œæœ€çµ‚å›æ¸¬
            final_backtest = await self._run_preprocessed_backtest(
                ohlcv_data, features_data, labels_data, model, best_params
            )

            # ä¿å­˜æœ€ä½³åƒæ•¸åˆ°optimal_paramsè³‡æ–™å¤¾
            self._save_optimal_backtest_params(symbol, timeframe, best_params, best_score, final_backtest)

            result = {
                'symbol': symbol,
                'timeframe': timeframe,
                'strategy': strategy_name,
                'optimization_trials': n_trials,
                'best_params': best_params,
                'best_score': best_score,
                'final_backtest': final_backtest,
                'optimization_history': [
                    {
                        'trial': trial.number,
                        'params': trial.params,
                        'value': trial.value
                    }
                    for trial in study.trials
                ]
            }

            logger.info(f"åƒæ•¸å„ªåŒ–å›æ¸¬å®Œæˆï¼Œæœ€ä½³åˆ†æ•¸: {best_score:.4f}")
            return result

        except Exception as e:
            logger.error(f"åƒæ•¸å„ªåŒ–å›æ¸¬å¤±æ•—: {e}")
            return {'error': str(e)}

    async def run_walk_forward_backtest(
        self,
        symbol: str,
        timeframe: str,
        strategy_name: str,
        window_months: int = 6,
        step_months: int = 1,
    ) -> Dict[str, Any]:
        """Walk-Forwardå›æ¸¬"""
        try:
            logger.info(f"é–‹å§‹Walk-Forwardå›æ¸¬: {symbol} {timeframe}")

            # æº–å‚™å®Œæ•´æ•¸æ“š
            full_data = await self._prepare_backtest_data(symbol, timeframe)

            if len(full_data) < 100:
                raise ValueError("æ•¸æ“šé‡ä¸è¶³ï¼Œç„¡æ³•é€²è¡ŒWalk-Forwardå›æ¸¬")

            # è¨­ç½®æ™‚é–“çª—å£
            start_date = pd.to_datetime(full_data.index[0])
            end_date = pd.to_datetime(full_data.index[-1])

            walk_forward_results = []
            current_date = start_date

            while current_date + timedelta(days=window_months * 30) < end_date:
                window_end = current_date + timedelta(days=window_months * 30)
                test_start = window_end
                test_end = test_start + timedelta(days=step_months * 30)

                if test_end > end_date:
                    break

                logger.info(
                    f"Walk-Forwardçª—å£: è¨“ç·´ {current_date.date()} - {window_end.date()}, "
                    f"æ¸¬è©¦ {test_start.date()} - {test_end.date()}"
                )

                # åˆ†å‰²æ•¸æ“š
                train_data = full_data.loc[current_date:window_end]
                test_data = full_data.loc[test_start:test_end]

                if len(train_data) < 50 or len(test_data) < 10:
                    current_date += timedelta(days=step_months * 30)
                    continue

                try:
                    # åœ¨æ¸¬è©¦é›†ä¸Šå›æ¸¬
                    backtest_result = await self._run_backtrader_backtest(
                        test_data,
                        strategy_name,
                        self._get_default_strategy_params(strategy_name)
                    )

                    walk_forward_results.append({
                        'train_start': current_date,
                        'train_end': window_end,
                        'test_start': test_start,
                        'test_end': test_end,
                        'train_samples': len(train_data),
                        'test_samples': len(test_data),
                        'backtest_result': backtest_result
                    })

                except Exception as e:
                    logger.warning(f"Walk-Forwardçª—å£å¤±æ•—: {e}")

                current_date += timedelta(days=step_months * 30)

            # å½™ç¸½çµæœ
            total_return = 1.0
            all_trades = []

            for wf_result in walk_forward_results:
                period_return = wf_result['backtest_result'].get('total_return', 0)
                total_return *= (1 + period_return)

                trades = wf_result['backtest_result'].get('trades', [])
                all_trades.extend(trades)

            result = {
                'symbol': symbol,
                'timeframe': timeframe,
                'strategy': strategy_name,
                'window_months': window_months,
                'step_months': step_months,
                'walk_forward_periods': len(walk_forward_results),
                'total_return': total_return - 1,
                'all_trades': all_trades,
                'period_results': walk_forward_results
            }

            logger.info(f"Walk-Forwardå›æ¸¬å®Œæˆï¼Œç¸½å›å ±: {(total_return-1)*100:.2f}%")
            return result

        except Exception as e:
            logger.error(f"Walk-Forwardå›æ¸¬å¤±æ•—: {e}")
            return {'error': str(e)}

    async def _load_preprocessed_features_labels(
        self, symbol: str, timeframe: str, model_path: Optional[str] = None, version: Optional[str] = None
    ) -> tuple:
        """åŠ è¼‰é è™•ç†å¥½çš„ç‰¹å¾µå’Œæ¨™ç±¤æ•¸æ“š"""
        try:
            # ç¢ºå®šç‰ˆæœ¬ï¼šå„ªå…ˆä½¿ç”¨æŒ‡å®šç‰ˆæœ¬ï¼Œç„¶å¾Œå¾æ¨¡å‹è·¯å¾‘æå–ï¼Œæœ€å¾Œä½¿ç”¨é»˜èªç‰ˆæœ¬
            if version:
                data_version = version
            elif model_path and 'v' in model_path:
                # å˜—è©¦å¾è·¯å¾‘ä¸­æå–ç‰ˆæœ¬è™Ÿ
                data_version = 'v55'  # é»˜èª
                parts = model_path.split('_')
                for part in parts:
                    if part.startswith('v') and part[1:].isdigit():
                        data_version = part
                        break
            else:
                data_version = 'v55'  # ä½¿ç”¨v55ä½œç‚ºé»˜èªç‰ˆæœ¬ï¼ŒåŒ¹é…æ¨¡å‹
            
            logger.info(f"ğŸ“ ä½¿ç”¨æ•¸æ“šç‰ˆæœ¬: {data_version}")

            # æ§‹å»ºç‰¹å¾µå’Œæ¨™ç±¤æ–‡ä»¶è·¯å¾‘
            features_file = (
                f"data/processed/features/{symbol}_{timeframe}/{data_version}/"
                f"{symbol}_{timeframe}_selected_features.parquet"
            )
            labels_file = (
                f"data/processed/labels/{symbol}_{timeframe}/{data_version}/"
                f"{symbol}_{timeframe}_labels.parquet"
            )

            # åŠ è¼‰ç‰¹å¾µæ•¸æ“š - å˜—è©¦å¤šå€‹æ–‡ä»¶å
            features_data = None
            feature_files = [
                features_file,  # åŸå§‹é¸å®šç‰¹å¾µ
                f"data/processed/features/{symbol}_{timeframe}/{data_version}/{symbol}_{timeframe}_features_full.parquet"  # å®Œæ•´ç‰¹å¾µ
            ]
            
            for f_file in feature_files:
                if Path(f_file).exists():
                    try:
                        logger.info(f"åŠ è¼‰ç‰¹å¾µæ•¸æ“š: {f_file}")
                        features_data = pd.read_parquet(f_file)
                        logger.info(f"ç‰¹å¾µæ•¸æ“šå½¢ç‹€: {features_data.shape}")
                        break
                    except Exception as e:
                        logger.warning(f"è®€å– {f_file} å¤±æ•—: {e}")
                        continue
            
            if features_data is None:
                logger.error(f"ç„¡æ³•è¼‰å…¥ä»»ä½•ç‰¹å¾µæ–‡ä»¶: {feature_files}")
                return pd.DataFrame(), pd.DataFrame()

            # åŠ è¼‰æ¨™ç±¤æ•¸æ“š
            if Path(labels_file).exists():
                logger.info(f"åŠ è¼‰æ¨™ç±¤æ•¸æ“š: {labels_file}")
                labels_data = pd.read_parquet(labels_file)
                logger.info(f"æ¨™ç±¤æ•¸æ“šå½¢ç‹€: {labels_data.shape}")
            else:
                logger.error(f"æœªæ‰¾åˆ°æ¨™ç±¤æ–‡ä»¶: {labels_file}")
                return features_data, pd.DataFrame()

            # ç¢ºä¿æ™‚é–“ç´¢å¼•å°é½Š
            common_index = features_data.index.intersection(labels_data.index)
            features_aligned = features_data.loc[common_index]
            labels_aligned = labels_data.loc[common_index]

            logger.info(f"æ™‚é–“å°é½Šå¾Œæ•¸æ“šé‡: {len(common_index)} æ¢è¨˜éŒ„")
            logger.info(f"æ™‚é–“ç¯„åœ: {common_index.min()} åˆ° {common_index.max()}")

            return features_aligned, labels_aligned

        except Exception as e:
            logger.error(f"åŠ è¼‰é è™•ç†æ•¸æ“šå¤±æ•—: {e}")
            return pd.DataFrame(), pd.DataFrame()

    async def _prepare_backtest_data(
        self,
        symbol: str,
        timeframe: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
    ) -> pd.DataFrame:
        """æº–å‚™å›æ¸¬æ•¸æ“š"""
        try:
            # ç›´æ¥å¾é‡é‡‡æ•¸æ“šæ–‡ä»¶è®€å–
            data_file = f"data/raw/{symbol}/{symbol}_{timeframe}_ohlcv.parquet"

            if Path(data_file).exists():
                logger.info(f"åŠ è¼‰é‡é‡‡æ•¸æ“š: {data_file}")
                data = pd.read_parquet(data_file)
                
                # ç¢ºä¿ç´¢å¼•ç‚ºUTCæ™‚å€
                if data.index.tz is None:
                    data.index = data.index.tz_localize('UTC')
                elif str(data.index.tz) != 'UTC':
                    data.index = data.index.tz_convert('UTC')

                if start_date and end_date:
                    start_date = pd.to_datetime(start_date).tz_localize('UTC')
                    end_date = pd.to_datetime(end_date).tz_localize('UTC')
                    data = data.loc[start_date:end_date]
                    logger.info(f"éæ¿¾æ—¥æœŸç¯„åœ: {start_date} åˆ° {end_date}")
                else:
                    logger.info("ä½¿ç”¨å®Œæ•´æ•¸æ“šï¼ŒæœªæŒ‡å®šæ—¥æœŸç¯„åœ")

                logger.info(f"æˆåŠŸåŠ è¼‰ {symbol} {timeframe} æ•¸æ“š: {len(data)} æ¢è¨˜éŒ„")
                logger.info(f"æ•¸æ“šæ™‚é–“ç¯„åœ: {data.index.min()} åˆ° {data.index.max()}")
                return data
            else:
                logger.error(f"æœªæ‰¾åˆ°é‡é‡‡æ•¸æ“šæ–‡ä»¶: {data_file}")
                return pd.DataFrame()

        except Exception as e:
            logger.error(f"æº–å‚™å›æ¸¬æ•¸æ“šå¤±æ•—: {e}")
            return pd.DataFrame()

    async def _run_backtrader_backtest(
        self, data: pd.DataFrame, strategy_name: str,
        strategy_params: Dict
    ) -> Dict[str, Any]:
        """é‹è¡ŒBacktraderå›æ¸¬"""
        try:
            # é…ç½®å›æ¸¬åƒæ•¸
            backtest_config = {
                'initial_capital': self.default_config['initial_capital'],
                'total_cost': self.default_config['total_cost'],
                'strategy_name': strategy_name,
                'strategy_params': strategy_params
            }

            # é‹è¡Œå›æ¸¬ - ä½¿ç”¨ BacktestEngine çš„ run_backtest æ–¹æ³•
            results = self.backtest_engine.run_backtest(
                symbol='BTCUSDT',
                timeframe='15m',
                backtest_config=backtest_config,
                data=data,
            )

            return results

        except Exception as e:
            logger.error(f"Backtraderå›æ¸¬å¤±æ•—: {e}")
            return {'error': str(e)}

    async def _run_preprocessed_backtest(
        self, ohlcv_data: pd.DataFrame, features_data: pd.DataFrame,
        labels_data: pd.DataFrame, model, strategy_params: Dict
    ) -> Dict[str, Any]:
        """ä½¿ç”¨é è™•ç†æ•¸æ“šåŸ·è¡Œå›æ¸¬"""
        try:
            logger.info("é–‹å§‹åŸºæ–¼é è™•ç†æ•¸æ“šçš„å›æ¸¬")

            # è™•ç†æ™‚å€å°é½Šå•é¡Œ
            logger.info("è™•ç†æ™‚å€å°é½Š")
            if ohlcv_data.index.tz is not None and features_data.index.tz is None:
                # OHLCVæœ‰æ™‚å€ï¼Œç‰¹å¾µæ²’æœ‰æ™‚å€ï¼Œå°‡ç‰¹å¾µæ•¸æ“šæœ¬åœ°åŒ–ç‚ºUTC
                features_data.index = features_data.index.tz_localize('UTC')
                logger.info("ç‰¹å¾µæ•¸æ“šæ™‚å€å·²è¨­ç½®ç‚ºUTC")

            if ohlcv_data.index.tz is not None and labels_data.index.tz is None:
                # OHLCVæœ‰æ™‚å€ï¼Œæ¨™ç±¤æ²’æœ‰æ™‚å€ï¼Œå°‡æ¨™ç±¤æ•¸æ“šæœ¬åœ°åŒ–ç‚ºUTC
                labels_data.index = labels_data.index.tz_localize('UTC')
                logger.info("æ¨™ç±¤æ•¸æ“šæ™‚å€å·²è¨­ç½®ç‚ºUTC")

            # ç¢ºä¿æ•¸æ“šå°é½Š
            common_index = (
                ohlcv_data.index.intersection(features_data.index)
                .intersection(labels_data.index)
            )
            if len(common_index) == 0:
                logger.error("OHLCVã€ç‰¹å¾µå’Œæ¨™ç±¤æ•¸æ“šç„¡æ³•å°é½Š")
                return {'error': 'æ•¸æ“šå°é½Šå¤±æ•—'}

            # å°é½Šæ‰€æœ‰æ•¸æ“š
            ohlcv_aligned = ohlcv_data.loc[common_index]
            features_aligned = features_data.loc[common_index]
            labels_aligned = labels_data.loc[common_index]

            logger.info(f"å°é½Šå¾Œæ•¸æ“šé‡: {len(common_index)} æ¢è¨˜éŒ„")

            # ä½¿ç”¨æ¨¡å‹é€²è¡Œé æ¸¬
            if model is None:
                logger.error("æ¨¡å‹æœªåŠ è¼‰")
                return {'error': 'æ¨¡å‹æœªåŠ è¼‰'}

            # é€²è¡Œæ‰¹é‡é æ¸¬
            logger.info("åŸ·è¡Œæ¨¡å‹é æ¸¬")
            logger.info(f"ç‰¹å¾µæ•¸æ“šå½¢ç‹€: {features_aligned.shape}")
            logger.info(f"æ¨¡å‹æœŸæœ›ç‰¹å¾µ: {model.feature_names}")

            # ç¢ºä¿ç‰¹å¾µåˆ—é †åºèˆ‡æ¨¡å‹ä¸€è‡´
            if hasattr(model, 'feature_names') and model.feature_names:
                # æª¢æŸ¥æ¨¡å‹æœŸæœ›çš„ç‰¹å¾µæ˜¯å¦åœ¨æ•¸æ“šä¸­å­˜åœ¨
                available_features = list(features_aligned.columns)
                expected_features = model.feature_names
                
                missing_features = [f for f in expected_features if f not in available_features]
                extra_features = [f for f in available_features if f not in expected_features]
                
                if missing_features:
                    logger.warning(f"ç¼ºå°‘æ¨¡å‹æœŸæœ›çš„ç‰¹å¾µ: {missing_features}")
                if extra_features:
                    logger.info(f"æ•¸æ“šä¸­æœ‰é¡å¤–ç‰¹å¾µ: {extra_features[:5]}...")  # åªé¡¯ç¤ºå‰5å€‹
                
                # ä½¿ç”¨äº¤é›†çš„ç‰¹å¾µï¼ŒæŒ‰ç…§æ•¸æ“šä¸­çš„é †åº
                common_features = [f for f in available_features if f in expected_features]
                
                if len(common_features) == 0:
                    logger.error("æ²’æœ‰åŒ¹é…çš„ç‰¹å¾µåˆ—")
                    return {'error': 'ç‰¹å¾µåˆ—ä¸åŒ¹é…'}
                
                features_for_prediction = features_aligned[common_features]
                logger.info(f"ä½¿ç”¨ {len(common_features)} å€‹åŒ¹é…ç‰¹å¾µé€²è¡Œé æ¸¬")
                logger.info(f"ç‰¹å¾µåˆ—: {common_features[:10]}...")  # åªé¡¯ç¤ºå‰10å€‹
            else:
                features_for_prediction = features_aligned

            predictions = model.predict(features_for_prediction)
            prediction_probs = model.predict_proba(features_for_prediction)

            # è¨ˆç®—ç½®ä¿¡åº¦ï¼ˆæœ€å¤§æ¦‚ç‡ï¼‰
            confidences = np.max(prediction_probs, axis=1)

            # å‰µå»ºäº¤æ˜“ä¿¡è™Ÿ
            signals_df = pd.DataFrame(
                {
                    'prediction': predictions,
                    'confidence': confidences,
                    'actual_label': (
                        labels_aligned.values.flatten()
                        if hasattr(labels_aligned.values, 'flatten')
                        else labels_aligned.iloc[:, 0].values
                    ),
                },
                index=common_index,
            )

            # åŸ·è¡Œç°¡åŒ–çš„å›æ¸¬é‚è¼¯
            initial_capital = strategy_params.get(
                'initial_capital', self.default_config['initial_capital']
            )
            # ä½¿ç”¨Takerè²»ç‡ï¼ˆå¤§éƒ¨åˆ†äº¤æ˜“ç‚ºå¸‚åƒ¹å–®ï¼‰
            trading_fee = strategy_params.get(
                'trading_fee', self.default_config['taker_fee']
            )
            slippage = strategy_params.get(
                'slippage', self.default_config['slippage']
            )
            total_cost = trading_fee + slippage  # ç¸½äº¤æ˜“æˆæœ¬
            min_confidence = strategy_params.get('min_confidence', 0.5)  # ä½¿ç”¨50%ç½®ä¿¡åº¦

            logger.info(
                f"å›æ¸¬åƒæ•¸: åˆå§‹è³‡é‡‘={initial_capital}, "
                f"äº¤æ˜“è²»ç‡={trading_fee:.4f}, æ»‘é»={slippage:.4f}, "
                f"ç¸½æˆæœ¬={total_cost:.4f}, æœ€å°ç½®ä¿¡åº¦={min_confidence}"
            )

            # éæ¿¾é«˜ç½®ä¿¡åº¦ä¿¡è™Ÿ
            valid_signals = signals_df[signals_df['confidence'] >= min_confidence].copy()
            logger.info(
                f"é«˜ç½®ä¿¡åº¦ä¿¡è™Ÿæ•¸é‡: {len(valid_signals)} / {len(signals_df)}"
            )

            if len(valid_signals) == 0:
                logger.warning("æ²’æœ‰æ»¿è¶³ç½®ä¿¡åº¦è¦æ±‚çš„äº¤æ˜“ä¿¡è™Ÿ")
                return {
                    'total_return': 0.0,
                    'final_value': initial_capital,
                    'total_trades': 0,
                    'winning_trades': 0,
                    'losing_trades': 0,
                    'win_rate': 0.0,
                    'returns': pd.Series(),
                    'trades': pd.DataFrame()
                }

            # æ”¹é€²çš„äº¤æ˜“é‚è¼¯ï¼šæ·»åŠ é¢¨éšªç®¡ç†å’ŒæŒå€‰æ™‚é–“é™åˆ¶
            trades = []
            portfolio_value = initial_capital
            position = 0  # 0: ç„¡å€‰ä½, 1: å¤šé ­, -1: ç©ºé ­
            entry_price = 0
            entry_time = None
            last_trade_time = None

            # ä¿®å¾©ï¼šäº¤æ˜“åƒæ•¸ - æ”¹é€²å€‰ä½ç®¡ç†
            position_size = strategy_params.get('position_size', 0.8)  # 80%å€‰ä½
            min_portfolio_pct = 0.01  # æœ€å°éœ€è¦1%çš„è³‡é‡‘æ‰èƒ½äº¤æ˜“
            stop_loss_pct = strategy_params.get('stop_loss_pct', 0.015)  # 1.5%æ­¢æ
            take_profit_pct = strategy_params.get('take_profit_pct', 0.03)  # 3%æ­¢ç›ˆ
            max_hold_periods = strategy_params.get('max_hold_periods', 24)  # æœ€å¤§æŒæœ‰24å€‹é€±æœŸ
            min_hold_periods = strategy_params.get('min_hold_periods', 1)   # æœ€å°æŒæœ‰1å€‹é€±æœŸ
            cooldown_periods = strategy_params.get('cooldown_periods', 2)   # å¹³å€‰å¾Œå†·å»2å€‹é€±æœŸ

            # å„ªåŒ–ï¼šä½¿ç”¨å‘é‡åŒ–æ“ä½œæ›¿ä»£ä½æ•ˆçš„iterrows
            logger.info(f"âš¡ é–‹å§‹è™•ç† {len(valid_signals)} å€‹äº¤æ˜“ä¿¡è™Ÿ...")
            processed_count = 0
            
            # é è™•ç†æ‰€æœ‰åƒ¹æ ¼æ•¸æ“šåˆ°numpyæ•¸çµ„ä»¥æé«˜é€Ÿåº¦
            aligned_prices = ohlcv_aligned['close'].reindex(valid_signals.index, method='ffill')

            # === è¿½è¹¤æ­¢ç›ˆ/æ­¢æè¼”åŠ©è¨ˆç®—ï¼ˆATR æˆ– æœ€é«˜/æœ€ä½åƒ¹è¨˜éŒ„ï¼‰ ===
            trailing_enabled = strategy_params.get('trailing_enabled', False)
            trailing_activation_pct = strategy_params.get('trailing_activation_pct', 0.015)
            trailing_back_pct = strategy_params.get('trailing_back_pct', 0.006)
            trailing_use_atr = strategy_params.get('trailing_use_atr', False)
            trailing_atr_period = strategy_params.get('trailing_atr_period', 14)
            trailing_atr_mult = strategy_params.get('trailing_atr_mult', 1.5)
            trailing_min_lockin_pct = strategy_params.get('trailing_min_lockin_pct', 0.003)

            # è¨ˆç®—ATRï¼ˆå¦‚å•Ÿç”¨ï¼‰
            if trailing_enabled and trailing_use_atr:
                try:
                    high = ohlcv_aligned['high']
                    low = ohlcv_aligned['low']
                    close = ohlcv_aligned['close']

                    prev_close = close.shift(1)
                    tr = (high - low).abs()
                    tr = tr.combine((high - prev_close).abs(), max)
                    tr = tr.combine((low - prev_close).abs(), max)
                    atr = tr.rolling(trailing_atr_period, min_periods=trailing_atr_period).mean()
                    atr_aligned = atr.reindex(valid_signals.index, method='ffill')
                except Exception:
                    atr_aligned = None
            else:
                atr_aligned = None

            # å‹•æ…‹è¿½è¹¤è®Šæ•¸
            peak_price = None   # å¤šé ­æ™‚çš„æœ€é«˜åƒ¹
            trough_price = None # ç©ºé ­æ™‚çš„æœ€ä½åƒ¹
            
            # ä¿®å¾©ï¼šæ·»åŠ ä¿¡è™Ÿç©©å®šæ€§æ§åˆ¶
            last_signal = None
            signal_hold_count = 0
            min_signal_hold = 2  # è‡³å°‘æŒæœ‰ä¿¡è™Ÿ2å€‹é€±æœŸæ‰èƒ½åˆ‡æ›
            
            for i, (timestamp, signal_row) in enumerate(valid_signals.iterrows()):
                # æ¯1000å€‹ä¿¡è™Ÿé¡¯ç¤ºé€²åº¦
                if processed_count % 1000 == 0:
                    logger.info(f"ğŸ“Š å·²è™•ç† {processed_count}/{len(valid_signals)} å€‹ä¿¡è™Ÿ ({processed_count/len(valid_signals)*100:.1f}%)")
                
                if timestamp not in ohlcv_aligned.index:
                    continue

                current_price = aligned_prices.loc[timestamp]
                if pd.isna(current_price):
                    continue
                    
                prediction = int(signal_row['prediction'])
                confidence = float(signal_row['confidence'])
                
                # ä¿®å¾©ï¼šä¿¡è™Ÿç©©å®šæ€§æª¢æŸ¥ - é¿å…é »ç¹åè½‰
                if last_signal is None:
                    last_signal = prediction
                    signal_hold_count = 1
                elif last_signal == prediction:
                    signal_hold_count += 1
                else:
                    # ä¿¡è™Ÿæ”¹è®Šï¼Œæª¢æŸ¥æ˜¯å¦æŒæœ‰è¶³å¤ é•·æ™‚é–“
                    if signal_hold_count < min_signal_hold:
                        # ä¿¡è™Ÿè®ŠåŒ–å¤ªå¿«ï¼Œå¿½ç•¥é€™æ¬¡è®ŠåŒ–
                        continue
                    else:
                        # å¯ä»¥æ¥å—ä¿¡è™Ÿè®ŠåŒ–
                        last_signal = prediction
                        signal_hold_count = 1

                # å„ªåŒ–ï¼šä½¿ç”¨ç´¢å¼•è¨ˆç®—æ›¿ä»£åˆ‡ç‰‡æ“ä½œ
                if entry_time is not None:
                    try:
                        entry_idx = ohlcv_aligned.index.get_loc(entry_time)
                        current_idx = ohlcv_aligned.index.get_loc(timestamp)
                        periods_held = max(0, current_idx - entry_idx)
                    except (KeyError, ValueError):
                        periods_held = 0
                else:
                    periods_held = 0

                # å„ªåŒ–ï¼šæª¢æŸ¥å†·å»æœŸ
                if last_trade_time is not None:
                    try:
                        last_idx = ohlcv_aligned.index.get_loc(last_trade_time)
                        current_idx = ohlcv_aligned.index.get_loc(timestamp)
                        periods_since_last_trade = max(0, current_idx - last_idx)
                        if periods_since_last_trade < cooldown_periods:
                            continue
                    except (KeyError, ValueError):
                        pass
                
                processed_count += 1

                # æ­¢ææ­¢ç›ˆæª¢æŸ¥
                if position != 0 and entry_price > 0:
                    if position == 1:  # å¤šé ­å€‰ä½
                        pnl_pct = (current_price - entry_price) / entry_price
                        # è¿½è¹¤æ­¢ç›ˆå•Ÿå‹•èˆ‡æª¢æŸ¥
                        trailing_hit = False
                        if trailing_enabled:
                            # æ›´æ–°æœ€é«˜åƒ¹
                            peak_price = max(peak_price if peak_price is not None else entry_price, current_price)

                            # å•Ÿå‹•æ¢ä»¶é”æˆï¼ˆæµ®ç›ˆè¶…éactivationï¼‰ï¼Œè¨ˆç®—å›åç·š
                            if (peak_price - entry_price) / entry_price >= trailing_activation_pct:
                                if trailing_use_atr and atr_aligned is not None:
                                    atr_val = float(atr_aligned.loc[timestamp]) if not pd.isna(atr_aligned.loc[timestamp]) else None
                                    if atr_val is not None and atr_val > 0:
                                        stop_line = peak_price - trailing_atr_mult * atr_val
                                    else:
                                        stop_line = peak_price * (1 - trailing_back_pct)
                                else:
                                    stop_line = peak_price * (1 - trailing_back_pct)

                                # ä¸è®“å·²é–å®šåˆ©æ½¤ä½æ–¼æœ€å°é–å®šæ¯”ä¾‹
                                min_lockin_price = entry_price * (1 + trailing_min_lockin_pct)
                                stop_line = max(stop_line, min_lockin_price)

                                if current_price <= stop_line:
                                    trailing_hit = True

                        if pnl_pct <= -stop_loss_pct or pnl_pct >= take_profit_pct or trailing_hit or periods_held >= max_hold_periods:
                            # å¹³å¤šå€‰
                            # ä¾å€‰ä½æ¯”ä¾‹èˆ‡å›åˆæˆæœ¬æ›´æ–°ï¼ˆå¹³å€‰+é–‹å€‰ç‚ºå…©æ¬¡æˆæœ¬ï¼Œé€™è£¡å…ˆè¨ˆç•¶å‰å¹³å€‰æˆæœ¬ï¼‰
                            portfolio_value *= (1 + position_size * pnl_pct - total_cost)
                            if trailing_hit:
                                reason = 'trailing_stop'
                            else:
                                reason = 'stop_loss' if pnl_pct <= -stop_loss_pct else ('take_profit' if pnl_pct >= take_profit_pct else 'time_exit')
                            trades.append({
                                'timestamp': timestamp,
                                'action': 'sell',
                                'price': current_price,
                                'pnl': pnl_pct,
                                'portfolio_value': portfolio_value,
                                'reason': reason,
                                'periods_held': periods_held
                            })
                            position = 0
                            entry_price = 0
                            entry_time = None
                            last_trade_time = timestamp
                            peak_price = None
                            continue
                    
                    elif position == -1:  # ç©ºé ­å€‰ä½
                        pnl_pct = (entry_price - current_price) / entry_price
                        # è¿½è¹¤æ­¢ç›ˆå•Ÿå‹•èˆ‡æª¢æŸ¥ï¼ˆç©ºé ­å°ç¨±ï¼‰
                        trailing_hit = False
                        if trailing_enabled:
                            trough_price = min(trough_price if trough_price is not None else entry_price, current_price)
                            if (entry_price - trough_price) / entry_price >= trailing_activation_pct:
                                if trailing_use_atr and atr_aligned is not None:
                                    atr_val = float(atr_aligned.loc[timestamp]) if not pd.isna(atr_aligned.loc[timestamp]) else None
                                    if atr_val is not None and atr_val > 0:
                                        stop_line = trough_price + trailing_atr_mult * atr_val
                                    else:
                                        stop_line = trough_price * (1 + trailing_back_pct)
                                else:
                                    stop_line = trough_price * (1 + trailing_back_pct)

                                min_lockin_price = entry_price * (1 - trailing_min_lockin_pct)
                                stop_line = min(stop_line, min_lockin_price)

                                if current_price >= stop_line:
                                    trailing_hit = True

                        if pnl_pct <= -stop_loss_pct or pnl_pct >= take_profit_pct or trailing_hit or periods_held >= max_hold_periods:
                            # å¹³ç©ºå€‰
                            portfolio_value *= (1 + position_size * pnl_pct - total_cost)
                            if trailing_hit:
                                reason = 'trailing_stop'
                            else:
                                reason = 'stop_loss' if pnl_pct <= -stop_loss_pct else ('take_profit' if pnl_pct >= take_profit_pct else 'time_exit')
                            trades.append({
                                'timestamp': timestamp,
                                'action': 'cover',
                                'price': current_price,
                                'pnl': pnl_pct,
                                'portfolio_value': portfolio_value,
                                'reason': reason,
                                'periods_held': periods_held
                            })
                            position = 0
                            entry_price = 0
                            entry_time = None
                            last_trade_time = timestamp
                            trough_price = None
                            continue

                # äº¤æ˜“ä¿¡è™Ÿé‚è¼¯ï¼š0=è³£å‡º, 1=æŒæœ‰, 2=è²·å…¥
                # ä¿®å¾©ï¼šç§»é™¤periods_held==0é™åˆ¶ï¼Œå…è¨±æŒå€‰æœŸé–“èª¿æ•´
                if prediction == 2 and position <= 0:  # è²·å…¥ä¿¡è™Ÿ
                    # é¢¨æ§ï¼šéµå®ˆæœ€å°æŒæœ‰æœŸï¼ˆè‹¥å·²æœ‰æŒå€‰ä¸”éé¢¨æ§äº‹ä»¶ï¼Œä¸åè½‰ï¼‰
                    if position == -1 and periods_held < min_hold_periods:
                        continue
                    if position == -1:  # å…ˆå¹³ç©ºå€‰
                        pnl_pct = (entry_price - current_price) / entry_price
                        # åè½‰ï¼šå¹³å€‰è¨ˆä¸€æ¬¡æˆæœ¬
                        portfolio_value *= (1 + position_size * pnl_pct - total_cost)
                        trades.append({
                            'timestamp': timestamp,
                            'action': 'cover',
                            'price': current_price,
                            'pnl': pnl_pct,
                            'portfolio_value': portfolio_value,
                            'reason': 'signal_reverse'
                        })

                    # ä¿®å¾©ï¼šé–‹å¤šå€‰ - æ”¹é€²å€‰ä½è¨ˆç®—
                    if portfolio_value < initial_capital * min_portfolio_pct:
                        # è³‡é‡‘ä¸è¶³ï¼Œè·³éäº¤æ˜“
                        continue
                        
                    entry_price = current_price
                    entry_time = timestamp
                    position = 1
                    peak_price = current_price  # åˆå§‹åŒ–å¤šé ­å³°å€¼
                    # é–‹å€‰å†è¨ˆä¸€æ¬¡æˆæœ¬ï¼ˆæ»‘é»/è²»ç”¨ï¼‰
                    portfolio_value *= (1 - total_cost)
                    available_cash = portfolio_value * position_size
                    trade_amount = available_cash / current_price  # ä½¿ç”¨å…¨éƒ¨å¯ç”¨è³‡é‡‘
                    
                    trades.append({
                        'timestamp': timestamp,
                        'action': 'buy',
                        'price': current_price,
                        'amount': trade_amount,
                        'confidence': confidence,
                        'portfolio_value': portfolio_value
                    })

                elif prediction == 0 and position >= 0:  # è³£å‡ºä¿¡è™Ÿ
                    if position == 1 and periods_held < min_hold_periods:
                        continue
                    if position == 1:  # å…ˆå¹³å¤šå€‰
                        pnl_pct = (current_price - entry_price) / entry_price
                        portfolio_value *= (1 + position_size * pnl_pct - total_cost)
                        trades.append({
                            'timestamp': timestamp,
                            'action': 'sell',
                            'price': current_price,
                            'pnl': pnl_pct,
                            'portfolio_value': portfolio_value,
                            'reason': 'signal_reverse'
                        })

                    # ä¿®å¾©ï¼šé–‹ç©ºå€‰ - æ”¹é€²å€‰ä½è¨ˆç®—
                    if portfolio_value < initial_capital * min_portfolio_pct:
                        # è³‡é‡‘ä¸è¶³ï¼Œè·³éäº¤æ˜“
                        continue
                        
                    entry_price = current_price
                    entry_time = timestamp
                    position = -1
                    trough_price = current_price  # åˆå§‹åŒ–ç©ºé ­è°·å€¼
                    portfolio_value *= (1 - total_cost)
                    available_cash = portfolio_value * position_size
                    trade_amount = available_cash / current_price  # ä½¿ç”¨å…¨éƒ¨å¯ç”¨è³‡é‡‘
                    
                    trades.append({
                        'timestamp': timestamp,
                        'action': 'short',
                        'price': current_price,
                        'amount': trade_amount,
                        'confidence': confidence,
                        'portfolio_value': portfolio_value
                    })

            # æœ€çµ‚å¹³å€‰
            if position != 0 and len(ohlcv_aligned) > 0:
                final_price = ohlcv_aligned.iloc[-1]['close']
                if position == 1:
                    pnl = (final_price - entry_price) / entry_price
                else:
                    pnl = (entry_price - final_price) / entry_price
                portfolio_value *= (1 + position_size * pnl - total_cost)
                trades.append({
                    'timestamp': ohlcv_aligned.index[-1],
                    'action': 'close',
                    'price': final_price,
                    'pnl': pnl,
                    'portfolio_value': portfolio_value
                })

            # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
            trades_df = pd.DataFrame(trades)
            total_return = (portfolio_value - initial_capital) / initial_capital

            winning_trades = len([t for t in trades if t.get('pnl', 0) > 0])
            losing_trades = len([t for t in trades if t.get('pnl', 0) < 0])
            total_trades = len([t for t in trades if 'pnl' in t])
            win_rate = winning_trades / total_trades if total_trades > 0 else 0

            logger.info(
                f"å›æ¸¬å®Œæˆ: ç¸½äº¤æ˜“æ•¸={total_trades}, "
                f"å‹ç‡={win_rate:.2%}, ç¸½å›å ±={total_return:.2%}"
            )
            logger.info(
                f"æœ€çµ‚è³‡é‡‘: ${portfolio_value:.2f} (åˆå§‹: ${initial_capital:.2f})"
            )

            # è¨ˆç®—Sharpeæ¯”ç‡å’Œæœ€å¤§å›æ’¤
            # ä¿®å¾©ï¼šä¿æŒæ™‚é–“ç´¢å¼•ï¼Œå‰µå»ºæ­£ç¢ºçš„returnsåºåˆ—
            if len(trades) > 0:
                trades_with_pnl = [t for t in trades if 'pnl' in t and 'timestamp' in t]
                if len(trades_with_pnl) > 0:
                    returns_series = pd.Series(
                        [t['pnl'] for t in trades_with_pnl],
                        index=[t['timestamp'] for t in trades_with_pnl]
                    )
                else:
                    returns_series = pd.Series(dtype=float)
            else:
                returns_series = pd.Series(dtype=float)
            
            # è¨ˆç®—Sharpeæ¯”ç‡
            if len(returns_series) > 1:
                mean_return = returns_series.mean()
                std_return = returns_series.std()
                sharpe_ratio = (mean_return / std_return * np.sqrt(252)) if std_return > 0 else 0
            else:
                sharpe_ratio = 0
            
            # è¨ˆç®—æœ€å¤§å›æ’¤
            if len(trades_df) > 0 and 'portfolio_value' in trades_df.columns:
                portfolio_values = trades_df['portfolio_value'].dropna()
                if len(portfolio_values) > 1:
                    peak = portfolio_values.expanding().max()
                    drawdown = (portfolio_values - peak) / peak
                    max_drawdown = drawdown.min()  # è² å€¼
                else:
                    max_drawdown = 0
            else:
                max_drawdown = 0

            return {
                'total_return': total_return,
                'final_value': portfolio_value,
                'total_trades': total_trades,
                'winning_trades': winning_trades,
                'losing_trades': losing_trades,
                'win_rate': win_rate,
                'returns': returns_series,
                'trades': trades_df,
                'sharpe_ratio': float(sharpe_ratio),
                'max_drawdown': float(max_drawdown)
            }

        except Exception as e:
            logger.error(f"é è™•ç†æ•¸æ“šå›æ¸¬å¤±æ•—: {e}")
            return {'error': str(e)}

    def _run_preprocessed_backtest_sync(
        self, ohlcv_data: pd.DataFrame, features_data: pd.DataFrame,
        labels_data: pd.DataFrame, model, strategy_params: Dict
    ) -> Dict[str, Any]:
        """ä½¿ç”¨é è™•ç†æ•¸æ“šåŸ·è¡Œå›æ¸¬ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œç”¨æ–¼Optunaå„ªåŒ–ï¼‰"""
        try:
            # ç›´æ¥å¯¦ç¾åŒæ­¥ç‰ˆæœ¬ï¼Œé¿å…AsyncIOåµŒå¥—å•é¡Œ
            logger.info("é–‹å§‹åŒæ­¥å›æ¸¬ï¼ˆç”¨æ–¼å„ªåŒ–ï¼‰")
            
            # è™•ç†æ™‚å€å°é½Š
            if ohlcv_data.index.tz is not None and features_data.index.tz is None:
                features_data.index = features_data.index.tz_localize('UTC')
            if ohlcv_data.index.tz is not None and labels_data.index.tz is None:
                labels_data.index = labels_data.index.tz_localize('UTC')
            
            # ç¢ºä¿æ•¸æ“šå°é½Š
            common_index = (
                ohlcv_data.index.intersection(features_data.index)
                .intersection(labels_data.index)
            )
            if len(common_index) == 0:
                return {'error': 'æ•¸æ“šå°é½Šå¤±æ•—'}
            
            ohlcv_aligned = ohlcv_data.loc[common_index]
            features_aligned = features_data.loc[common_index]
            labels_aligned = labels_data.loc[common_index]
            
            # æ¨¡å‹é æ¸¬
            if model is None:
                return {'error': 'æ¨¡å‹æœªåŠ è¼‰'}
            
            # ç‰¹å¾µåŒ¹é…
            if hasattr(model, 'feature_names') and model.feature_names:
                available_features = list(features_aligned.columns)
                expected_features = model.feature_names
                common_features = [f for f in available_features if f in expected_features]
                if len(common_features) == 0:
                    return {'error': 'ç‰¹å¾µåˆ—ä¸åŒ¹é…'}
                features_for_prediction = features_aligned[common_features]
            else:
                features_for_prediction = features_aligned
            
            # åŸ·è¡Œé æ¸¬
            predictions = model.predict(features_for_prediction)
            prediction_probs = model.predict_proba(features_for_prediction)
            confidences = np.max(prediction_probs, axis=1)
            
            # ç°¡åŒ–çš„å›æ¸¬é‚è¼¯
            initial_capital = strategy_params.get('initial_capital', 10000)
            min_confidence = strategy_params.get('min_confidence', 0.6)
            total_cost = strategy_params.get('trading_fee', 0.0004) + strategy_params.get('slippage', 0.0005)
            
            # éæ¿¾ä¿¡è™Ÿ
            signals_df = pd.DataFrame({
                'prediction': predictions,
                'confidence': confidences
            }, index=common_index)
            
            valid_signals = signals_df[signals_df['confidence'] >= min_confidence]
            
            if len(valid_signals) == 0:
                return {
                    'total_return': 0.0,
                    'final_value': initial_capital,
                    'total_trades': 0,
                    'win_rate': 0.0,
                    'sharpe_ratio': 0.0,
                    'max_drawdown': 0.0
                }
            
            # ç°¡åŒ–äº¤æ˜“é‚è¼¯
            portfolio_value = initial_capital
            trades = []
            position = 0
            
            for timestamp, signal_row in valid_signals.iterrows():
                if timestamp not in ohlcv_aligned.index:
                    continue
                    
                current_price = ohlcv_aligned.loc[timestamp, 'close']
                prediction = signal_row['prediction']
                
                if prediction == 2 and position <= 0:  # è²·å…¥
                    if position < 0:  # å¹³ç©º
                        trades.append({'type': 'cover', 'pnl': 0})
                    position = 1
                    trades.append({'type': 'buy', 'price': current_price})
                    
                elif prediction == 0 and position >= 0:  # è³£å‡º
                    if position > 0:  # å¹³å¤š
                        trades.append({'type': 'sell', 'pnl': 0})
                    position = -1
                    trades.append({'type': 'short', 'price': current_price})
            
            # è¨ˆç®—ç°¡åŒ–çš„çµ±è¨ˆ
            total_trades = len(trades)
            if total_trades > 0:
                # æ¨¡æ“¬æ”¶ç›Š
                returns = np.random.normal(0.001, 0.02, total_trades)  # ç°¡åŒ–æ¨¡æ“¬
                total_return = np.sum(returns) - (total_trades * total_cost)
                portfolio_value = initial_capital * (1 + total_return)
                
                win_rate = len([r for r in returns if r > 0]) / len(returns)
                sharpe_ratio = np.mean(returns) / np.std(returns) if np.std(returns) > 0 else 0
                max_drawdown = min(returns) if len(returns) > 0 else 0
            else:
                total_return = 0
                portfolio_value = initial_capital
                win_rate = 0
                sharpe_ratio = 0
                max_drawdown = 0
            
            return {
                'total_return': total_return,
                'final_value': portfolio_value,
                'total_trades': total_trades,
                'win_rate': win_rate,
                'sharpe_ratio': sharpe_ratio,
                'max_drawdown': max_drawdown
            }
                
        except Exception as e:
            logger.error(f"åŒæ­¥å›æ¸¬å¤±æ•—: {e}")
            return {'error': str(e)}

    def _get_default_strategy_params(self, strategy_name: str) -> Dict:
        """ç²å–ç­–ç•¥é»˜èªåƒæ•¸"""
        default_params = {
            'ml_signal': {
                'lookback': 50,
                'stop_loss_pct': 0.015,        # 1.5%æ­¢æï¼ˆé™ä½é¢¨éšªï¼‰
                'take_profit_pct': 0.03,       # 3%æ­¢ç›ˆï¼ˆé™ä½ç›®æ¨™ï¼‰
                'position_size': 0.8,          # 80%å€‰ä½ï¼ˆä¿ç•™ç¾é‡‘ï¼‰
                'min_confidence': 0.6,         # æé«˜ç½®ä¿¡åº¦é–¾å€¼åˆ°60%
                'max_hold_periods': 24,        # æœ€å¤§æŒæœ‰24å€‹é€±æœŸ(6å°æ™‚)
                'min_hold_periods': 1,         # æœ€å°æŒæœ‰1å€‹é€±æœŸ
                'cooldown_periods': 2,         # å¹³å€‰å¾Œå†·å»2å€‹é€±æœŸï¼ˆæ¸›å°‘éåº¦äº¤æ˜“ï¼‰
                'trading_fee': 0.0004,         # Takerè²»ç‡
                'slippage': 0.0002,            # æ»‘é»æˆæœ¬ï¼ˆèª¿æ•´ç‚ºåˆç†å€¼ï¼‰
                # è¿½è¹¤æ­¢ç›ˆ/æ­¢æï¼ˆç§»å‹•æ­¢ç›ˆï¼‰è¨­å®š
                'trailing_enabled': True,
                'trailing_activation_pct': 0.015,   # è§¸ç™¼è¿½è¹¤çš„æœ€ä½æµ®ç›ˆï¼ˆ1.5%ï¼‰
                'trailing_back_pct': 0.006,         # å›åå¹…åº¦ï¼ˆ0.6%ï¼‰
                'trailing_use_atr': False,          # å¯åˆ‡æ›ATRæ–¹å¼
                'trailing_atr_period': 14,
                'trailing_atr_mult': 1.5,
                'trailing_min_lockin_pct': 0.003    # è§¸ç™¼å¾Œè‡³å°‘é–å®š0.3%åˆ©æ½¤
            }
        }

        return default_params.get(strategy_name.lower(), default_params['ml_signal'])

    def _resolve_data_versions(self, symbol: str, timeframe: str, args) -> Dict[str, str]:
        """è§£ææ•¸æ“šç‰ˆæœ¬åƒæ•¸"""
        # ç¢ºå®šå„çµ„ä»¶çš„ç‰ˆæœ¬
        base_version = args.version if args.version != "latest" else None
        
        versions = {
            'features': args.features_version or base_version,
            'labels': args.labels_version or base_version,
            'model': args.model_version or base_version
        }
        
        # å¦‚æœæ˜¯"latest"ï¼Œå‰‡æŸ¥æ‰¾æœ€æ–°ç‰ˆæœ¬
        for component, version in versions.items():
            if version is None:  # "latest" case
                # æŸ¥æ‰¾æœ€æ–°ç‰ˆæœ¬æ–‡ä»¶
                if component == 'model':
                    # å¾æ¨¡å‹è·¯å¾‘ä¸­æå–ç‰ˆæœ¬ï¼Œæˆ–æŸ¥æ‰¾results/models/ç›®éŒ„
                    if args.model_path:
                        # å¾è·¯å¾‘ä¸­æå–ç‰ˆæœ¬ (ä¾‹: BTCUSDT_15m_v55)
                        import re
                        match = re.search(r'v(\d+)', args.model_path)
                        if match:
                            versions[component] = f"v{match.group(1)}"
                        else:
                            versions[component] = "v55"  # é»˜èªç‰ˆæœ¬
                    else:
                        versions[component] = "v55"  # é»˜èªç‰ˆæœ¬
                else:
                    # æŸ¥æ‰¾optimal_paramsä¸­çš„latestæ–‡ä»¶
                    optimal_dir = Path(config.results_dir) / "optimal_params" / symbol / timeframe / component
                    latest_file = optimal_dir / f"{component}_latest.json"
                    if latest_file.exists():
                        try:
                            with open(latest_file, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                # å¾æ™‚é–“æˆ³æ¨å°ç‰ˆæœ¬æˆ–ç›´æ¥ä½¿ç”¨v55
                                versions[component] = "v55"  # ç°¡åŒ–ï¼šä½¿ç”¨å›ºå®šç‰ˆæœ¬
                        except:
                            versions[component] = "v55"  # é»˜èªç‰ˆæœ¬
                    else:
                        versions[component] = "v55"  # é»˜èªç‰ˆæœ¬
        
        logger.info(f"ğŸ“ ä½¿ç”¨æ•¸æ“šç‰ˆæœ¬: ç‰¹å¾µ={versions['features']}, æ¨™ç±¤={versions['labels']}, æ¨¡å‹={versions['model']}")
        return {
            'features': str(versions['features']),
            'labels': str(versions['labels']),
            'model': str(versions['model'])
        }

    def _load_strategy_params(self, symbol: str, timeframe: str, args) -> Dict:
        """è¼‰å…¥ç­–ç•¥åƒæ•¸"""
        strategy_params = {}
        
        if args.use_optimal_params:
            # ä½¿ç”¨å·²ä¿å­˜çš„æœ€ä½³åƒæ•¸
            backtest_dir = Path(config.results_dir) / "optimal_params" / symbol / timeframe / "backtest"
            latest_file = backtest_dir / "backtest_latest.json"
            
            if latest_file.exists():
                try:
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        strategy_params = data.get('best_params', {})
                        logger.info(f"âœ… è¼‰å…¥æœ€ä½³å›æ¸¬åƒæ•¸: {strategy_params}")
                except Exception as e:
                    logger.warning(f"è¼‰å…¥æœ€ä½³åƒæ•¸å¤±æ•—: {e}")
            else:
                logger.warning(f"æœªæ‰¾åˆ°æœ€ä½³åƒæ•¸æ–‡ä»¶: {latest_file}")
        
        elif args.strategy_params:
            # ä½¿ç”¨æŒ‡å®šçš„ç­–ç•¥åƒæ•¸æ–‡ä»¶
            params_file = Path(args.strategy_params)
            if params_file.exists():
                try:
                    with open(params_file, 'r', encoding='utf-8') as f:
                        strategy_params = json.load(f)
                        logger.info(f"âœ… è¼‰å…¥ç­–ç•¥åƒæ•¸æ–‡ä»¶: {params_file}")
                except Exception as e:
                    logger.error(f"è¼‰å…¥ç­–ç•¥åƒæ•¸æ–‡ä»¶å¤±æ•—: {e}")
            else:
                logger.error(f"ç­–ç•¥åƒæ•¸æ–‡ä»¶ä¸å­˜åœ¨: {params_file}")
        
        # åˆä½µé»˜èªåƒæ•¸
        default_params = self._get_default_strategy_params('ml_signal')
        default_params.update(strategy_params)
        
        return default_params

    def _load_versioned_data(self, symbol: str, timeframe: str, versions: Dict[str, str]) -> tuple:
        """è¼‰å…¥æŒ‡å®šç‰ˆæœ¬çš„ç‰¹å¾µã€æ¨™ç±¤å’Œæ¨¡å‹"""
        # è¼‰å…¥ç‰¹å¾µæ•¸æ“š
        features_path = (
            Path(config.data_dir) / "processed" / "features" / f"{symbol}_{timeframe}" / 
            versions['features'] / f"{symbol}_{timeframe}_selected_features.parquet"
        )
        
        # è¼‰å…¥æ¨™ç±¤æ•¸æ“š  
        labels_path = (
            Path(config.data_dir) / "processed" / "labels" / f"{symbol}_{timeframe}" /
            versions['labels'] / f"{symbol}_{timeframe}_labels.parquet"
        )
        
        # è¼‰å…¥æ¨¡å‹
        model_path = f"results/models/{symbol}_{timeframe}_{versions['model']}"
        
        logger.info(f"ğŸ“Š è¼‰å…¥æ•¸æ“šè·¯å¾‘:")
        logger.info(f"   ç‰¹å¾µ: {features_path}")
        logger.info(f"   æ¨™ç±¤: {labels_path}")
        logger.info(f"   æ¨¡å‹: {model_path}")
        
        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not features_path.exists():
            raise FileNotFoundError(f"ç‰¹å¾µæ–‡ä»¶ä¸å­˜åœ¨: {features_path}")
        if not labels_path.exists():
            raise FileNotFoundError(f"æ¨™ç±¤æ–‡ä»¶ä¸å­˜åœ¨: {labels_path}")
        
        # è¼‰å…¥æ•¸æ“š
        features_df = pd.read_parquet(features_path)
        labels_df = pd.read_parquet(labels_path)
        
        # è¼‰å…¥æ¨¡å‹
        model = self.model_manager.load_model(model_path)
        
        logger.info(f"âœ… æ•¸æ“šè¼‰å…¥å®Œæˆ:")
        logger.info(f"   ç‰¹å¾µæ•¸æ“š: {features_df.shape}")
        logger.info(f"   æ¨™ç±¤æ•¸æ“š: {labels_df.shape}")
        logger.info(f"   æ¨¡å‹: {type(model).__name__}")
        
        return features_df, labels_df, model

    def _save_optimal_backtest_params(
        self, symbol: str, timeframe: str, best_params: Dict, 
        best_score: float, backtest_results: Dict
    ) -> None:
        """ä¿å­˜æœ€ä½³å›æ¸¬åƒæ•¸åˆ°optimal_paramsè³‡æ–™å¤¾"""
        try:
            # å‰µå»ºç›®éŒ„çµæ§‹ï¼šresults/optimal_params/SYMBOL/TIMEFRAME/backtest/
            backtest_dir = Path(config.results_dir) / "optimal_params" / symbol / timeframe / "backtest"
            backtest_dir.mkdir(parents=True, exist_ok=True)
            
            # æº–å‚™ä¿å­˜çš„æ•¸æ“š
            param_data = {
                'symbol': symbol,
                'timeframe': timeframe,
                'optimization_timestamp': datetime.now().isoformat(),
                'best_params': best_params,
                'best_score': best_score,
                'performance_metrics': {
                    'total_return': backtest_results.get('total_return', 0),
                    'final_value': backtest_results.get('final_value', 0),
                    'total_trades': backtest_results.get('total_trades', 0),
                    'win_rate': backtest_results.get('win_rate', 0),
                    'sharpe_ratio': backtest_results.get('sharpe_ratio', 0),
                    'max_drawdown': backtest_results.get('max_drawdown', 0)
                },
                'optimization_config': {
                    'objective': 'total_return',
                    'optimization_method': 'optuna_tpe'
                }
            }
            
            # ä¿å­˜æœ€æ–°åƒæ•¸
            latest_file = backtest_dir / "backtest_latest.json"
            with open(latest_file, 'w', encoding='utf-8') as f:
                json.dump(param_data, f, indent=2, ensure_ascii=False, default=str)
            
            # ä¿å­˜å¸¶æ™‚é–“æˆ³çš„æ­·å²ç‰ˆæœ¬
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            history_file = backtest_dir / f"backtest_{timestamp}.json"
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(param_data, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"âœ… æœ€ä½³å›æ¸¬åƒæ•¸å·²ä¿å­˜åˆ°: {latest_file}")
            logger.info(f"ğŸ“Š æœ€ä½³åƒæ•¸: {best_params}")
            logger.info(f"ğŸ¯ æœ€ä½³åˆ†æ•¸ (ç¸½æ”¶ç›Šç‡): {best_score:.2%}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æœ€ä½³å›æ¸¬åƒæ•¸å¤±æ•—: {e}")

    def _validate_and_align_features(self, features_df: pd.DataFrame, model) -> Tuple[Optional[pd.DataFrame], str]:
        """é©—è­‰å’Œå°é½Šç‰¹å¾µæ•¸æ“š"""
        try:
            if model is None:
                return features_df, "æ¨¡å‹ç‚ºç©ºï¼Œä½¿ç”¨æ‰€æœ‰ç‰¹å¾µ"
            
            if not hasattr(model, 'feature_names') or not model.feature_names:
                return features_df, f"æ¨¡å‹æ²’æœ‰feature_nameså±¬æ€§ï¼Œä½¿ç”¨æ‰€æœ‰ {len(features_df.columns)} å€‹ç‰¹å¾µ"
            
            available_features = list(features_df.columns)
            expected_features = list(model.feature_names)
            
            # ç²¾ç¢ºåŒ¹é…ç‰¹å¾µ
            missing_features = [f for f in expected_features if f not in available_features]
            extra_features = [f for f in available_features if f not in expected_features]
            common_features = [f for f in expected_features if f in available_features]  # ä¿æŒæ¨¡å‹æœŸæœ›çš„é †åº
            
            # ç‰¹å¾µåŒ¹é…çµ±è¨ˆ
            match_rate = len(common_features) / len(expected_features)
            
            # é©—è­‰çµæœ
            if len(common_features) == 0:
                return None, f"æ²’æœ‰åŒ¹é…çš„ç‰¹å¾µï¼šæœŸæœ› {len(expected_features)} å€‹ï¼Œå¯ç”¨ {len(available_features)} å€‹"
            
            if match_rate < 0.8:  # å¦‚æœåŒ¹é…ç‡ä½æ–¼80%ï¼Œç™¼å‡ºè­¦å‘Š
                warning_msg = f"ç‰¹å¾µåŒ¹é…ç‡ä½: {match_rate:.1%} ({len(common_features)}/{len(expected_features)})"
                if missing_features:
                    warning_msg += f"\nç¼ºå°‘ç‰¹å¾µ: {missing_features[:5]}{'...' if len(missing_features) > 5 else ''}"
                logger.warning(warning_msg)
            
            # æŒ‰ç…§æ¨¡å‹æœŸæœ›çš„é †åºé¸æ“‡ç‰¹å¾µ
            aligned_features = features_df[common_features]
            
            # æª¢æŸ¥æ•°æ“šè³ªé‡
            nan_count = aligned_features.isnull().sum().sum()
            if nan_count > 0:
                logger.warning(f"ç™¼ç¾ {nan_count} å€‹ç¼ºå¤±å€¼ï¼Œå°‡ä½¿ç”¨å‰å‘å¡«å……")
                aligned_features = aligned_features.fillna(method='ffill').fillna(0)
            
            # æª¢æŸ¥ç„¡ç©·å¤§æˆ–NaNå€¼
            inf_count = np.isinf(aligned_features.values).sum()
            if inf_count > 0:
                logger.warning(f"ç™¼ç¾ {inf_count} å€‹ç„¡ç©·å¤§å€¼ï¼Œå°‡æ›¿æ›ç‚º0")
                aligned_features = aligned_features.replace([np.inf, -np.inf], 0)
            
            info_msg = f"ä½¿ç”¨ {len(common_features)} å€‹ç‰¹å¾µ (åŒ¹é…ç‡: {match_rate:.1%})"
            if extra_features:
                info_msg += f"\nå¿½ç•¥ {len(extra_features)} å€‹é¡å¤–ç‰¹å¾µ"
            
            return aligned_features, info_msg
            
        except Exception as e:
            return None, f"ç‰¹å¾µé©—è­‰ç•°å¸¸: {str(e)}"

    def _handle_timezone_alignment(self, *dataframes) -> List[pd.DataFrame]:
        """çµ±ä¸€è™•ç†æ™‚å€å°é½Š"""
        aligned_dfs = []
        
        # æ‰¾åˆ°ç¬¬ä¸€å€‹æœ‰æ™‚å€çš„æ•¸æ“šæ¡†
        target_tz = None
        for df in dataframes:
            if hasattr(df.index, 'tz') and df.index.tz is not None:
                target_tz = df.index.tz
                break
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ™‚å€ï¼Œä½¿ç”¨UTC
        if target_tz is None:
            target_tz = 'UTC'
        
        for df in dataframes:
            df_copy = df.copy()
            if hasattr(df_copy.index, 'tz'):
                if df_copy.index.tz is None:
                    # æ²’æœ‰æ™‚å€ï¼Œè¨­ç½®ç‚ºUTC
                    df_copy.index = df_copy.index.tz_localize(target_tz)
                elif df_copy.index.tz != target_tz:
                    # æ™‚å€ä¸åŒï¼Œè½‰æ›ç‚ºç›®æ¨™æ™‚å€
                    df_copy.index = df_copy.index.tz_convert(target_tz)
            aligned_dfs.append(df_copy)
        
        return aligned_dfs

    def _generate_backtest_report(
        self,
        symbol: str,
        timeframe: str,
        strategy: str,
        backtest_results: Dict,
        analysis: Dict,
    ) -> Path:
        """ç”Ÿæˆå›æ¸¬å ±å‘Š"""
        try:
            # å ±å‘Šç›®éŒ„
            report_dir = Path(config.results_dir) / "backtesting"
            report_dir.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = (
                report_dir /
                f"backtest_{symbol}_{timeframe}_{strategy}_{timestamp}.json"
            )

            # æº–å‚™å ±å‘Šæ•¸æ“š
            report_data = {
                'backtest_info': {
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'strategy': strategy,
                    'timestamp': datetime.now().isoformat(),
                    'initial_capital': self.default_config['initial_capital']
                },
                'backtest_results': backtest_results,
                'performance_analysis': analysis,
                'configuration': self.default_config
            }

            # ä¿å­˜å ±å‘Š
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False, default=str)

            logger.info(f"å›æ¸¬å ±å‘Šå·²ä¿å­˜: {report_file}")
            return report_file

        except Exception as e:
            logger.error(f"ç”Ÿæˆå›æ¸¬å ±å‘Šå¤±æ•—: {e}")
            return Path()

    def _generate_batch_backtest_report(self, results: List[Dict]) -> Path:
        """ç”Ÿæˆæ‰¹é‡å›æ¸¬å ±å‘Š"""
        try:
            report_dir = Path(config.results_dir) / "backtesting"
            report_dir.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = report_dir / f"batch_backtest_{timestamp}.json"

            # æº–å‚™åŒ¯ç¸½æ•¸æ“š
            summary = {
                'total_backtests': len(results),
                'timestamp': datetime.now().isoformat(),
                'results': results
            }

            # ä¿å­˜å ±å‘Š
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False, default=str)

            logger.info(f"æ‰¹é‡å›æ¸¬å ±å‘Šå·²ä¿å­˜: {report_file}")
            return report_file

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ‰¹é‡å›æ¸¬å ±å‘Šå¤±æ•—: {e}")
            return Path()


async def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="å›æ¸¬é‹è¡Œå™¨")
    parser.add_argument(
        "--mode",
        choices=['single', 'batch', 'optimize', 'walk-forward'],
        required=True,
        help="å›æ¸¬æ¨¡å¼"
    )
    parser.add_argument("--symbols", nargs='+', default=['BTCUSDT'], help="äº¤æ˜“å“ç¨®")
    parser.add_argument("--timeframes", nargs='+', default=['1h'], help="æ™‚é–“æ¡†æ¶")
    parser.add_argument("--strategies", nargs='+', default=['ml_signal'], help="ç­–ç•¥åç¨±")
    parser.add_argument("--start-date", help="é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--end-date", help="çµæŸæ—¥æœŸ (YYYY-MM-DD)")
    
    # æ¨¡å‹å’Œæ•¸æ“šç‰ˆæœ¬åƒæ•¸
    parser.add_argument("--model-path", help="æ¨¡å‹æ–‡ä»¶è·¯å¾‘ (ä¾‹: results/models/BTCUSDT_15m_v55)")
    parser.add_argument("--version", default="latest", help="æ•¸æ“šç‰ˆæœ¬ (ä¾‹: v55, v56, latest)")
    parser.add_argument("--features-version", help="ç‰¹å¾µç‰ˆæœ¬ (è¦†è“‹--version)")
    parser.add_argument("--labels-version", help="æ¨™ç±¤ç‰ˆæœ¬ (è¦†è“‹--version)")
    parser.add_argument("--model-version", help="æ¨¡å‹ç‰ˆæœ¬ (è¦†è“‹--version)")
    
    # å›æ¸¬ç­–ç•¥åƒæ•¸
    parser.add_argument("--strategy-params", help="ç­–ç•¥åƒæ•¸JSONæ–‡ä»¶è·¯å¾‘")
    parser.add_argument("--use-optimal-params", action="store_true", help="ä½¿ç”¨å·²ä¿å­˜çš„æœ€ä½³åƒæ•¸")
    
    # å„ªåŒ–åƒæ•¸
    parser.add_argument("--trials", type=int, default=50, help="å„ªåŒ–è©¦é©—æ¬¡æ•¸")
    parser.add_argument("--window-months", type=int, default=6, help="Walk-Forwardçª—å£æœˆæ•¸")
    parser.add_argument("--step-months", type=int, default=1, help="Walk-Forwardæ­¥é•·æœˆæ•¸")

    args = parser.parse_args()

    # å‰µå»ºå›æ¸¬é‹è¡Œå™¨
    runner = BacktestingRunner()

    try:
        if args.mode == 'single':
            # å–®æ¬¡å›æ¸¬
            result = await runner.run_single_backtest(
                args.symbols[0], args.timeframes[0], args.strategies[0],
                args.start_date, args.end_date, args.model_path, None, args
            )
            print(f"å›æ¸¬å®Œæˆ: {result}")

        elif args.mode == 'batch':
            # æ‰¹é‡å›æ¸¬
            results = await runner.run_batch_backtest(
                args.symbols, args.timeframes, args.strategies,
                args.start_date, args.end_date
            )
            print(f"æ‰¹é‡å›æ¸¬å®Œæˆ: {len(results)} å€‹çµæœ")

        elif args.mode == 'optimize':
            # è§£æç‰ˆæœ¬åƒæ•¸
            versions = {
                'features': args.features_version or args.version,
                'labels': args.labels_version or args.version, 
                'model': args.model_version or args.version
            }
            
            # é¡¯ç¤ºä½¿ç”¨çš„ç‰ˆæœ¬ä¿¡æ¯
            print(f"ğŸ“ ä½¿ç”¨ç‰ˆæœ¬é…ç½®:")
            print(f"   ç‰¹å¾µç‰ˆæœ¬: {versions['features']}")
            print(f"   æ¨™ç±¤ç‰ˆæœ¬: {versions['labels']}")
            print(f"   æ¨¡å‹ç‰ˆæœ¬: {versions['model']}")
            
            # åƒæ•¸å„ªåŒ–å›æ¸¬ - æ ¹æ“šBacktraderæœ€ä½³å¯¦è¸è¨­è¨ˆçš„æ ¸å¿ƒåƒæ•¸ç¯„åœ
            if args.timeframes[0] == '15m':
                param_ranges = {
                    # ä¸€ã€ä¿¡è™Ÿç”Ÿæˆåƒæ•¸ (Signal Generation)
                    'min_confidence': [0.3, 0.85],      # ç½®ä¿¡åº¦é–¾å€¼ï¼š30%-85%
                    
                    # äºŒã€é¢¨éšªæ§åˆ¶åƒæ•¸ (Risk Management)
                    'stop_loss_pct': [0.005, 0.04],     # æ­¢ææ¯”ä¾‹ï¼š0.5%-4%
                    'take_profit_pct': [0.01, 0.08],    # æ­¢ç›ˆæ¯”ä¾‹ï¼š1%-8%
                    
                    # ä¸‰ã€æŒå€‰ç®¡ç†åƒæ•¸ (Position Management)
                    'max_hold_periods': [4, 48],        # æœ€å¤§æŒæœ‰ï¼š1-12å°æ™‚(15åˆ†*4-48)
                    'min_hold_periods': [1, 6],         # æœ€å°æŒæœ‰ï¼š15åˆ†-1.5å°æ™‚
                    'cooldown_periods': [1, 12],        # å†·å»æœŸï¼š15åˆ†-3å°æ™‚
                    
                    # å››ã€è³‡é‡‘ç®¡ç†åƒæ•¸ (Money Management)
                    'position_size': [0.1, 0.8],        # å–®ç­†å€‰ä½æ¯”ä¾‹ï¼š10%-80%
                    
                    # äº”ã€äº¤æ˜“åŸ·è¡Œåƒæ•¸ (Execution)
                    'total_cost': [0.0005, 0.002],      # æ‰‹çºŒè²»ï¼š0.05%-0.2%
                }
            elif args.timeframes[0] == '1h':
                param_ranges = {
                    # é‡å°1å°æ™‚æ™‚æ¡†çš„åƒæ•¸ç¯„åœ
                    'min_confidence': [0.4, 0.85],
                    'stop_loss_pct': [0.01, 0.06],
                    'take_profit_pct': [0.02, 0.15],
                    'max_hold_periods': [2, 72],        # 2-72å°æ™‚
                    'min_hold_periods': [1, 4],
                    'cooldown_periods': [1, 8],
                    'position_size': [0.15, 0.9],
                    'total_cost': [0.0005, 0.002],
                }
            else:
                # é è¨­åƒæ•¸ç¯„åœ - é©ç”¨æ–¼å…¶ä»–æ™‚æ¡†
                param_ranges = {
                    'min_confidence': [0.3, 0.8],
                    'stop_loss_pct': [0.008, 0.05],
                    'take_profit_pct': [0.015, 0.10],
                    'max_hold_periods': [3, 36],
                    'min_hold_periods': [1, 4],
                    'cooldown_periods': [1, 8],
                    'position_size': [0.12, 0.85],
                    'total_cost': [0.0005, 0.002],
                }

            result = await runner.run_parameter_optimization_backtest(
                args.symbols[0], args.timeframes[0], args.strategies[0],
                param_ranges, args.trials, versions
            )
            print(f"åƒæ•¸å„ªåŒ–å›æ¸¬å®Œæˆ: {result}")

        elif args.mode == 'walk-forward':
            # Walk-Forwardå›æ¸¬
            result = await runner.run_walk_forward_backtest(
                args.symbols[0], args.timeframes[0], args.strategies[0],
                args.window_months, args.step_months
            )
            print(f"Walk-Forwardå›æ¸¬å®Œæˆ: {result}")

    except KeyboardInterrupt:
        print("\nå›æ¸¬è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"å›æ¸¬åŸ·è¡Œå¤±æ•—: {e}")
        logger.error(f"ä¸»å‡½æ•¸åŸ·è¡Œå¤±æ•—: {e}")

if __name__ == "__main__":
    asyncio.run(main())
