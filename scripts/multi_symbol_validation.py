# -*- coding: utf-8 -*-
"""
å¤šå¸ç§éªŒè¯è„šæœ¬
éªŒè¯ç­–ç•¥åœ¨ä¸åŒå¸ç§ä¸Šçš„é€šç”¨æ€§
"""
import sys
from pathlib import Path
import pandas as pd
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from optuna_system.coordinator import OptunaCoordinator
from config.timeframe_scaler import MultiTimeframeCoordinator


def validate_multi_symbols(
    symbols: List[str] = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT'],
    timeframe: str = '15m',
    n_trials: int = 50  # å¿«é€ŸéªŒè¯ï¼Œè¯•éªŒæ¬¡æ•°å‡å°‘
):
    """
    å¤šå¸ç§éªŒè¯
    
    Args:
        symbols: éªŒè¯çš„å¸ç§åˆ—è¡¨
        timeframe: æ—¶é—´æ¡†æ¶
        n_trials: æ¯ä¸ªå¸ç§çš„ä¼˜åŒ–æ¬¡æ•°ï¼ˆå¿«é€ŸéªŒè¯ç”¨50ï¼‰
    """
    
    print("="*70)
    print("ğŸŒ å¤šå¸ç§éªŒè¯å·¥å…·")
    print("="*70)
    print(f"éªŒè¯å¸ç§: {symbols}")
    print(f"æ—¶é—´æ¡†æ¶: {timeframe}")
    print(f"è¯•éªŒæ¬¡æ•°: {n_trials}")
    print("="*70)
    
    results_summary = {}
    
    for idx, symbol in enumerate(symbols):
        print(f"\n[{idx+1}/{len(symbols)}] éªŒè¯å¸ç§: {symbol}")
        print("-"*70)
        
        try:
            # åˆ›å»ºåè°ƒå™¨
            multi_scaler = MultiTimeframeCoordinator(symbol=symbol, data_path='data')
            scaled_config = multi_scaler.get_scaled_config_for_timeframe(timeframe)
            
            coordinator = OptunaCoordinator(
                symbol=symbol,
                timeframe=timeframe,
                data_path='data',
                scaled_config=scaled_config
            )
            
            # è¿è¡ŒLayer0-2ä¼˜åŒ–
            print(f"  [Step 1/3] Layer0 æ•°æ®æ¸…æ´—...")
            layer0 = coordinator.run_layer0_data_cleaning(n_trials=max(10, n_trials//5))
            
            print(f"  [Step 2/3] Layer1 æ ‡ç­¾ä¼˜åŒ–...")
            layer1 = coordinator.run_layer1_label_optimization(n_trials=n_trials)
            
            print(f"  [Step 3/3] Layer2 ç‰¹å¾ä¼˜åŒ–...")
            layer2 = coordinator.run_layer2_feature_optimization(n_trials=n_trials)
            
            # æå–ç»“æœ
            layer0_score = layer0.get('best_score', 0)
            layer1_score = layer1.get('best_score', 0)
            layer2_score = layer2.get('best_score', 0)
            
            # æ ‡ç­¾åˆ†å¸ƒ
            label_dist = {}
            if 'metadata' in layer1:
                label_dist = layer1['metadata'].get('label_distribution', {})
            
            # ç‰¹å¾æ•°é‡
            n_features = 0
            if 'best_params' in layer2 and 'selected_features' in layer2['best_params']:
                n_features = len(layer2['best_params']['selected_features'])
                
                # ç­–ç•¥ç‰¹å¾ç»Ÿè®¡
                selected = layer2['best_params']['selected_features']
                strategy_features = [f for f in selected if any(p in f for p in ['wyk_', 'td_', 'micro_'])]
                n_strategy = len(strategy_features)
            else:
                n_strategy = 0
            
            # è®°å½•ç»“æœ
            results_summary[symbol] = {
                'success': True,
                'layer0_score': layer0_score,
                'layer1_score': layer1_score,
                'layer2_score': layer2_score,
                'label_distribution': label_dist,
                'n_features': n_features,
                'n_strategy_features': n_strategy
            }
            
            print(f"\n  âœ… {symbol} éªŒè¯å®Œæˆ:")
            print(f"     Layer0: {layer0_score:.4f}")
            print(f"     Layer1: {layer1_score:.4f}")
            print(f"     Layer2: {layer2_score:.4f}")
            print(f"     ç‰¹å¾æ•°: {n_features}")
            print(f"     ç­–ç•¥ç‰¹å¾: {n_strategy}ä¸ª")
            
        except Exception as e:
            print(f"  âŒ {symbol} éªŒè¯å¤±è´¥: {e}")
            results_summary[symbol] = {
                'success': False,
                'error': str(e)
            }
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print("\n" + "="*70)
    print("ğŸ“Š éªŒè¯æ±‡æ€»")
    print("="*70)
    
    generate_validation_report(results_summary, timeframe, symbols)
    
    return results_summary


def generate_validation_report(results: Dict, timeframe: str, symbols: List[str]):
    """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
    
    # ç»Ÿè®¡æˆåŠŸç‡
    successful = [s for s, r in results.items() if r.get('success')]
    success_rate = len(successful) / len(symbols)
    
    print(f"\næˆåŠŸç‡: {len(successful)}/{len(symbols)} ({success_rate:.1%})")
    
    # è¡¨æ ¼è¾“å‡º
    print("\n| å¸ç§ | Layer1 F1 | Layer2 F1 | ç‰¹å¾æ•° | ç­–ç•¥ç‰¹å¾ | çŠ¶æ€ |")
    print("|------|-----------|-----------|--------|----------|------|")
    
    for symbol in symbols:
        data = results[symbol]
        
        if data.get('success'):
            l1 = data.get('layer1_score', 0)
            l2 = data.get('layer2_score', 0)
            nf = data.get('n_features', 0)
            ns = data.get('n_strategy_features', 0)
            status = "âœ…"
            
            print(f"| {symbol} | {l1:.4f} | {l2:.4f} | {nf} | {ns} | {status} |")
        else:
            print(f"| {symbol} | - | - | - | - | âŒ å¤±è´¥ |")
    
    # è®¡ç®—å¹³å‡å€¼
    valid_results = [r for r in results.values() if r.get('success')]
    
    if valid_results:
        avg_l1 = np.mean([r['layer1_score'] for r in valid_results])
        avg_l2 = np.mean([r['layer2_score'] for r in valid_results])
        avg_features = np.mean([r['n_features'] for r in valid_results])
        
        print(f"\nå¹³å‡æŒ‡æ ‡:")
        print(f"  Layer1 F1: {avg_l1:.4f}")
        print(f"  Layer2 F1: {avg_l2:.4f}")
        print(f"  ç‰¹å¾æ•°: {avg_features:.0f}")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_file = project_root / 'optuna_system' / 'results' / 'multi_symbol_validation.json'
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timeframe': timeframe,
            'symbols': symbols,
            'results': results,
            'summary': {
                'success_rate': success_rate,
                'avg_layer1_f1': avg_l1 if valid_results else 0,
                'avg_layer2_f1': avg_l2 if valid_results else 0
            }
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜: {output_file}")
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    md_report = output_file.parent / 'multi_symbol_validation.md'
    
    md_lines = [
        "# å¤šå¸ç§éªŒè¯æŠ¥å‘Š\n",
        f"\n**æ—¶é—´æ¡†æ¶**: {timeframe}",
        f"\n**éªŒè¯å¸ç§**: {len(symbols)}ä¸ª\n",
        "\n## ç»“æœæ±‡æ€»\n",
        "| å¸ç§ | Layer1 F1 | Layer2 F1 | ç‰¹å¾æ•° | ç­–ç•¥ç‰¹å¾ |",
        "|------|-----------|-----------|--------|----------|"
    ]
    
    for symbol in symbols:
        data = results[symbol]
        if data.get('success'):
            md_lines.append(
                f"| {symbol} | {data['layer1_score']:.4f} | "
                f"{data['layer2_score']:.4f} | {data['n_features']} | "
                f"{data['n_strategy_features']} |"
            )
        else:
            md_lines.append(f"| {symbol} | âŒ | âŒ | - | - |")
    
    if valid_results:
        md_lines.extend([
            "",
            f"**å¹³å‡Layer1 F1**: {avg_l1:.4f}",
            f"**å¹³å‡Layer2 F1**: {avg_l2:.4f}",
            f"**æˆåŠŸç‡**: {success_rate:.1%}"
        ])
    
    with open(md_report, 'w', encoding='utf-8') as f:
        f.write('\n'.join(md_lines))
    
    print(f"ğŸ“„ MarkdownæŠ¥å‘Šå·²ä¿å­˜: {md_report}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='å¤šå¸ç§éªŒè¯å·¥å…·')
    parser.add_argument('--symbols', nargs='+', 
                       default=['BTCUSDT', 'ETHUSDT', 'BNBUSDT'],
                       help='éªŒè¯çš„å¸ç§åˆ—è¡¨')
    parser.add_argument('--timeframe', default='15m',
                       help='æ—¶é—´æ¡†æ¶')
    parser.add_argument('--trials', type=int, default=50,
                       help='æ¯ä¸ªå¸ç§çš„ä¼˜åŒ–æ¬¡æ•°')
    
    args = parser.parse_args()
    
    validate_multi_symbols(
        symbols=args.symbols,
        timeframe=args.timeframe,
        n_trials=args.trials
    )
