#!/usr/bin/env python3
"""
å¢å¼·çš„é©—è­‰æ©Ÿåˆ¶ - é˜²æ­¢æ•¸æ“šæ´©æ¼çš„åš´æ ¼æ™‚åºåˆ†å‰²
åŒ…å«Walk-Forward Analysis, Purged K-Fold CVç­‰
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import TimeSeriesSplit
from typing import List, Tuple, Iterator
import warnings

class PurgedTimeSeriesSplit:
    """
    æ¸…æ´—ç‰ˆæ™‚é–“åºåˆ—åˆ†å‰² - é˜²æ­¢æ•¸æ“šæ´©æ¼
    
    ç‰¹é»ï¼š
    1. è¨“ç·´é›†å’Œæ¸¬è©¦é›†ä¹‹é–“æœ‰gapæœŸé–“
    2. ç¢ºä¿æœªä¾†ä¿¡æ¯ä¸æ´©æ¼åˆ°è¨“ç·´é›†
    3. æ”¯æŒWalk-Forward Analysis
    4. æ·»åŠ embargoæœŸé˜²æ­¢åºåˆ—ç›¸é—œæ€§æ´©æ¼
    """
    
    def __init__(self, n_splits: int = 5, test_size: int = None, 
                 gap: int = 6, embargo_hours: float = 1.5, max_train_size: int = None):
        """
        Parameters:
        - n_splits: åˆ†å‰²æ•¸é‡
        - test_size: æ¸¬è©¦é›†å¤§å°
        - gap: è¨“ç·´é›†å’Œæ¸¬è©¦é›†ä¹‹é–“çš„åŸºæœ¬é–“éš”æœŸæ•¸ (ç¾åœ¨é»˜èªç‚º6ï¼Œå°15åˆ†é˜æ•¸æ“šç´„1.5å°æ™‚)
        - embargo_hours: embargoæœŸé–“é•·åº¦(å°æ™‚) - é˜²æ­¢åºåˆ—ç›¸é—œæ€§æ´©æ¼
        - max_train_size: æœ€å¤§è¨“ç·´é›†å¤§å°
        """
        self.n_splits = n_splits
        self.test_size = test_size
        self.gap = gap
        self.embargo_hours = embargo_hours
        self.max_train_size = max_train_size
    
    def split(self, X: pd.DataFrame, y: pd.Series = None) -> Iterator[Tuple[np.ndarray, np.ndarray]]:
        """ç”Ÿæˆè¨“ç·´/æ¸¬è©¦ç´¢å¼•ï¼ŒåŒ…å«embargoæœŸé–“é˜²æ­¢åºåˆ—ç›¸é—œæ€§æ´©æ¼"""
        n_samples = len(X)
        
        # è¨ˆç®—embargoæœŸé–“çš„æ¨£æœ¬æ•¸
        # å‡è¨­æ•¸æ“šæ˜¯15åˆ†é˜é–“éš”ï¼Œ1å°æ™‚=4å€‹æ¨£æœ¬
        samples_per_hour = 4  # 15åˆ†é˜ * 4 = 1å°æ™‚
        embargo_samples = int(self.embargo_hours * samples_per_hour)
        
        # ç¸½çš„é–“éš” = åŸºæœ¬gap + embargoæœŸé–“
        total_gap = self.gap + embargo_samples
        
        # è¨ˆç®—æ¸¬è©¦é›†å¤§å°
        if self.test_size is None:
            test_size = n_samples // (self.n_splits + 1)
        else:
            test_size = self.test_size
        
        # ç¢ºä¿æœ‰è¶³å¤ çš„æ•¸æ“š
        min_required = test_size * self.n_splits + total_gap * self.n_splits
        if n_samples < min_required:
            raise ValueError(f"æ•¸æ“šä¸è¶³ï¼šéœ€è¦è‡³å°‘{min_required}å€‹æ¨£æœ¬ï¼Œä½†åªæœ‰{n_samples}å€‹")
        
        # ç”Ÿæˆåˆ†å‰²
        for i in range(self.n_splits):
            # æ¸¬è©¦é›†çµæŸä½ç½®
            test_end = n_samples - (self.n_splits - 1 - i) * test_size
            test_start = test_end - test_size
            
            # è¨“ç·´é›†çµæŸä½ç½®ï¼ˆè€ƒæ…®total_gapï¼ŒåŒ…å«embargoæœŸé–“ï¼‰
            train_end = test_start - total_gap
            
            if train_end <= 0:
                continue
            
            # è¨“ç·´é›†é–‹å§‹ä½ç½®
            if self.max_train_size is None:
                train_start = 0
            else:
                train_start = max(0, train_end - self.max_train_size)
            
            # ç”Ÿæˆç´¢å¼•
            train_indices = np.arange(train_start, train_end)
            test_indices = np.arange(test_start, test_end)
            
            # é©—è­‰æ²’æœ‰é‡ç–Šï¼Œç¢ºä¿æœ‰è¶³å¤ çš„gap
            if len(train_indices) > 0 and len(test_indices) > 0:
                actual_gap = min(test_indices) - max(train_indices) - 1
                assert actual_gap >= total_gap, f"å¯¦éš›gap({actual_gap})å°æ–¼è¦æ±‚çš„gap({total_gap})"
                yield train_indices, test_indices

class WalkForwardAnalysis:
    """
    Walk-Forward Analysis å¯¦ç¾ - åŠ å…¥gapé˜²æ­¢æ•¸æ“šæ´©æ¼
    """
    
    def __init__(self, min_train_size: int = 1000, test_size: int = 100, 
                 step_size: int = 50, gap: int = 6, max_folds: int = 10):
        self.min_train_size = min_train_size
        self.test_size = test_size
        self.step_size = step_size
        self.gap = gap
        self.max_folds = max_folds
    
    def split(self, X: pd.DataFrame, y: pd.Series = None) -> Iterator[Tuple[np.ndarray, np.ndarray]]:
        """Walk-Forwardåˆ†å‰² - åŠ å…¥gapé˜²æ­¢æ•¸æ“šæ´©æ¼"""
        n_samples = len(X)
        
        # é–‹å§‹ä½ç½®ï¼Œè€ƒæ…®gap
        current_end = self.min_train_size + self.test_size + self.gap
        fold_count = 0
        
        while current_end <= n_samples and fold_count < self.max_folds:
            # è¨“ç·´é›†
            train_start = 0
            train_end = current_end - self.test_size - self.gap  # æ¸›å»gap
            
            # æ¸¬è©¦é›†ï¼ˆèˆ‡è¨“ç·´é›†ä¹‹é–“æœ‰gapé–“éš”ï¼‰
            test_start = train_end + self.gap
            test_end = current_end
            
            # ç¢ºä¿æœ‰æ•ˆçš„ç´¢å¼•ç¯„åœ
            if train_end <= train_start or test_start >= test_end:
                current_end += self.step_size
                fold_count += 1
                continue
            
            # ç”Ÿæˆç´¢å¼•
            train_indices = np.arange(train_start, train_end)
            test_indices = np.arange(test_start, test_end)
            
            # é©—è­‰gap
            if len(train_indices) > 0 and len(test_indices) > 0:
                actual_gap = min(test_indices) - max(train_indices) - 1
                assert actual_gap >= self.gap, f"WFAå¯¦éš›gap({actual_gap})å°æ–¼è¦æ±‚çš„gap({self.gap})"
                yield train_indices, test_indices
            
            # ç§»å‹•çª—å£
            current_end += self.step_size
            fold_count += 1

class EnhancedValidator:
    """
    å¢å¼·çš„é©—è­‰å™¨ - é›†æˆå¤šç¨®é˜²æ´©æ¼é©—è­‰æ–¹æ³•
    """
    
    def __init__(self, validation_method: str = "purged_cv", **kwargs):
        self.validation_method = validation_method
        self.kwargs = kwargs
    
    def validate_model(self, model, X: pd.DataFrame, y: pd.Series, 
                      scoring_func=None) -> dict:
        """
        é©—è­‰æ¨¡å‹æ€§èƒ½
        
        Returns:
        - cv_scores: äº¤å‰é©—è­‰åˆ†æ•¸
        - wfa_scores: Walk-Forwardåˆ†æ•¸  
        - consistency_ratio: CVèˆ‡WFAçš„ä¸€è‡´æ€§æ¯”ç‡
        - is_overfitting: æ˜¯å¦éæ“¬åˆ
        """
        from sklearn.metrics import f1_score
        
        if scoring_func is None:
            if len(y.unique()) > 2:
                scoring_func = lambda y_true, y_pred: f1_score(y_true, y_pred, average='weighted', zero_division=0)
            else:
                scoring_func = lambda y_true, y_pred: f1_score(y_true, y_pred, average='binary', zero_division=0)
        
        results = {}
        
        # 1. Purged CV (ä½¿ç”¨æ›´åš´æ ¼çš„gapå’Œembargoè¨­ç½®)
        cv_scores = []
        purged_cv = PurgedTimeSeriesSplit(
            n_splits=self.kwargs.get('n_splits', 3),  # æ¸›å°‘åˆ†å‰²æ•¸ä»¥é©æ‡‰æ›´å¤§çš„gap
            gap=self.kwargs.get('gap', 6),  # é»˜èª6å€‹æ™‚é–“å–®ä½(15åˆ†é˜*6=1.5å°æ™‚)
            embargo_hours=self.kwargs.get('embargo_hours', 1.5)  # 1.5å°æ™‚embargoæœŸ
        )
        
        try:
            for train_idx, test_idx in purged_cv.split(X, y):
                X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
                y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
                
                if len(y_train.unique()) < 2 or len(y_test.unique()) < 2:
                    continue
                
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                score = scoring_func(y_test, y_pred)
                cv_scores.append(score)
        except Exception as e:
            print(f"Purged CVå¤±æ•—: {e}")
            cv_scores = [0.0]
        
        # 2. Walk-Forward Analysis (åŠ å…¥gapåƒæ•¸)
        wfa_scores = []
        wfa = WalkForwardAnalysis(
            min_train_size=self.kwargs.get('min_train_size', len(X)//4),
            test_size=self.kwargs.get('test_size', len(X)//10),
            step_size=self.kwargs.get('step_size', len(X)//20),
            gap=self.kwargs.get('gap', 6)  # èˆ‡CVä½¿ç”¨ç›¸åŒçš„gapè¨­ç½®
        )
        
        try:
            for train_idx, test_idx in wfa.split(X, y):
                X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
                y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
                
                if len(y_train.unique()) < 2 or len(y_test.unique()) < 2:
                    continue
                
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                score = scoring_func(y_test, y_pred)
                wfa_scores.append(score)
        except Exception as e:
            print(f"Walk-Forward Analysiså¤±æ•—: {e}")
            wfa_scores = [0.0]
        
        # 3. è¨ˆç®—ä¸€è‡´æ€§
        cv_mean = np.mean(cv_scores) if cv_scores else 0.0
        wfa_mean = np.mean(wfa_scores) if wfa_scores else 0.0
        
        if cv_mean > 0:
            consistency_ratio = wfa_mean / cv_mean
            delta_pct = abs(cv_mean - wfa_mean) / cv_mean
        else:
            consistency_ratio = 0.0
            delta_pct = 1.0
        
        # 4. éæ“¬åˆæª¢æ¸¬
        is_overfitting = (
            delta_pct > 0.10 or  # CVèˆ‡WFAå·®ç•°è¶…é10%
            cv_mean > 0.95 or    # CVåˆ†æ•¸éé«˜
            consistency_ratio < 0.8  # ä¸€è‡´æ€§å¤ªä½
        )
        
        results = {
            'cv_scores': cv_scores,
            'wfa_scores': wfa_scores,
            'cv_mean': cv_mean,
            'wfa_mean': wfa_mean,
            'consistency_ratio': consistency_ratio,
            'delta_pct': delta_pct,
            'is_overfitting': is_overfitting,
            'final_score': wfa_mean  # ä½¿ç”¨WFAåˆ†æ•¸ä½œç‚ºæœ€çµ‚åˆ†æ•¸
        }
        
        return results

def validate_no_future_leakage(X: pd.DataFrame, y: pd.Series, 
                              label_lag: int = 5) -> bool:
    """
    é©—è­‰æ˜¯å¦å­˜åœ¨æœªä¾†æ•¸æ“šæ´©æ¼
    
    æª¢æŸ¥ï¼š
    1. æ¨™ç±¤æ˜¯å¦ä½¿ç”¨äº†æœªä¾†ä¿¡æ¯
    2. ç‰¹å¾µæ˜¯å¦åŒ…å«æœªä¾†æ•¸æ“š
    3. æ™‚é–“åºåˆ—æ˜¯å¦æ­£ç¢ºæ’åº
    """
    warnings = []
    
    # 1. æª¢æŸ¥æ™‚é–“ç´¢å¼•
    if isinstance(X.index, pd.DatetimeIndex):
        if not X.index.is_monotonic_increasing:
            warnings.append("æ™‚é–“åºåˆ—æœªæŒ‰æ™‚é–“æ’åº")
    
    # 2. æª¢æŸ¥æ¨™ç±¤lag - ğŸ”§ ä¿®å¾©èª¤å ±ï¼šåªæœ‰ç•¶æ¨™ç±¤æ˜¯åŸºæ–¼æœªä¾†æ”¶ç›Šæ™‚æ‰æ˜¯çœŸæ­£çš„æ´©æ¼
    # å°æ–¼åŸºæ–¼æ­·å²æŠ€è¡“æŒ‡æ¨™çš„æ¨™ç±¤ï¼Œé€™ä¸æ˜¯æ´©æ¼
    last_labels = y.tail(label_lag)
    if not last_labels.isna().all():
        # æª¢æŸ¥æ¨™ç±¤è®ŠåŒ–æ¨¡å¼ï¼Œå¦‚æœæ˜¯åŸºæ–¼æ­·å²æ•¸æ“šçš„æŠ€è¡“æŒ‡æ¨™ï¼Œå…è¨±å­˜åœ¨
        if hasattr(y, 'name') and 'future' in str(y.name).lower():
            warnings.append(f"æœ€å¾Œ{label_lag}å€‹æ¨™ç±¤å¯èƒ½ä½¿ç”¨äº†æœªä¾†æ•¸æ“š")
        else:
            # åŸºæ–¼æ­·å²æŠ€è¡“æŒ‡æ¨™çš„æ¨™ç±¤æ˜¯å…è¨±çš„
            print(f"â„¹ï¸ æª¢æ¸¬åˆ°åŸºæ–¼æ­·å²æŠ€è¡“æŒ‡æ¨™çš„æ¨™ç±¤ï¼ˆç„¡æ•¸æ“šæ´©æ¼ï¼‰")
    
    # 3. æª¢æŸ¥ç‰¹å¾µçš„æœªä¾†ä¿¡æ¯
    # ç°¡å–®æª¢æŸ¥ï¼šç‰¹å¾µå€¼æ˜¯å¦åœ¨æ™‚é–“ä¸Šæœ‰ç•°å¸¸è·³èº
    for col in X.columns[:5]:  # åªæª¢æŸ¥å‰5å€‹ç‰¹å¾µ
        if X[col].dtype in ['float64', 'int64']:
            # è¨ˆç®—è®ŠåŒ–ç‡
            changes = X[col].pct_change().abs()
            if changes.quantile(0.99) > 10:  # 99%åˆ†ä½æ•¸è®ŠåŒ–è¶…é1000%
                warnings.append(f"ç‰¹å¾µ{col}å¯èƒ½åŒ…å«ç•°å¸¸è·³èº")
    
    if warnings:
        print("âš ï¸ æ•¸æ“šæ´©æ¼é¢¨éšªæª¢æ¸¬:")
        for w in warnings:
            print(f"  - {w}")
        return False
    
    return True
