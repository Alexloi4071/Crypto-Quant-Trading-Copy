#!/usr/bin/env python3
"""
æ¨™ç±¤ç”Ÿæˆå™¨ - ç°¡åŒ–ç‰ˆæœ¬ï¼Œå°ˆæ³¨æ–¼æ¨™ç±¤ç”Ÿæˆé‚è¼¯
åŸ Optuna å„ªåŒ–åŠŸèƒ½å·²é·ç§»è‡³ optuna_system/optimizers/optuna_label.py

è² è²¬ï¼š
- åŸºæ–¼åƒ¹æ ¼æ•¸æ“šç”Ÿæˆäº¤æ˜“æ¨™ç±¤
- è¨ˆç®—æ¨™ç±¤ç©©å®šæ€§å’Œå¹³è¡¡æ€§
- æ•¸æ“šå¹³è¡¡è™•ç† (SMOTEç­‰)
"""

import numpy as np
import pandas as pd
from sklearn.utils import resample
from typing import Dict, List, Tuple, Any
import warnings

# Import balancing libraries (åˆä½µè‡ªLabelBalanceråŠŸèƒ½)
try:
    from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE
    from imblearn.under_sampling import RandomUnderSampler
    from imblearn.combine import SMOTETomek
    IMBALANCED_LEARN_AVAILABLE = True
except ImportError:
    IMBALANCED_LEARN_AVAILABLE = False

warnings.filterwarnings('ignore')

from .config import get_config


class LabelGenerator:
    """æ¨™ç±¤ç”Ÿæˆå™¨ - å°ˆæ³¨æ–¼æ¨™ç±¤ç”Ÿæˆå’Œå¹³è¡¡è™•ç†"""

    def __init__(self, symbol: str, timeframe: str):
        self.symbol = symbol
        self.timeframe = timeframe
        self.config = get_config("label", timeframe)

    def generate_labels(
        self,
        price_data: pd.Series,
        lag: int,
        profit_threshold: float,
        loss_threshold: float,
        label_type: str,
        threshold_method: str = "fixed"
    ) -> pd.Series:
        """
        åŸºæ–¼æœªä¾†å¯¦éš›ç›ˆåˆ©èƒ½åŠ›ç”Ÿæˆäº¤æ˜“æ¨™ç±¤
        
        Args:
            price_data: åƒ¹æ ¼åºåˆ—
            lag: é æ¸¬æœªä¾†NæœŸçš„æ”¶ç›Š
            profit_threshold: æœ€å°ç›ˆåˆ©é–¾å€¼ (æ­£å€¼) æˆ–åˆ†ä½æ•¸ (0-1)
            loss_threshold: æœ€å¤§è™§æé–¾å€¼ (è² å€¼) æˆ–åˆ†ä½æ•¸ (0-1)
            label_type: æ¨™ç±¤é¡å‹ ("binary" æˆ– "ternary")
            threshold_method: é–¾å€¼è¨ˆç®—æ–¹æ³• ("fixed", "quantile", "adaptive")
        """
        try:
            print(f"ğŸ¯ ç”Ÿæˆæ¨™ç±¤: åŸºæ–¼æœªä¾†{lag}æœŸå¯¦éš›ç›ˆåˆ©èƒ½åŠ›")
            
            # ğŸ¯ æ ¸å¿ƒé‚è¼¯: è¨ˆç®—æœªä¾†å¯¦éš›æ”¶ç›Š (è€ƒæ…®äº¤æ˜“æˆæœ¬)
            future_prices = price_data.shift(-lag)  # æœªä¾†lagæœŸåƒ¹æ ¼
            future_returns = (future_prices / price_data) - 1  # æœªä¾†åŸå§‹æ”¶ç›Šç‡
            
            # è€ƒæ…®å¯¦éš›äº¤æ˜“æˆæœ¬
            total_trading_cost = 0.0006  # 0.04% (taker) + 0.02% (slippage)
            actual_profit = future_returns - total_trading_cost
            
            # å‹•æ…‹é–¾å€¼è¨ˆç®—
            if threshold_method == "adaptive":
                dynamic_profit_threshold, dynamic_loss_threshold = self._calculate_adaptive_thresholds(
                    price_data, profit_threshold, loss_threshold
                )
            elif threshold_method == "quantile":
                dynamic_profit_threshold, dynamic_loss_threshold = self._calculate_quantile_thresholds(
                    actual_profit, profit_threshold, loss_threshold
                )
            else:
                # å›ºå®šé–¾å€¼
                dynamic_profit_threshold = profit_threshold
                dynamic_loss_threshold = loss_threshold
                print(f"ğŸ“Š ä½¿ç”¨å›ºå®šé–¾å€¼: ç›ˆåˆ©>{profit_threshold:.4f}, è™§æ<{loss_threshold:.4f}")
            
            # ğŸ·ï¸ æ ¹æ“šå¯¦éš›ç›ˆåˆ©èƒ½åŠ›ç”Ÿæˆæ¨™ç±¤
            if label_type == "binary":
                # äºŒåˆ†é¡: ç›ˆåˆ©(1) vs ä¸ç›ˆåˆ©(0)
                labels = (actual_profit > dynamic_profit_threshold).astype(int)
                print("ğŸ·ï¸ äºŒåˆ†é¡æ¨™ç±¤: 1=ç›ˆåˆ©, 0=ä¸ç›ˆåˆ©")
            else:
                # ä¸‰åˆ†é¡: è²·å…¥(2) vs æŒæœ‰(1) vs è³£å‡º(0)
                labels = pd.Series(
                    np.where(actual_profit > dynamic_profit_threshold, 2,      # ç›ˆåˆ©è¶³å¤  -> è²·å…¥
                            np.where(actual_profit < dynamic_loss_threshold, 0,  # è™§æéå¤§ -> è³£å‡º
                                    1)),  # å…¶ä»–æƒ…æ³ -> æŒæœ‰
                    index=price_data.index
                )
                print("ğŸ·ï¸ ä¸‰åˆ†é¡æ¨™ç±¤: 2=è²·å…¥(ç›ˆåˆ©), 1=æŒæœ‰(ä¸­æ€§), 0=è³£å‡º(è™§æ)")
            
            # ç§»é™¤æœªä¾†æ•¸æ“šæ´©æ¼
            if lag > 0:
                labels = labels[:-lag]
                print(f"ğŸ”§ ç§»é™¤æœ€å¾Œ{lag}æœŸæ•¸æ“šé¿å…æ´©æ¼ï¼Œå‰©é¤˜{len(labels)}æ¢è¨˜éŒ„")
            
            # æ¨™ç±¤åˆ†ä½ˆçµ±è¨ˆ
            self._print_label_distribution(labels)
            
            # è™•ç†NaNå€¼
            labels = labels.fillna(1)  # é»˜èªç‚ºæŒæœ‰
            
            return labels
            
        except Exception as e:
            print(f"âŒ æ¨™ç±¤ç”Ÿæˆå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            # è¿”å›é»˜èªæ¨™ç±¤ (å…¨éƒ¨æŒæœ‰)
            return pd.Series(index=price_data.index[:-lag] if lag > 0 else price_data.index, 
                           data=1, dtype=int)

    def _calculate_adaptive_thresholds(self, price_data: pd.Series, 
                                     profit_threshold: float, loss_threshold: float) -> Tuple[float, float]:
        """è¨ˆç®—è‡ªé©æ‡‰é–¾å€¼"""
        try:
            lookback_window = min(100, len(price_data) // 4)
            rolling_volatility = price_data.pct_change().rolling(lookback_window, min_periods=20).std()
            
            # åŸºç¤é–¾å€¼ + æ³¢å‹•ç‡èª¿æ•´
            volatility_factor = rolling_volatility / rolling_volatility.median()
            dynamic_profit_threshold = profit_threshold * (1 + volatility_factor * 0.5)
            dynamic_loss_threshold = loss_threshold * (1 + volatility_factor * 0.5)
            
            # é¿å…æ¥µç«¯å€¼
            dynamic_profit_threshold = np.clip(dynamic_profit_threshold, 
                                             profit_threshold * 0.5, profit_threshold * 3)
            dynamic_loss_threshold = np.clip(dynamic_loss_threshold, 
                                           loss_threshold * 3, loss_threshold * 0.5)
            
            print(f"ğŸ“Š ä½¿ç”¨è‡ªé©æ‡‰é–¾å€¼: ç›ˆåˆ©={profit_threshold:.4f}Â±æ³¢å‹•èª¿æ•´, è™§æ={loss_threshold:.4f}Â±æ³¢å‹•èª¿æ•´")
            return dynamic_profit_threshold.iloc[-1], dynamic_loss_threshold.iloc[-1]
            
        except Exception as e:
            print(f"âš ï¸ è‡ªé©æ‡‰é–¾å€¼è¨ˆç®—å¤±æ•—: {e}")
            return profit_threshold, loss_threshold

    def _calculate_quantile_thresholds(self, actual_profit: pd.Series, 
                                     pos_q: float, neg_q: float) -> Tuple[float, float]:
        """è¨ˆç®—åˆ†ä½æ•¸é–¾å€¼"""
        try:
            # ä½¿ç”¨å·²æ‰£æˆæœ¬çš„å¯¦éš›æ”¶ç›Šåˆ†å¸ƒè¨ˆç®—ä¸Šä¸‹é–¾å€¼
            q_high = actual_profit.quantile(pos_q)
            q_low = actual_profit.quantile(neg_q)
            
            # å®‰å…¨è™•ç†ï¼šç¢ºä¿æ–¹å‘æ€§åˆç†
            if q_high <= 0:
                q_high = max(0.0005, actual_profit.quantile(min(0.9, max(0.6, pos_q))))
            if q_low >= 0:
                q_low = min(-0.0005, actual_profit.quantile(max(0.1, min(0.4, neg_q))))

            print(f"ğŸ“Š ä½¿ç”¨åˆ†ä½æ•¸é–¾å€¼: ä¸Šç•Œ={q_high:.5f} (q={pos_q:.3f}), ä¸‹ç•Œ={q_low:.5f} (q={neg_q:.3f})")
            return q_high, q_low
            
        except Exception as e:
            print(f"âš ï¸ åˆ†ä½æ•¸é–¾å€¼è¨ˆç®—å¤±æ•—: {e}")
            return 0.005, -0.005  # é»˜èªé–¾å€¼

    def _print_label_distribution(self, labels: pd.Series):
        """æ‰“å°æ¨™ç±¤åˆ†ä½ˆçµ±è¨ˆ"""
        label_counts = labels.value_counts().sort_index()
        total_samples = len(labels.dropna())
        print(f"ğŸ“Š æ¨™ç±¤åˆ†ä½ˆ:")
        for label, count in label_counts.items():
            percentage = count / total_samples * 100
            label_name = {0: "è³£å‡º", 1: "æŒæœ‰", 2: "è²·å…¥"}.get(label, f"é¡åˆ¥{label}")
            print(f"   {label_name}({label}): {count:,} ({percentage:.1f}%)")
        
        # æª¢æŸ¥æ¨™ç±¤å¹³è¡¡æ€§
        if len(label_counts) < 2:
            print("âš ï¸ è­¦å‘Š: åªç”¢ç”Ÿä¸€å€‹é¡åˆ¥ï¼Œå¯èƒ½é–¾å€¼è¨­ç½®ä¸ç•¶")
        elif label_counts.max() / total_samples > 0.9:
            print("âš ï¸ è­¦å‘Š: æ•¸æ“šåš´é‡ä¸å¹³è¡¡ï¼Œä¸»å°é¡åˆ¥è¶…é90%")

    def calculate_label_stability(self, labels: pd.Series, window: int = 10) -> float:
        """è¨ˆç®—æ¨™ç±¤ç©©å®šæ€§"""
        try:
            if len(labels) < window * 2:
                return 0.0

            label_changes = labels.diff().abs()
            rolling_std = label_changes.rolling(window=window).std()

            avg_std = rolling_std.mean()
            max_possible_std = np.sqrt(len(labels.unique()) - 1)

            stability = 1 - (avg_std / max(max_possible_std, 0.001))
            return max(0.0, min(1.0, stability))

        except Exception as e:
            print(f"ç©©å®šæ€§è¨ˆç®—å¤±æ•—: {e}")
            return 0.0

    def calculate_label_balance(self, labels: pd.Series) -> float:
        """
        è¨ˆç®—æ¨™ç±¤å¹³è¡¡æ€§åˆ†æ•¸
        
        ä½¿ç”¨å¹³è¡¡åˆ†æ•¸ = min(class_ratios) / max(class_ratios)
        ç›®æ¨™ï¼šä½¿å„é¡åˆ¥åˆ†ä½ˆæ›´å‡è¡¡ï¼Œé¿å…æ¥µåº¦ä¸å¹³è¡¡
        """
        try:
            if len(labels) == 0:
                return 0.0
            
            # è¨ˆç®—å„é¡åˆ¥æ¯”ä¾‹
            label_counts = labels.value_counts()
            total_samples = len(labels)
            
            if len(label_counts) < 2:
                return 0.0  # åªæœ‰ä¸€å€‹é¡åˆ¥ï¼Œå®Œå…¨ä¸å¹³è¡¡
            
            class_ratios = label_counts / total_samples
            min_ratio = class_ratios.min()
            max_ratio = class_ratios.max()
            
            # è¨ˆç®—å¹³è¡¡åˆ†æ•¸ï¼šç†æƒ³æƒ…æ³ä¸‹å„é¡åˆ¥ç›¸ç­‰ï¼Œåˆ†æ•¸ç‚º1.0
            balance_score = min_ratio / max_ratio if max_ratio > 0 else 0.0
            
            # é¡å¤–çå‹µï¼šå¦‚æœæœ€å°é¡åˆ¥ >= 20%ï¼Œçµ¦äºˆé¡å¤–åˆ†æ•¸
            if min_ratio >= 0.20:
                balance_score *= 1.2
            
            # æ‡²ç½°æ¥µåº¦ä¸å¹³è¡¡ï¼šå¦‚æœæœ€å¤§é¡åˆ¥ > 90%ï¼Œåš´é‡æ‡²ç½°
            if max_ratio > 0.90:
                balance_score *= 0.1
            elif max_ratio > 0.80:
                balance_score *= 0.5
            
            return max(0.0, min(1.0, balance_score))
            
        except Exception as e:
            print(f"å¹³è¡¡æ€§è¨ˆç®—å¤±æ•—: {e}")
            return 0.0


    def balance_labels(self, X: pd.DataFrame, y: pd.Series, method: str = 'smote',
                      **kwargs) -> Tuple[pd.DataFrame, pd.Series]:
        """
        æ¨™ç±¤å¹³è¡¡è™•ç†
        
        Args:
            X: ç‰¹å¾µDataFrame
            y: æ¨™ç±¤Series  
            method: å¹³è¡¡æ–¹æ³• ('smote', 'adasyn', 'undersample', 'oversample')
            **kwargs: å…¶ä»–åƒæ•¸
            
        Returns:
            å¹³è¡¡å¾Œçš„ (X, y)
        """
        try:
            print(f"ğŸ”§ ä½¿ç”¨ {method} æ–¹æ³•å¹³è¡¡æ¨™ç±¤...")
            
            # è¨˜éŒ„åŸå§‹åˆ†ä½ˆ
            original_dist = y.value_counts().sort_index()
            print(f"ğŸ“Š åŸå§‹åˆ†ä½ˆ: {dict(original_dist)}")
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦å¹³è¡¡
            balance_score = self.calculate_label_balance(y)
            if balance_score > 0.4:  # å¦‚æœå·²ç¶“ç›¸å°å¹³è¡¡
                print(f"âœ… æ•¸æ“šå·²ç›¸å°å¹³è¡¡ (åˆ†æ•¸: {balance_score:.3f})ï¼Œè·³éå¹³è¡¡è™•ç†")
                return X, y
            
            # æ ¹æ“šæ–¹æ³•é€²è¡Œå¹³è¡¡
            if method == 'smote' and IMBALANCED_LEARN_AVAILABLE:
                return self._apply_smote(X, y, **kwargs)
            elif method == 'adasyn' and IMBALANCED_LEARN_AVAILABLE:
                return self._apply_adasyn(X, y, **kwargs)
            elif method == 'undersample':
                return self._apply_undersample(X, y, **kwargs)
            elif method == 'oversample':
                return self._apply_oversample(X, y, **kwargs)
            else:
                print(f"âš ï¸ æ–¹æ³• {method} ä¸å¯ç”¨æˆ–æœªå®‰è£ä¾è³´ï¼Œä½¿ç”¨ç°¡å–®éæ¡æ¨£")
                return self._apply_oversample(X, y, **kwargs)
                
        except Exception as e:
            print(f"âŒ æ¨™ç±¤å¹³è¡¡å¤±æ•—: {e}")
            return X, y

    def _apply_smote(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> Tuple[pd.DataFrame, pd.Series]:
        """æ‡‰ç”¨SMOTEéæ¡æ¨£"""
        try:
            smote = SMOTE(random_state=42, k_neighbors=max(1, min(5, y.value_counts().min()-1)))
            X_balanced, y_balanced = smote.fit_resample(X, y)
            X_balanced = pd.DataFrame(X_balanced, columns=X.columns)
            y_balanced = pd.Series(y_balanced)
            
            print(f"âœ… SMOTEå®Œæˆï¼Œæ¨£æœ¬æ•¸: {len(X)} -> {len(X_balanced)}")
            return X_balanced, y_balanced
        except Exception as e:
            print(f"âš ï¸  SMOTEå¤±æ•—: {e}ï¼Œæ”¹ç”¨ç°¡å–®éæ¡æ¨£")
            return self._apply_oversample(X, y, **kwargs)

    def _apply_adasyn(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> Tuple[pd.DataFrame, pd.Series]:
        """æ‡‰ç”¨ADASYNè‡ªé©æ‡‰éæ¡æ¨£"""
        try:
            adasyn = ADASYN(random_state=42)
            X_balanced, y_balanced = adasyn.fit_resample(X, y)
            X_balanced = pd.DataFrame(X_balanced, columns=X.columns)
            y_balanced = pd.Series(y_balanced)
            
            print(f"âœ… ADASYNå®Œæˆï¼Œæ¨£æœ¬æ•¸: {len(X)} -> {len(X_balanced)}")
            return X_balanced, y_balanced
        except Exception as e:
            print(f"âš ï¸  ADASYNå¤±æ•—: {e}ï¼Œæ”¹ç”¨ç°¡å–®éæ¡æ¨£")
            return self._apply_oversample(X, y, **kwargs)

    def _apply_undersample(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> Tuple[pd.DataFrame, pd.Series]:
        """æ‡‰ç”¨éš¨æ©Ÿæ¬ æ¡æ¨£"""
        try:
            # æ‰¾åˆ°æœ€å°é¡åˆ¥çš„æ¨£æœ¬æ•¸
            min_samples = y.value_counts().min()
            
            X_balanced = pd.DataFrame()
            y_balanced = pd.Series(dtype=y.dtype)
            
            for label in y.unique():
                label_mask = y == label
                X_label = X[label_mask]
                y_label = y[label_mask]
                
                if len(X_label) > min_samples:
                    # éš¨æ©Ÿæ¡æ¨£åˆ°æœ€å°æ•¸é‡
                    indices = np.random.choice(len(X_label), min_samples, replace=False)
                    X_sampled = X_label.iloc[indices]
                    y_sampled = y_label.iloc[indices]
                else:
                    X_sampled = X_label
                    y_sampled = y_label
                
                X_balanced = pd.concat([X_balanced, X_sampled], ignore_index=True)
                y_balanced = pd.concat([y_balanced, y_sampled], ignore_index=True)
            
            print(f"âœ… æ¬ æ¡æ¨£å®Œæˆï¼Œæ¨£æœ¬æ•¸: {len(X)} -> {len(X_balanced)}")
            return X_balanced, y_balanced
            
        except Exception as e:
            print(f"âŒ æ¬ æ¡æ¨£å¤±æ•—: {e}")
            return X, y

    def _apply_oversample(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> Tuple[pd.DataFrame, pd.Series]:
        """æ‡‰ç”¨ç°¡å–®éæ¡æ¨£"""
        try:
            # æ‰¾åˆ°æœ€å¤§é¡åˆ¥çš„æ¨£æœ¬æ•¸
            max_samples = y.value_counts().max()
            
            X_balanced = pd.DataFrame()
            y_balanced = pd.Series(dtype=y.dtype)
            
            for label in y.unique():
                label_mask = y == label
                X_label = X[label_mask]
                y_label = y[label_mask]
                
                if len(X_label) < max_samples:
                    # éæ¡æ¨£åˆ°æœ€å¤§æ•¸é‡
                    X_resampled = resample(X_label, replace=True, n_samples=max_samples, random_state=42)
                    y_resampled = resample(y_label, replace=True, n_samples=max_samples, random_state=42)
                else:
                    X_resampled = X_label
                    y_resampled = y_label
                
                X_balanced = pd.concat([X_balanced, X_resampled], ignore_index=True)
                y_balanced = pd.concat([y_balanced, y_resampled], ignore_index=True)
            
            print(f"âœ… éæ¡æ¨£å®Œæˆï¼Œæ¨£æœ¬æ•¸: {len(X)} -> {len(X_balanced)}")
            return X_balanced, y_balanced
            
        except Exception as e:
            print(f"âŒ éæ¡æ¨£å¤±æ•—: {e}")
            return X, y

    def get_available_balance_methods(self) -> List[str]:
        """ç²å–å¯ç”¨çš„å¹³è¡¡æ–¹æ³•åˆ—è¡¨"""
        methods = ['oversample', 'undersample']
        
        if IMBALANCED_LEARN_AVAILABLE:
            methods.extend(['smote', 'adasyn'])
            
        return methods

    def generate_report(self, labels: pd.Series) -> str:
        """ç”Ÿæˆæ¨™ç±¤å ±å‘Š"""
        if labels is None or len(labels) == 0:
            return "æ¨™ç±¤æ•¸æ“šç‚ºç©º"
        
        label_counts = labels.value_counts().sort_index()
        total_samples = len(labels)
        stability = self.calculate_label_stability(labels)
        balance_score = self.calculate_label_balance(labels)
        
        report = f"""
ğŸ·ï¸ æ¨™ç±¤ç”Ÿæˆå ±å‘Š - {self.symbol} {self.timeframe}
{'='*50}
ğŸ“Š æ¨™ç±¤åˆ†ä½ˆ:"""

        for label, count in label_counts.items():
            percentage = count / total_samples * 100
            label_name = {0: "è³£å‡º", 1: "æŒæœ‰", 2: "è²·å…¥"}.get(label, f"é¡åˆ¥{label}")
            report += f"\nâ”œâ”€ {label_name}({label}): {count:,} ({percentage:.1f}%)"

        report += f"""

ğŸ“ˆ è³ªé‡æŒ‡æ¨™:
â”œâ”€ æ¨™ç±¤ç©©å®šæ€§: {stability:.4f}
â”œâ”€ å¹³è¡¡æ€§åˆ†æ•¸: {balance_score:.4f}
â””â”€ ç¸½æ¨£æœ¬æ•¸: {total_samples:,}

ğŸ’¡ å»ºè­°:"""

        if balance_score < 0.3:
            report += "\nâ”œâ”€ æ¨™ç±¤åš´é‡ä¸å¹³è¡¡ï¼Œå»ºè­°èª¿æ•´é–¾å€¼æˆ–ä½¿ç”¨SMOTE"
        elif balance_score < 0.5:
            report += "\nâ”œâ”€ æ¨™ç±¤è¼•å¾®ä¸å¹³è¡¡ï¼Œå¯è€ƒæ…®æ•¸æ“šå¹³è¡¡è™•ç†"
        else:
            report += "\nâ”œâ”€ æ¨™ç±¤åˆ†ä½ˆè‰¯å¥½"

        if stability < 0.5:
            report += "\nâ””â”€ æ¨™ç±¤ç©©å®šæ€§è¼ƒä½ï¼Œå¯èƒ½éœ€è¦èª¿æ•´lagåƒæ•¸"
        else:
            report += "\nâ””â”€ æ¨™ç±¤ç©©å®šæ€§è‰¯å¥½"

        return report


# èˆŠé¡åä¿æŒå…¼å®¹æ€§
LabelOptimizer = LabelGenerator  # åˆ¥åï¼Œä¿æŒå‘å¾Œå…¼å®¹
