# -*- coding: utf-8 -*-
"""
Meta Quality Optimizer å–®å…ƒæ¸¬è©¦
æ¸¬è©¦ Layer 1B: Meta Model çš„å„é …åŠŸèƒ½
"""
import sys
from pathlib import Path
import pytest
import pandas as pd
import numpy as np

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from optuna_system.optimizers.optuna_meta_quality import MetaQualityOptimizer


class TestMetaQualityOptimizer:
    """Meta Quality Optimizer æ¸¬è©¦é¡"""
    
    @pytest.fixture
    def optimizer(self):
        """å‰µå»ºæ¸¬è©¦ç”¨çš„å„ªåŒ–å™¨å¯¦ä¾‹"""
        return MetaQualityOptimizer(
            data_path='data',
            config_path='configs',
            symbol='BTCUSDT',
            timeframe='15m'
        )
    
    @pytest.fixture
    def sample_signals(self):
        """æ¸¬è©¦ç”¨çš„ Primary ä¿¡è™Ÿ"""
        # æ¨¡æ“¬ 50/50 å¹³è¡¡çš„ä¿¡è™Ÿ
        np.random.seed(42)
        signals = np.random.choice([1, -1], size=1000)
        return pd.Series(signals, index=pd.date_range('2024-01-01', periods=1000, freq='15min'))
    
    @pytest.fixture
    def sample_price_data(self):
        """æ¸¬è©¦ç”¨çš„åƒ¹æ ¼æ•¸æ“š"""
        np.random.seed(42)
        dates = pd.date_range('2024-01-01', periods=1000, freq='15min')
        
        # æ¨¡æ“¬åƒ¹æ ¼èµ°å‹¢
        returns = np.random.normal(0.0001, 0.01, 1000)
        prices = 100 * (1 + returns).cumprod()
        
        data = pd.DataFrame({
            'open': prices * 0.999,
            'high': prices * 1.005,
            'low': prices * 0.995,
            'close': prices,
            'volume': np.random.uniform(1000, 10000, 1000)
        }, index=dates)
        
        return data
    
    @pytest.fixture
    def sample_params(self):
        """æ¸¬è©¦ç”¨çš„åƒæ•¸"""
        return {
            'lag': 12,
            'atr_period': 14,
            'profit_multiplier': 2.0,
            'stop_multiplier': 1.5,
            'transaction_cost_bps': 10.0,
            'strength_weight': 0.3,
            'trend_weight': 0.3,
            'winrate_weight': 0.2,
            'alignment_weight': 0.2,
            'quality_threshold': 0.5,
        }
    
    def test_init(self, optimizer):
        """æ¸¬è©¦åˆå§‹åŒ–"""
        assert optimizer.symbol == 'BTCUSDT'
        assert optimizer.timeframe == '15m'
        assert optimizer.primary_signals is None  # åˆå§‹æœªè¨­å®š
    
    def test_set_primary_signals(self, optimizer, sample_signals):
        """æ¸¬è©¦è¨­å®š Primary ä¿¡è™Ÿ"""
        optimizer.set_primary_signals(sample_signals)
        
        assert optimizer.primary_signals is not None
        assert len(optimizer.primary_signals) == len(sample_signals)
        assert optimizer.primary_signals.equals(sample_signals)
    
    def test_atr_calculation(self, optimizer, sample_price_data):
        """æ¸¬è©¦ ATR è¨ˆç®—"""
        optimizer.price_data = sample_price_data
        close = sample_price_data['close']
        
        atr = optimizer._calculate_atr(close, period=14)
        
        assert isinstance(atr, pd.Series)
        assert len(atr) == len(close)
        assert not atr.isna().all()  # è‡³å°‘æœ‰ä¸€äº›é NaN å€¼
        assert (atr >= 0).all()  # ATR æ‡‰è©²éè² 
    
    def test_meta_features_generation(self, optimizer, sample_signals, sample_price_data, sample_params):
        """æ¸¬è©¦å…ƒç‰¹å¾µç”Ÿæˆ"""
        optimizer.price_data = sample_price_data
        
        meta_features = optimizer.generate_meta_features(
            sample_signals, sample_price_data, sample_params
        )
        
        # åŸºæœ¬é©—è­‰
        assert isinstance(meta_features, pd.DataFrame)
        assert len(meta_features) == len(sample_signals)
        
        # é©—è­‰åŒ…å«çš„ç‰¹å¾µ
        expected_features = [
            'signal_strength',
            'risk_reward_ratio',
            'volatility',
            'trend_strength',
            'volume_ratio',
            'momentum_5',
            'momentum_20',
            'recent_winrate',
            'signal_momentum_alignment'
        ]
        
        for feature in expected_features:
            assert feature in meta_features.columns, f"ç¼ºå°‘ç‰¹å¾µ: {feature}"
        
        # é©—è­‰æ²’æœ‰ NaN
        assert not meta_features.isna().any().any(), "å…ƒç‰¹å¾µåŒ…å« NaN å€¼"
        
        print(f"\n   âœ… ç”Ÿæˆ {len(meta_features.columns)} å€‹å…ƒç‰¹å¾µ")
    
    def test_meta_labels_generation(self, optimizer, sample_signals, sample_price_data, sample_params):
        """æ¸¬è©¦å…ƒæ¨™ç±¤ç”Ÿæˆ"""
        meta_labels = optimizer.generate_meta_labels(
            sample_signals, sample_price_data, sample_params
        )
        
        # åŸºæœ¬é©—è­‰
        assert isinstance(meta_labels, pd.Series)
        assert len(meta_labels) == len(sample_signals)
        assert meta_labels.isin([0, 1]).all()  # åªåŒ…å« 0 å’Œ 1
        
        # çµ±è¨ˆé©—è­‰
        good_ratio = (meta_labels == 1).sum() / len(meta_labels)
        print(f"\n   å¥½ä¿¡è™Ÿæ¯”ä¾‹: {good_ratio:.1%}")
        
        # æ‡‰è©²æœ‰ä¸€å®šæ¯”ä¾‹çš„å¥½ä¿¡è™Ÿ
        assert 0.2 <= good_ratio <= 0.8, f"å¥½ä¿¡è™Ÿæ¯”ä¾‹ {good_ratio:.1%} ç•°å¸¸"
    
    def test_quality_evaluation(self, optimizer, sample_signals, sample_price_data, sample_params):
        """æ¸¬è©¦è³ªé‡è©•ä¼°"""
        optimizer.price_data = sample_price_data
        
        meta_features = optimizer.generate_meta_features(
            sample_signals, sample_price_data, sample_params
        )
        
        quality_labels = optimizer.evaluate_quality(meta_features, sample_params)
        
        # åŸºæœ¬é©—è­‰
        assert isinstance(quality_labels, pd.Series)
        assert len(quality_labels) == len(meta_features)
        assert quality_labels.isin([0, 1]).all()  # åªåŒ…å« 0 å’Œ 1
        
        # åŸ·è¡Œç‡é©—è­‰
        execution_ratio = (quality_labels == 1).sum() / len(quality_labels)
        print(f"\n   åŸ·è¡Œç‡: {execution_ratio:.1%}")
        
        # åŸ·è¡Œç‡æ‡‰è©²åœ¨åˆç†ç¯„åœï¼ˆ20-80%ï¼‰
        assert 0.1 <= execution_ratio <= 0.9, f"åŸ·è¡Œç‡ {execution_ratio:.1%} ç•°å¸¸"
    
    def test_objective_function(self, optimizer, sample_signals, sample_price_data):
        """æ¸¬è©¦ç›®æ¨™å‡½æ•¸"""
        import optuna
        
        # è¨­å®šå¿…è¦çš„æ•¸æ“š
        optimizer.set_primary_signals(sample_signals)
        optimizer.price_data = sample_price_data
        
        study = optuna.create_study(direction='maximize')
        
        # é‹è¡Œ 3 å€‹è©¦é©—
        study.optimize(optimizer.objective, n_trials=3, show_progress_bar=False)
        
        # é©—è­‰
        assert study.best_value is not None
        assert study.best_value > -999  # ä¸æ‡‰è©²æ˜¯éŒ¯èª¤å€¼
        assert len(study.best_params) > 0
        
        # é©—è­‰è¨˜éŒ„çš„é¡å¤–ä¿¡æ¯
        best_trial = study.best_trial
        assert 'f1_score' in best_trial.user_attrs
        assert 'precision' in best_trial.user_attrs
        assert 'recall' in best_trial.user_attrs
        assert 'sharpe' in best_trial.user_attrs
        assert 'execution_ratio' in best_trial.user_attrs
    
    def test_optimize_integration(self, optimizer, sample_signals, sample_price_data):
        """æ¸¬è©¦å®Œæ•´å„ªåŒ–æµç¨‹ï¼ˆé›†æˆæ¸¬è©¦ï¼‰"""
        # è¨­å®šå¿…è¦çš„æ•¸æ“š
        optimizer.set_primary_signals(sample_signals)
        optimizer.price_data = sample_price_data
        
        result = optimizer.optimize(n_trials=5)
        
        # é©—è­‰çµæœçµæ§‹
        assert 'best_params' in result
        assert 'best_score' in result
        assert 'f1_score' in result
        assert 'precision' in result
        assert 'recall' in result
        assert 'sharpe' in result
        assert 'execution_ratio' in result
        
        # é©—è­‰çµæœç¯„åœ
        assert result['best_score'] > 0, "æœ€ä½³å¾—åˆ†æ‡‰è©²ç‚ºæ­£æ•¸"
        assert 0 <= result['f1_score'] <= 1, "F1 åˆ†æ•¸æ‡‰è©²åœ¨ 0-1 ä¹‹é–“"
        assert 0 <= result['precision'] <= 1, "ç²¾ç¢ºç‡æ‡‰è©²åœ¨ 0-1 ä¹‹é–“"
        assert 0 <= result['recall'] <= 1, "å¬å›ç‡æ‡‰è©²åœ¨ 0-1 ä¹‹é–“"
        assert 0 <= result['execution_ratio'] <= 1, "åŸ·è¡Œç‡æ‡‰è©²åœ¨ 0-1 ä¹‹é–“"
        
        print(f"\n   âœ… å„ªåŒ–å®Œæˆ:")
        print(f"      æœ€ä½³å¾—åˆ†: {result['best_score']:.4f}")
        print(f"      F1 åˆ†æ•¸: {result['f1_score']:.3f}")
        print(f"      ç²¾ç¢ºç‡: {result['precision']:.3f}")
        print(f"      å¬å›ç‡: {result['recall']:.3f}")
        print(f"      Sharpe: {result['sharpe']:.2f}")
        print(f"      åŸ·è¡Œç‡: {result['execution_ratio']:.1%}")
    
    def test_rolling_winrate_calculation(self, optimizer, sample_signals, sample_price_data):
        """æ¸¬è©¦æ»¾å‹•å‹ç‡è¨ˆç®—"""
        winrate = optimizer._calculate_rolling_winrate(
            sample_signals, sample_price_data, window=20, lag=12
        )
        
        # åŸºæœ¬é©—è­‰
        assert isinstance(winrate, pd.Series)
        assert len(winrate) == len(sample_signals)
        
        # é©—è­‰å‹ç‡ç¯„åœï¼ˆ0-1ï¼‰
        valid_winrate = winrate.dropna()
        assert (valid_winrate >= 0).all(), "å‹ç‡ä¸æ‡‰ç‚ºè² "
        assert (valid_winrate <= 1).all(), "å‹ç‡ä¸æ‡‰è¶…é 1"
    
    def test_feature_quality(self, optimizer, sample_signals, sample_price_data, sample_params):
        """æ¸¬è©¦å…ƒç‰¹å¾µçš„è³ªé‡ï¼ˆç„¡æ¥µç«¯å€¼ï¼‰"""
        optimizer.price_data = sample_price_data
        
        meta_features = optimizer.generate_meta_features(
            sample_signals, sample_price_data, sample_params
        )
        
        # é©—è­‰æ²’æœ‰ç„¡é™å€¼
        assert not np.isinf(meta_features.values).any(), "å…ƒç‰¹å¾µåŒ…å«ç„¡é™å€¼"
        
        # é©—è­‰æ²’æœ‰æ¥µç«¯å¤§çš„å€¼
        for col in meta_features.columns:
            values = meta_features[col].abs()
            max_val = values.max()
            assert max_val < 1e10, f"ç‰¹å¾µ {col} åŒ…å«æ¥µç«¯å€¼: {max_val}"


def test_quick_validation():
    """å¿«é€Ÿé©—è­‰æ¸¬è©¦ï¼ˆç¨ç«‹é‹è¡Œï¼‰"""
    print("\nğŸš€ Meta Quality Optimizer å¿«é€Ÿé©—è­‰")
    
    optimizer = MetaQualityOptimizer(
        data_path='data',
        config_path='configs'
    )
    
    # å‰µå»ºæ¨¡æ“¬æ•¸æ“š
    np.random.seed(42)
    dates = pd.date_range('2024-01-01', periods=1000, freq='15min')
    
    # æ¨¡æ“¬ Primary ä¿¡è™Ÿ
    signals = pd.Series(
        np.random.choice([1, -1], size=1000),
        index=dates
    )
    
    # æ¨¡æ“¬åƒ¹æ ¼æ•¸æ“š
    returns = np.random.normal(0.0001, 0.01, 1000)
    prices = 100 * (1 + returns).cumprod()
    
    price_data = pd.DataFrame({
        'open': prices * 0.999,
        'high': prices * 1.005,
        'low': prices * 0.995,
        'close': prices,
        'volume': np.random.uniform(1000, 10000, 1000)
    }, index=dates)
    
    # è¨­å®šæ•¸æ“š
    optimizer.set_primary_signals(signals)
    optimizer.price_data = price_data
    
    print(f"âœ… æ•¸æ“šè¨­å®šå®Œæˆ")
    
    # æ¸¬è©¦å…ƒç‰¹å¾µç”Ÿæˆ
    params = {
        'lag': 12,
        'atr_period': 14,
        'profit_multiplier': 2.0,
        'stop_multiplier': 1.5,
        'transaction_cost_bps': 10.0,
        'strength_weight': 0.3,
        'trend_weight': 0.3,
        'winrate_weight': 0.2,
        'alignment_weight': 0.2,
        'quality_threshold': 0.5,
    }
    
    meta_features = optimizer.generate_meta_features(signals, price_data, params)
    print(f"âœ… å…ƒç‰¹å¾µç”Ÿæˆ: {len(meta_features.columns)} å€‹ç‰¹å¾µ")
    
    meta_labels = optimizer.generate_meta_labels(signals, price_data, params)
    good_ratio = (meta_labels == 1).sum() / len(meta_labels)
    print(f"âœ… å…ƒæ¨™ç±¤ç”Ÿæˆ: å¥½ä¿¡è™Ÿæ¯”ä¾‹ {good_ratio:.1%}")
    
    quality = optimizer.evaluate_quality(meta_features, params)
    exec_ratio = (quality == 1).sum() / len(quality)
    print(f"âœ… è³ªé‡è©•ä¼°: åŸ·è¡Œç‡ {exec_ratio:.1%}")
    
    print("âœ… æ‰€æœ‰é©—è­‰é€šé!")


if __name__ == "__main__":
    # ç¨ç«‹é‹è¡Œæ¸¬è©¦
    test_quick_validation()

